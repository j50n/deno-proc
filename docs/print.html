<!DOCTYPE HTML>
<html lang="en" class="navy sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>proc</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="Run child processes and work with async iterables in Deno‚Äîwith the fluent Array API you already know.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/custom.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "navy";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('navy')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">proc</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/j50n/deno-proc" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="welcome-to-proc"><a class="header" href="#welcome-to-proc">Welcome to proc</a></h1>
<p>Running child processes and working with streams should be simple. <strong>proc</strong>
makes it simple.</p>
<blockquote>
<p><strong>‚ú® The Big Idea</strong>: Treat processes and streams like arrays. Use <code>map</code>,
<code>filter</code>, <code>reduce</code> on anything. Errors flow naturally through pipelines. No
callbacks, no edge cases, no headaches.</p>
</blockquote>
<h2 id="what-is-proc"><a class="header" href="#what-is-proc">What is proc?</a></h2>
<p>proc is a Deno library that gives you two superpowers:</p>
<ol>
<li><strong>Run child processes</strong> with a clean, composable API</li>
<li><strong>Work with async iterables</strong> using the Array methods you already know</li>
</ol>
<p>But here's the real magic: <strong>errors just work</strong>. They flow through your
pipelines naturally, like data. No edge cases, no separate error channels, no
callbacks. One try-catch at the end handles everything.</p>
<blockquote>
<p><strong>üí° Tip</strong>: If you've ever struggled with JavaScript streams, you're going to
love this.</p>
</blockquote>
<h2 id="a-taste-of-proc"><a class="header" href="#a-taste-of-proc">A Taste of proc</a></h2>
<p>Count lines in a compressed file‚Äîstreaming, no temp files:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const lines = await read("war-and-peace.txt.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .count();

console.log(`${lines} lines`); // 23,166 lines
</code></pre>
<p>Build custom transformations with readable async generators:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

// Parse and validate JSON lines
async function* parseJsonLines(lines) {
  for await (const line of lines) {
    try {
      const obj = JSON.parse(line.trim());
      if (obj.id &amp;&amp; obj.timestamp) yield obj;
    } catch {
      // Skip invalid JSON
    }
  }
}

const validEntries = await enumerate(logLines)
  .transform(parseJsonLines)
  .collect();
</code></pre>
<p>Chain processes like shell pipes:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const result = await run("cat", "data.txt")
  .run("grep", "error")
  .run("wc", "-l")
  .lines.first;
</code></pre>
<p>Handle errors gracefully:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

try {
  await run("npm", "test")
    .lines
    .map((line) =&gt; line.toUpperCase())
    .filter((line) =&gt; line.includes("FAIL"))
    .forEach((line) =&gt; console.log(line));
} catch (error) {
  // All errors caught here‚Äîfrom the process, from map, from filter
  console.error(`Tests failed: ${error.code}`);
}
</code></pre>
<h2 id="why-proc"><a class="header" href="#why-proc">Why proc?</a></h2>
<p><strong>JavaScript streaming is fast, but error handling shouldn't break your brain.</strong>
proc gives you:</p>
<ul>
<li><strong>Errors that propagate naturally</strong> through pipelines</li>
<li><strong>Array methods on async iterables</strong> (map, filter, reduce, and more)</li>
<li><strong>Custom transformations with async generators</strong> (easier than streams API)</li>
<li><strong>Process management</strong> that feels like shell scripting</li>
<li><strong>Streaming everything</strong> for memory efficiency</li>
<li><strong>Type safety</strong> with full TypeScript support</li>
</ul>
<h2 id="who-is-this-for"><a class="header" href="#who-is-this-for">Who is this for?</a></h2>
<ul>
<li><strong>DevOps engineers</strong> automating deployments, processing logs, and managing
infrastructure</li>
<li><strong>Data engineers</strong> processing large CSV files, log files, or streaming data</li>
<li><strong>Backend developers</strong> building CLI tools, batch processors, or data pipelines</li>
<li><strong>System administrators</strong> replacing Bash scripts with type-safe, testable Deno
code</li>
<li><strong>Anyone</strong> who needs to run child processes or work with large datasets
efficiently</li>
</ul>
<h2 id="ready-to-dive-in"><a class="header" href="#ready-to-dive-in">Ready to dive in?</a></h2>
<p>Start with <a href="./getting-started/installation.html">Installation</a> or jump straight to
the <a href="./getting-started/quick-start.html">Quick Start</a>.</p>
<hr />
<p><strong>Current Version:</strong> 0.23.3<br />
<strong>Status:</strong> Stable, actively maintained, ready for production</p>
<p>Found a bug? Have a question?
<a href="https://github.com/j50n/deno-proc/issues">File an issue</a> or check the
<a href="./faq.html">FAQ</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>Getting started with proc is simple‚Äîit's just a Deno import away.</p>
<h2 id="import-from-jsr"><a class="header" href="#import-from-jsr">Import from JSR</a></h2>
<p>Add proc to your Deno project:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import * as proc from "jsr:@j50n/proc@0.23.3";
</code></pre>
<p>Or import just what you need:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run, enumerate, read } from "jsr:@j50n/proc@0.23.3";
</code></pre>
<p>That's it! No installation step, no package.json, no node_modules.</p>
<h2 id="permissions"><a class="header" href="#permissions">Permissions</a></h2>
<p>proc needs permissions to run child processes and access files. When you run your script, Deno will prompt you, or you can grant them upfront:</p>
<pre><code class="language-bash">deno run --allow-run --allow-read your-script.ts
</code></pre>
<p><strong>Common permissions:</strong></p>
<ul>
<li><code>--allow-run</code> - Required to run child processes</li>
<li><code>--allow-read</code> - Needed to read files</li>
<li><code>--allow-write</code> - Needed to write files</li>
<li><code>--allow-env</code> - If your processes need environment variables</li>
</ul>
<p>You can be more specific:</p>
<pre><code class="language-bash"># Only allow running specific commands
deno run --allow-run=ls,grep,wc your-script.ts

# Only allow reading specific directories
deno run --allow-read=/var/log your-script.ts
</code></pre>
<h2 id="version-pinning"><a class="header" href="#version-pinning">Version Pinning</a></h2>
<p>For production, pin to a specific version:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@1.0.0";
</code></pre>
<p>For development, use the latest:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc";
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>Ready to write your first proc script? Head to the <a href="getting-started/./quick-start.html">Quick Start</a> guide.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h1>
<p>Let's get you running code in 5 minutes.</p>
<h2 id="your-first-process"><a class="header" href="#your-first-process">Your First Process</a></h2>
<p>Create a file called <code>hello.ts</code>:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "quick-start: basic run and capture" -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

// Run a command and capture output
const lines = await run("echo", "Hello, proc!").lines.collect();
console.log(lines); // ["Hello, proc!"]
</code></pre>
<p>Run it:</p>
<pre><code class="language-bash">deno run --allow-run hello.ts
</code></pre>
<p><strong>What just happened?</strong></p>
<ul>
<li><code>run()</code> started the <code>echo</code> command</li>
<li><code>.lines</code> converted the output to text lines</li>
<li><code>.collect()</code> gathered all lines into an array</li>
</ul>
<h2 id="chaining-processes"><a class="header" href="#chaining-processes">Chaining Processes</a></h2>
<p>Let's chain commands together, like shell pipes:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "quick-start: chain processes" -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const result = await run("echo", "HELLO WORLD")
  .run("tr", "A-Z", "a-z")  // Convert to lowercase
  .lines.first;

console.log(result); // "hello world"
</code></pre>
<p>Each <code>.run()</code> pipes the previous output to the next command's input.</p>
<h2 id="working-with-files"><a class="header" href="#working-with-files">Working with Files</a></h2>
<p>Process a file line by line:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "quick-start: process file" -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const errorCount = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .count();

console.log(`Found ${errorCount} errors`);
</code></pre>
<h2 id="handling-errors"><a class="header" href="#handling-errors">Handling Errors</a></h2>
<p>Errors propagate naturally‚Äîcatch them once at the end:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "quick-start: handle errors" -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

try {
  await run("false")  // This command exits with code 1
    .lines
    .collect();
} catch (error) {
  console.error(`Command failed: ${error.code}`);
}
</code></pre>
<p>No need to check errors at each step. They flow through the pipeline and you catch them once. For details, see <a href="getting-started/../core/error-handling.html">Error Handling</a>.</p>
<h2 id="using-array-methods"><a class="header" href="#using-array-methods">Using Array Methods</a></h2>
<p>Work with async data using familiar Array methods:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "quick-start: enumerate with indices" -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const data = ["apple", "banana", "cherry"];

const numbered = await enumerate(data)
  .enum()  // Add indices
  .map(([fruit, i]) =&gt; `${i + 1}. ${fruit}`)
  .collect();

console.log(numbered);
// ["1. apple", "2. banana", "3. cherry"]
</code></pre>
<h2 id="a-real-example"><a class="header" href="#a-real-example">A Real Example</a></h2>
<p>Let's find the 5 most recent commits that mention "fix":</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "quick-start: git log example" -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const commits = await run("git", "log", "--oneline")
  .lines
  .filter(line =&gt; line.includes("fix"))
  .take(5)
  .collect();

commits.forEach(commit =&gt; console.log(commit));
</code></pre>
<p>This chains multiple operations, all streaming, using minimal memory. For more complex examples, see <a href="getting-started/../recipes/counting-words.html">Recipes</a>.</p>
<h2 id="whats-next"><a class="header" href="#whats-next">What's Next?</a></h2>
<p>Now that you've got the basics, learn about:</p>
<ul>
<li><a href="getting-started/./key-concepts.html">Key Concepts</a> - Properties vs methods, resource management</li>
<li><a href="getting-started/../core/error-handling.html">Error Handling</a> - The killer feature explained</li>
<li><a href="getting-started/../core/running-processes.html">Running Processes</a> - All the ways to run commands</li>
</ul>
<p>Or jump straight to <a href="getting-started/../recipes/counting-words.html">Recipes</a> for copy-paste solutions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h1>
<p>Before you dive deep, let's cover a few concepts that will make everything click.</p>
<h2 id="properties-vs-methods"><a class="header" href="#properties-vs-methods">Properties vs Methods</a></h2>
<p>This trips up everyone at first. Some APIs are <strong>properties</strong> (no parentheses), some are <strong>methods</strong> (with parentheses).</p>
<p><strong>Properties:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">.lines    // Not .lines()
.status   // Not .status()
.first    // Not .first()
.last     // Not .last()
</code></pre>
<p><strong>Methods:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">.collect()
.map()
.filter()
.count()
</code></pre>
<p><strong>Why?</strong> Properties are getters that return new objects or promises. Methods are functions you call. Your IDE will help, but when in doubt, check the docs.</p>
<h2 id="error-propagation"><a class="header" href="#error-propagation">Error Propagation</a></h2>
<p>Errors flow through pipelines like data‚Äîno need to check at every step:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  await run("command1")
    .run("command2")
    .run("command3")
    .lines
    .forEach(process);
} catch (error) {
  // All errors caught here
  handle(error);
}
</code></pre>
<p>Errors from processes, transformations, or your own code all propagate to the same place. For details, see <a href="getting-started/../core/error-handling.html">Error Handling</a>.</p>
<h2 id="resource-management"><a class="header" href="#resource-management">Resource Management</a></h2>
<p><strong>Golden rule:</strong> Always consume process output.</p>
<p><strong>Good:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("ls").lines.collect();  // ‚úÖ Output consumed
await run("ls").lines.forEach(console.log);  // ‚úÖ Output consumed
</code></pre>
<p><strong>Bad:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const p = run("ls");  // ‚ùå Output never consumed = resource leak
</code></pre>
<p><strong>Why?</strong> Unconsumed output keeps the process handle open. Always use <code>.collect()</code>, <code>.forEach()</code>, or iterate through the output.</p>
<h2 id="enumeration-pattern"><a class="header" href="#enumeration-pattern">Enumeration Pattern</a></h2>
<p><code>enumerate()</code> wraps an iterable to give it Array-like methods. To add indices, call <code>.enum()</code> on the result:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

// enumerate() wraps the iterable, .enum() adds indices
const numbered = await enumerate(["a", "b", "c"])
  .enum()  // Returns [item, index] tuples
  .map(([item, i]) =&gt; `${i}: ${item}`)
  .collect();
// ["0: a", "1: b", "2: c"]
</code></pre>
<p><strong>Why two steps?</strong> <code>enumerate()</code> gives you the methods (map, filter, etc.), while <code>.enum()</code> is just one of many operations you can perform. You might not always need indices:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "key-concepts: enumerate without indices" -->
<pre><code class="language-typescript">// Use enumerate() without .enum() for other operations
const doubled = await enumerate([1, 2, 3])
  .map(n =&gt; n * 2)  // No indices needed
  .collect();
</code></pre>
<h2 id="streaming-everything"><a class="header" href="#streaming-everything">Streaming Everything</a></h2>
<p>proc is <strong>lazy</strong> and <strong>streaming</strong> by default. Nothing happens until you consume the output.</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "key-concepts: streaming" -->
<pre><code class="language-typescript">// This doesn't run anything yet
const pipeline = run("cat", "huge-file.txt")
  .run("grep", "error")
  .lines
  .map(line =&gt; line.toUpperCase());

// Now it runs, one line at a time
for await (const line of pipeline) {
  console.log(line);  // Processes one line at a time
}
</code></pre>
<p>This means you can process files larger than memory. The data flows through, never all loaded at once.</p>
<h2 id="type-safety"><a class="header" href="#type-safety">Type Safety</a></h2>
<p>proc is fully typed. Your IDE will guide you:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lines: string[] = await run("ls").lines.collect();
//    ^-- TypeScript knows this is string[]

const count: number = await run("ls").lines.count();
//    ^-- TypeScript knows this is number
</code></pre>
<p>If you see a type error, you're probably using the API wrong. Check the docs!</p>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>Now that you understand the concepts, dive into:</p>
<ul>
<li><a href="getting-started/../core/error-handling.html">Error Handling</a> - Deep dive into the killer feature</li>
<li><a href="getting-started/../core/running-processes.html">Running Processes</a> - All the ways to run commands</li>
<li><a href="getting-started/../iterables/array-methods.html">Array-Like Methods</a> - map, filter, reduce, and more</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h1>
<p>This guide shows typical usage patterns to help you understand how proc works in
practice.</p>
<h2 id="pattern-run-and-collect"><a class="header" href="#pattern-run-and-collect">Pattern: Run and Collect</a></h2>
<p>The most basic pattern‚Äîrun a command and get all output:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const lines = await run("ls", "-la").lines.collect();
// lines is string[]
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li><code>.lines</code> is a property (no parentheses) that returns an Enumerable</li>
<li><code>.collect()</code> is a method that consumes the stream and returns an array</li>
<li>Always consume output to avoid resource leaks</li>
</ul>
<h2 id="pattern-process-pipeline"><a class="header" href="#pattern-process-pipeline">Pattern: Process Pipeline</a></h2>
<p>Chain commands like shell pipes:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const count = await run("cat", "data.txt")
  .run("grep", "error")
  .run("wc", "-l")
  .lines.first;
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li>Each <code>.run()</code> pipes the previous command's stdout to the next command's stdin</li>
<li><code>.first</code> is a property that returns a Promise&lt;string | undefined&gt;</li>
<li>Errors from any command in the chain propagate to the catch block</li>
</ul>
<h2 id="pattern-transform-and-filter"><a class="header" href="#pattern-transform-and-filter">Pattern: Transform and Filter</a></h2>
<p>Process output with Array methods:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const errors = await run("cat", "app.log")
  .lines
  .filter((line) =&gt; line.includes("ERROR"))
  .map((line) =&gt; line.trim())
  .take(10)
  .collect();
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li><code>.lines</code> converts byte stream to line stream</li>
<li>Methods like <code>.filter()</code>, <code>.map()</code>, <code>.take()</code> work on the stream</li>
<li>Nothing executes until you call a terminal operation like <code>.collect()</code></li>
</ul>
<h2 id="pattern-error-handling"><a class="header" href="#pattern-error-handling">Pattern: Error Handling</a></h2>
<p>Catch errors at the end of the pipeline:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

try {
  await run("npm", "test")
    .lines
    .forEach((line) =&gt; console.log(line));
} catch (error) {
  if (error.code) {
    console.error(`Process exited with code ${error.code}`);
  } else {
    console.error(`Error: ${error.message}`);
  }
}
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li>Processes that exit with non-zero codes throw <code>ExitCodeError</code></li>
<li>The error has a <code>.code</code> property with the exit code</li>
<li>All errors (process, transform, your code) propagate to the same catch block</li>
</ul>
<h2 id="pattern-check-status-without-throwing"><a class="header" href="#pattern-check-status-without-throwing">Pattern: Check Status Without Throwing</a></h2>
<p>Get exit status without throwing an error:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const p = run("some-command");
await p.lines.collect(); // Consume output first
const status = await p.status; // .status is a property

if (status.code !== 0) {
  console.error(`Command failed with code ${status.code}`);
}
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li><code>.status</code> is a property that returns <code>Promise&lt;CommandStatus&gt;</code></li>
<li>You must consume output before checking status</li>
<li>This doesn't throw on non-zero exit codes</li>
</ul>
<h2 id="pattern-enumerate-with-indices"><a class="header" href="#pattern-enumerate-with-indices">Pattern: Enumerate with Indices</a></h2>
<p>Add indices to any iterable:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const numbered = await enumerate(["a", "b", "c"])
  .enum() // Adds [item, index] tuples
  .map(([item, i]) =&gt; `${i + 1}. ${item}`)
  .collect();
// ["1. a", "2. b", "3. c"]
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li><code>enumerate()</code> wraps an iterable to add Array-like methods</li>
<li><code>.enum()</code> is a method that transforms items to <code>[item, index]</code> tuples</li>
<li>This is a two-step process: wrap, then enumerate</li>
</ul>
<h2 id="pattern-enumerate-without-indices"><a class="header" href="#pattern-enumerate-without-indices">Pattern: Enumerate Without Indices</a></h2>
<p>Use Array methods without adding indices:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const filtered = await enumerate(["a", "b", "c"])
  .filter((item) =&gt; item !== "b")
  .map((item) =&gt; item.toUpperCase())
  .collect();
// ["A", "C"]
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li>You don't need to call <code>.enum()</code> if you don't need indices</li>
<li><code>enumerate()</code> just adds Array-like methods to any iterable</li>
</ul>
<h2 id="pattern-stream-large-files"><a class="header" href="#pattern-stream-large-files">Pattern: Stream Large Files</a></h2>
<p>Process files without loading into memory:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const errorCount = await read("huge-log.txt")
  .lines
  .filter((line) =&gt; line.includes("ERROR"))
  .count();
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li><code>read()</code> returns an Enumerable of bytes</li>
<li><code>.lines</code> converts to line stream</li>
<li>Everything streams‚Äîno memory spike for large files</li>
</ul>
<h2 id="pattern-decompress-and-process"><a class="header" href="#pattern-decompress-and-process">Pattern: Decompress and Process</a></h2>
<p>Handle compressed files:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const lines = await read("data.txt.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .collect();
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li><code>.transform()</code> applies a TransformStream</li>
<li><code>DecompressionStream</code> is built into Deno</li>
<li>Everything streams‚Äîno temp files needed</li>
</ul>
<h2 id="pattern-concurrent-processing"><a class="header" href="#pattern-concurrent-processing">Pattern: Concurrent Processing</a></h2>
<p>Process items in parallel with concurrency control:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const urls = ["url1", "url2", "url3"];

await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    const response = await fetch(url);
    return { url, status: response.status };
  }, { concurrency: 5 })
  .forEach((result) =&gt; console.log(result));
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li><code>.concurrentMap()</code> processes items in parallel</li>
<li><code>concurrency</code> option limits how many run at once</li>
<li>Results maintain input order (use <code>.concurrentUnorderedMap()</code> for faster
unordered results)</li>
</ul>
<h2 id="pattern-build-objects-with-reduce"><a class="header" href="#pattern-build-objects-with-reduce">Pattern: Build Objects with Reduce</a></h2>
<p>Aggregate data into a single value:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const wordCount = await run("cat", "data.txt")
  .lines
  .reduce((acc, line) =&gt; {
    const words = line.split(/\s+/);
    for (const word of words) {
      acc[word] = (acc[word] || 0) + 1;
    }
    return acc;
  }, {} as Record&lt;string, number&gt;);
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li><code>.reduce()</code> works like Array.reduce()</li>
<li>Provide an initial value (second argument)</li>
<li>The accumulator can be any type</li>
</ul>
<h2 id="pattern-split-stream-with-tee"><a class="header" href="#pattern-split-stream-with-tee">Pattern: Split Stream with Tee</a></h2>
<p>Process the same stream multiple ways:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const [errors, warnings] = run("cat", "app.log")
  .lines
  .tee(2);

const errorCount = errors.filter((line) =&gt; line.includes("ERROR")).count();
const warningCount = warnings.filter((line) =&gt; line.includes("WARN")).count();

console.log(`Errors: ${await errorCount}, Warnings: ${await warningCount}`);
</code></pre>
<p><strong>Key points:</strong></p>
<ul>
<li><code>.tee(n)</code> splits a stream into n identical streams</li>
<li>Each stream can be processed independently</li>
<li>All streams must be consumed</li>
</ul>
<h2 id="anti-pattern-not-consuming-output"><a class="header" href="#anti-pattern-not-consuming-output">Anti-Pattern: Not Consuming Output</a></h2>
<p><strong>Don't do this:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const p = run("ls"); // ‚ùå Output never consumed
</code></pre>
<p><strong>Why it's bad:</strong> Unconsumed output keeps the process handle open, causing
resource leaks.</p>
<p><strong>Do this instead:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("ls").lines.collect(); // ‚úÖ Output consumed
</code></pre>
<h2 id="anti-pattern-mixing-sync-and-async"><a class="header" href="#anti-pattern-mixing-sync-and-async">Anti-Pattern: Mixing Sync and Async</a></h2>
<p><strong>Don't do this:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lines = run("ls").lines; // ‚ùå Not awaited
lines.forEach((line) =&gt; console.log(line)); // ‚ùå Won't work
</code></pre>
<p><strong>Why it's bad:</strong> <code>.lines</code> returns an Enumerable, but you need to await the
terminal operation.</p>
<p><strong>Do this instead:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("ls").lines.forEach((line) =&gt; console.log(line)); // ‚úÖ Awaited
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h1>
<p>Error handling is proc's primary design goal. <strong>Errors flow through pipelines naturally, just like data.</strong></p>
<h2 id="the-problem"><a class="header" href="#the-problem">The Problem</a></h2>
<p>Traditional stream error handling requires managing errors at multiple points:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// With Deno.Command - manual error handling at each step
const cmd1 = new Deno.Command("cat", { args: ["file.txt"] });
const proc1 = cmd1.spawn();
const output1 = await proc1.output();
if (!output1.success) {
  throw new Error(`cat failed: ${output1.code}`);
}

const cmd2 = new Deno.Command("grep", { 
  args: ["pattern"],
  stdin: "piped"
});
const proc2 = cmd2.spawn();
// ... manually pipe output1 to proc2 stdin ...
const output2 = await proc2.output();
if (!output2.success) {
  throw new Error(`grep failed: ${output2.code}`);
}
</code></pre>
<p>With Node.js streams, you need error handlers on each stream:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">stream1.on('error', handleError);
stream2.on('error', handleError);
stream3.on('error', handleError);
</code></pre>
<h2 id="the-proc-solution"><a class="header" href="#the-proc-solution">The proc Solution</a></h2>
<p>Errors flow through pipelines like data. Handle them once, at the end:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  await run("cat", "file.txt")
    .run("grep", "pattern")
    .run("wc", "-l")
    .lines
    .map(transform)
    .filter(predicate)
    .forEach(process);
} catch (error) {
  // All errors caught here:
  // - Process exit codes
  // - Transform errors
  // - Filter errors
  // - Your own errors
  console.error(`Pipeline failed: ${error.message}`);
}
</code></pre>
<p><strong>One try-catch. No edge cases. No separate error channels.</strong></p>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h2>
<p>When something goes wrong anywhere in the pipeline:</p>
<ol>
<li>The error is captured</li>
<li>Downstream operations are skipped</li>
<li>The error propagates to your catch block</li>
</ol>
<p>It's functional programming‚Äîerrors are just another type of data flowing through.</p>
<h2 id="error-types"><a class="header" href="#error-types">Error Types</a></h2>
<p>proc throws specific error types so you can handle them differently:</p>
<h3 id="exitcodeerror"><a class="header" href="#exitcodeerror">ExitCodeError</a></h3>
<p>Thrown when a process exits with a non-zero code:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { ExitCodeError } from "jsr:@j50n/proc@0.23.3";

try {
  await run("false").lines.collect();
} catch (error) {
  if (error instanceof ExitCodeError) {
    console.error(`Process failed with code ${error.code}`);
    console.error(`Command: ${error.command.join(" ")}`);
  }
}
</code></pre>
<h3 id="signalerror"><a class="header" href="#signalerror">SignalError</a></h3>
<p>Thrown when a process is killed by a signal:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { SignalError } from "jsr:@j50n/proc@0.23.3";

try {
  await run("sleep", "1000").lines.collect();
  // Kill it with Ctrl+C
} catch (error) {
  if (error instanceof SignalError) {
    console.error(`Process killed by signal: ${error.signal}`);
  }
}
</code></pre>
<h3 id="upstreamerror"><a class="header" href="#upstreamerror">UpstreamError</a></h3>
<p>Thrown when an error comes from upstream in a pipeline:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { UpstreamError } from "jsr:@j50n/proc@0.23.3";

try {
  await run("cat", "missing.txt")  // This fails
    .run("grep", "pattern")         // This gets UpstreamError
    .lines.collect();
} catch (error) {
  if (error instanceof UpstreamError) {
    console.error(`Upstream failure: ${error.cause}`);
  }
}
</code></pre>
<h2 id="checking-exit-status-without-throwing"><a class="header" href="#checking-exit-status-without-throwing">Checking Exit Status Without Throwing</a></h2>
<p>Sometimes you want to check the exit code without throwing:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const p = run("some-command");
await p.lines.collect();  // Consume output
const status = await p.status;  // Check status

if (status.code !== 0) {
  console.error(`Command failed with code ${status.code}`);
}
</code></pre>
<p><strong>Important:</strong> Consume the output first, then check status. Otherwise you'll leak resources.</p>
<h2 id="handling-specific-exit-codes"><a class="header" href="#handling-specific-exit-codes">Handling Specific Exit Codes</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  await run("grep", "pattern", "file.txt").lines.collect();
} catch (error) {
  if (error instanceof ExitCodeError) {
    if (error.code === 1) {
      // grep returns 1 when no matches found
      console.log("No matches found");
    } else {
      // Other errors
      throw error;
    }
  }
}
</code></pre>
<h2 id="errors-in-transformations"><a class="header" href="#errors-in-transformations">Errors in Transformations</a></h2>
<p>Errors in your own code propagate the same way:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  await run("cat", "numbers.txt")
    .lines
    .map(line =&gt; {
      const num = parseInt(line);
      if (isNaN(num)) {
        throw new Error(`Invalid number: ${line}`);
      }
      return num;
    })
    .forEach(console.log);
} catch (error) {
  // Catches both process errors AND your parsing errors
  console.error(`Pipeline failed: ${error.message}`);
}
</code></pre>
<h2 id="custom-error-handling"><a class="header" href="#custom-error-handling">Custom Error Handling</a></h2>
<p>You can customize how errors are handled per process using the <code>fnError</code> option:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run(
  {
    fnError: (error, stderrData) =&gt; {
      // Custom error handling
      if (error?.code === 1) {
        // Suppress or transform specific errors
        console.warn("Command returned 1, continuing anyway");
        return;
      }
      // Re-throw other errors
      throw error;
    }
  },
  "command"
).lines.collect();
</code></pre>
<h3 id="suppress-all-errors"><a class="header" href="#suppress-all-errors">Suppress All Errors</a></h3>
<p>Sometimes you want to ignore failures:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Ignore all errors from this command
await run(
  { fnError: () =&gt; {} },
  "command"
).lines.collect();
</code></pre>
<h3 id="transform-errors"><a class="header" href="#transform-errors">Transform Errors</a></h3>
<p>Add context or change error types:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run(
  {
    fnError: (error) =&gt; {
      throw new Error(`Database backup failed: ${error.message}`);
    }
  },
  "pg_dump", "mydb"
).lines.collect();
</code></pre>
<h2 id="working-with-stderr"><a class="header" href="#working-with-stderr">Working with Stderr</a></h2>
<p>By default, stderr is passed through to <code>Deno.stderr</code>. You can capture and process it:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run(
  {
    fnStderr: async (stderr) =&gt; {
      for await (const line of stderr.lines) {
        console.error(`[STDERR] ${line}`);
      }
    }
  },
  "command"
).lines.collect();
</code></pre>
<h3 id="collect-stderr"><a class="header" href="#collect-stderr">Collect Stderr</a></h3>
<p>Capture stderr for analysis:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const stderrLines: string[] = [];

await run(
  {
    fnStderr: async (stderr) =&gt; {
      for await (const line of stderr.lines) {
        stderrLines.push(line);
      }
    }
  },
  "command"
).lines.collect();

console.log("Stderr output:", stderrLines);
</code></pre>
<h3 id="combine-stdout-and-stderr"><a class="header" href="#combine-stdout-and-stderr">Combine Stdout and Stderr</a></h3>
<p>Process both streams together:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const allOutput: string[] = [];

await run(
  {
    fnStderr: async (stderr) =&gt; {
      for await (const line of stderr.lines) {
        allOutput.push(`[ERR] ${line}`);
      }
    }
  },
  "command"
).lines.forEach(line =&gt; {
  allOutput.push(`[OUT] ${line}`);
});
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="1-catch-at-the-end"><a class="header" href="#1-catch-at-the-end">1. Catch at the End</a></h3>
<p>Don't catch errors in the middle of a pipeline unless you're handling them specifically:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Don't do this
try {
  const lines = await run("command").lines.collect();
} catch (e) {
  // Handle here
}
try {
  const filtered = lines.filter(predicate);
} catch (e) {
  // And here
}

// ‚úÖ Do this
try {
  await run("command")
    .lines
    .filter(predicate)
    .forEach(process);
} catch (error) {
  // Handle once
}
</code></pre>
<h3 id="2-always-consume-output"><a class="header" href="#2-always-consume-output">2. Always Consume Output</a></h3>
<p>Even if you don't care about the output, consume it:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Resource leak
const p = run("command");
// Never consumed!

// ‚úÖ Consume it
await run("command").lines.collect();
// Or
await run("command").lines.forEach(() =&gt; {});
</code></pre>
<h3 id="3-use-specific-error-types"><a class="header" href="#3-use-specific-error-types">3. Use Specific Error Types</a></h3>
<p>Handle different errors differently:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  await pipeline();
} catch (error) {
  if (error instanceof ExitCodeError) {
    // Process failed
  } else if (error instanceof SignalError) {
    // Process killed
  } else {
    // Something else
  }
}
</code></pre>
<h3 id="4-use-custom-handlers-sparingly"><a class="header" href="#4-use-custom-handlers-sparingly">4. Use Custom Handlers Sparingly</a></h3>
<p>Only customize error handling when you have a specific need. The default behavior works well for most cases.</p>
<h2 id="why-this-matters"><a class="header" href="#why-this-matters">Why This Matters</a></h2>
<p>Error handling is the <strong>primary reason</strong> proc exists. If you've ever:</p>
<ul>
<li>Fought with stream error events</li>
<li>Debugged edge cases in error propagation</li>
<li>Written the same error handling code over and over</li>
<li>Lost errors in complex pipelines</li>
</ul>
<p>...then you understand why this is revolutionary.</p>
<p><strong>Errors just work.</strong> Like they should have all along.</p>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<ul>
<li><a href="core/./running-processes.html">Running Processes</a> - Learn all the ways to run commands</li>
<li><a href="core/./pipelines.html">Process Pipelines</a> - Chain commands together</li>
<li><a href="core/../advanced/custom-errors.html">Custom Error Handling</a> - Advanced error customization</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="running-processes"><a class="header" href="#running-processes">Running Processes</a></h1>
<p>Running a child process with proc is as simple as it gets.</p>
<h2 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h2>
<!-- TESTED: tests/mdbook_examples.test.ts - "running-processes: capture output" -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

// Run a command
await run("ls", "-la").lines.collect();
</code></pre>
<p>That's it. No boilerplate, no configuration, just run it.</p>
<h2 id="command-and-arguments"><a class="header" href="#command-and-arguments">Command and Arguments</a></h2>
<p>The first parameter is the command, the rest are arguments:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">run("command", "arg1", "arg2", "arg3")
</code></pre>
<p><strong>Important:</strong> Arguments are separate parameters, not a single string:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚úÖ Correct
run("ls", "-la", "/home")

// ‚ùå Wrong - this won't work
run("ls -la /home")
</code></pre>
<h2 id="capturing-output"><a class="header" href="#capturing-output">Capturing Output</a></h2>
<h3 id="as-an-array"><a class="header" href="#as-an-array">As an Array</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lines = await run("ls", "-la").lines.collect();
// lines is string[]
</code></pre>
<h3 id="line-by-line"><a class="header" href="#line-by-line">Line by Line</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">for await (const line of run("ls", "-la").lines) {
  console.log(line);
}
</code></pre>
<h3 id="first-or-last-line"><a class="header" href="#first-or-last-line">First or Last Line</a></h3>
<!-- TESTED: tests/mdbook_examples.test.ts - "running-processes: first line" -->
<pre><code class="language-typescript">const first = await run("ls").lines.first;
const last = await run("ls").lines.last;
</code></pre>
<h3 id="as-raw-bytes"><a class="header" href="#as-raw-bytes">As Raw Bytes</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const bytes = await run("cat", "file.bin").collect();
// bytes is Uint8Array[]
</code></pre>
<h2 id="printing-to-console"><a class="header" href="#printing-to-console">Printing to Console</a></h2>
<p>Send output directly to stdout:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("ls", "-la").toStdout();
</code></pre>
<p>This is perfect for commands where you just want to see the output.</p>
<h2 id="building-commands-dynamically"><a class="header" href="#building-commands-dynamically">Building Commands Dynamically</a></h2>
<p>Sometimes you need to build a command from variables:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { type Cmd, run } from "jsr:@j50n/proc@0.23.3";

const cmd: Cmd = ["ls"];

if (showAll) {
  cmd.push("-la");
}

if (directory) {
  cmd.push(directory);
}

await run(...cmd).toStdout();
</code></pre>
<p>The <code>Cmd</code> type is an array where the first element is the command (string or URL) and the rest are string arguments. Using the <code>Cmd</code> type ensures type safety when building commands dynamically.</p>
<h2 id="process-options"><a class="header" href="#process-options">Process Options</a></h2>
<p>Customize process behavior with options:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run(
  {
    cwd: "/tmp",           // Working directory
    env: { FOO: "bar" },   // Environment variables
  },
  "command",
  "arg1"
).lines.collect();
</code></pre>
<h3 id="working-directory"><a class="header" href="#working-directory">Working Directory</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run(
  { cwd: "/var/log" },
  "ls"
).toStdout();
</code></pre>
<h3 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run(
  { env: { PATH: "/custom/path" } },
  "command"
).lines.collect();
</code></pre>
<h2 id="checking-exit-status"><a class="header" href="#checking-exit-status">Checking Exit Status</a></h2>
<p>Get the exit status without throwing:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const p = run("command");
await p.lines.collect();  // Consume output first
const status = await p.status;

console.log(`Exit code: ${status.code}`);
console.log(`Success: ${status.success}`);
</code></pre>
<p><strong>Remember:</strong> Always consume output before checking status, or you'll leak resources.</p>
<h2 id="process-id"><a class="header" href="#process-id">Process ID</a></h2>
<p>Get the process ID:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const p = run("sleep", "10");
console.log(`PID: ${p.pid}`);
await p.lines.collect();
</code></pre>
<h2 id="running-with-urls"><a class="header" href="#running-with-urls">Running with URLs</a></h2>
<p>You can use URLs for the command:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const scriptUrl = new URL("./script.sh", import.meta.url);
await run(scriptUrl).toStdout();
</code></pre>
<h2 id="common-patterns-1"><a class="header" href="#common-patterns-1">Common Patterns</a></h2>
<h3 id="silent-execution"><a class="header" href="#silent-execution">Silent Execution</a></h3>
<p>Run a command and ignore output:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("command").lines.forEach(() =&gt; {});
</code></pre>
<h3 id="capture-and-print"><a class="header" href="#capture-and-print">Capture and Print</a></h3>
<p>Capture output while also printing it:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lines: string[] = [];
await run("command").lines.forEach(line =&gt; {
  console.log(line);
  lines.push(line);
});
</code></pre>
<h3 id="conditional-execution"><a class="header" href="#conditional-execution">Conditional Execution</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">if (needsProcessing) {
  await run("process-data").toStdout();
}
</code></pre>
<h2 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h2>
<p>By default, non-zero exit codes throw <code>ExitCodeError</code>:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  await run("false").lines.collect();
} catch (error) {
  console.error(`Command failed: ${error.code}`);
}
</code></pre>
<p>See <a href="core/./error-handling.html">Error Handling</a> for complete details.</p>
<h2 id="performance-tips"><a class="header" href="#performance-tips">Performance Tips</a></h2>
<h3 id="stream-instead-of-collect"><a class="header" href="#stream-instead-of-collect">Stream Instead of Collect</a></h3>
<p>Process data as it arrives rather than loading everything into memory:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Loads everything into memory
const lines = await run("cat", "huge-file.txt").lines.collect();
for (const line of lines) {
  process(line);
}

// ‚úÖ Processes one line at a time
for await (const line of run("cat", "huge-file.txt").lines) {
  process(line);
}
</code></pre>
<h3 id="pipe-instead-of-collect-intermediate-results"><a class="header" href="#pipe-instead-of-collect-intermediate-results">Pipe Instead of Collect Intermediate Results</a></h3>
<p>Chain processes instead of collecting intermediate results:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Collects intermediate results
const lines1 = await run("cat", "file.txt").lines.collect();
const input = lines1.join("\n");
const lines2 = await run("grep", "pattern").lines.collect();

// ‚úÖ Streams through
await run("cat", "file.txt")
  .run("grep", "pattern")
  .toStdout();
</code></pre>
<h3 id="use-take-to-stop-early"><a class="header" href="#use-take-to-stop-early">Use take() to Stop Early</a></h3>
<p>Stop processing once you have what you need:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Stops after finding 10 matches
const first10 = await run("grep", "ERROR", "huge.log")
  .lines
  .take(10)
  .collect();
</code></pre>
<h3 id="filter-before-expensive-operations"><a class="header" href="#filter-before-expensive-operations">Filter Before Expensive Operations</a></h3>
<p>Reduce the amount of data flowing through expensive operations:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚úÖ Filter first (fast), then transform (expensive)
const result = await run("cat", "data.txt")
  .lines
  .filter(line =&gt; line.length &gt; 0)  // Fast filter
  .map(expensiveTransform)          // Only runs on filtered data
  .collect();
</code></pre>
<p>For more performance optimization strategies, see <a href="core/../advanced/concurrent.html">Concurrent Processing</a> and <a href="core/../advanced/streaming.html">Streaming Large Files</a>.</p>
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<ul>
<li><a href="core/./pipelines.html">Process Pipelines</a> - Chain commands together</li>
<li><a href="core/./output.html">Working with Output</a> - Transform and process output</li>
<li><a href="core/./error-handling.html">Error Handling</a> - Handle failures gracefully</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="process-pipelines"><a class="header" href="#process-pipelines">Process Pipelines</a></h1>
<p>Chain processes together like shell pipes. It's beautiful.</p>
<h2 id="the-basics"><a class="header" href="#the-basics">The Basics</a></h2>
<p>In a shell, you'd write:</p>
<pre><code class="language-bash">cat file.txt | grep error | wc -l
</code></pre>
<p>In proc, you write:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const count = await run("cat", "file.txt")
  .run("grep", "error")
  .run("wc", "-l")
  .lines.first;
</code></pre>
<p>Each <code>.run()</code> pipes the previous output to the next command's stdin.</p>
<h2 id="how-it-works-1"><a class="header" href="#how-it-works-1">How It Works</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">run("command1")      // Produces output
  .run("command2")   // Receives command1's output as stdin
  .run("command3")   // Receives command2's output as stdin
</code></pre>
<p>The data flows through, one buffer at a time. Nothing is collected in memory unless you ask for it.</p>
<h2 id="real-examples"><a class="header" href="#real-examples">Real Examples</a></h2>
<h3 id="count-lines"><a class="header" href="#count-lines">Count Lines</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lines = await run("cat", "file.txt")
  .run("wc", "-l")
  .lines.first;

console.log(`${lines} lines`);
</code></pre>
<h3 id="find-and-count"><a class="header" href="#find-and-count">Find and Count</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const errorCount = await run("cat", "app.log")
  .run("grep", "ERROR")
  .run("wc", "-l")
  .lines.first;
</code></pre>
<h3 id="sort-and-unique"><a class="header" href="#sort-and-unique">Sort and Unique</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const unique = await run("cat", "words.txt")
  .run("sort")
  .run("uniq")
  .lines.collect();
</code></pre>
<h3 id="case-conversion"><a class="header" href="#case-conversion">Case Conversion</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lowercase = await run("echo", "HELLO WORLD")
  .run("tr", "A-Z", "a-z")
  .lines.first;
// "hello world"
</code></pre>
<h2 id="mixing-processes-and-transformations"><a class="header" href="#mixing-processes-and-transformations">Mixing Processes and Transformations</a></h2>
<p>You can mix process pipes with JavaScript transformations:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const result = await run("cat", "data.txt")
  .run("grep", "pattern")
  .lines
  .map(line =&gt; line.trim())
  .filter(line =&gt; line.length &gt; 0)
  .collect();
</code></pre>
<p>The <code>.lines</code> converts bytes to text, then JavaScript takes over.</p>
<h2 id="complex-pipelines"><a class="header" href="#complex-pipelines">Complex Pipelines</a></h2>
<p>Build sophisticated data processing pipelines:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const stats = await run("cat", "access.log")
  .run("grep", "ERROR")
  .run("cut", "-d", " ", "-f", "1")  // Extract IP addresses
  .run("sort")
  .run("uniq", "-c")                  // Count occurrences
  .run("sort", "-rn")                 // Sort by count
  .run("head", "-10")                 // Top 10
  .lines
  .collect();

console.log("Top 10 error sources:");
stats.forEach(line =&gt; console.log(line));
</code></pre>
<h2 id="branching-pipelines"><a class="header" href="#branching-pipelines">Branching Pipelines</a></h2>
<p>Sometimes you need to process the same data in multiple ways. Use <code>.tee()</code> to split a pipeline into multiple branches:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const [branch1, branch2] = run("cat", "data.txt")
  .lines
  .tee();

// Process both branches concurrently
const [result1, result2] = await Promise.all([
  branch1.filter(line =&gt; line.includes("A")).collect(),
  branch2.filter(line =&gt; line.includes("B")).collect(),
]);
</code></pre>
<p><strong>How it works:</strong> <code>.tee()</code> creates two independent iterables from one source. Each branch can be processed differently, and both can run concurrently.</p>
<p><strong>Use cases:</strong></p>
<ul>
<li>Collect different subsets of data in one pass</li>
<li>Calculate multiple statistics simultaneously</li>
<li>Process data while also logging it</li>
</ul>
<p><strong>Important:</strong> Both branches must be consumed, or you'll leak resources.</p>
<h2 id="error-handling-in-pipelines"><a class="header" href="#error-handling-in-pipelines">Error Handling in Pipelines</a></h2>
<p>Errors propagate through the entire pipeline:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  await run("cat", "missing.txt")  // This fails
    .run("grep", "pattern")         // Never runs
    .run("wc", "-l")                // Never runs
    .lines.collect();
} catch (error) {
  // Catches the error from cat
  console.error(`Pipeline failed: ${error.message}`);
}
</code></pre>
<p>See <a href="core/./error-handling.html">Error Handling</a> for details.</p>
<h2 id="performance-characteristics"><a class="header" href="#performance-characteristics">Performance Characteristics</a></h2>
<p>Pipelines are:</p>
<ul>
<li><strong>Streaming</strong> - Data flows through, not collected in memory</li>
<li><strong>Lazy</strong> - Nothing runs until you consume the output</li>
<li><strong>Concurrent</strong> - All processes run at the same time</li>
<li><strong>Efficient</strong> - Minimal memory usage, even for huge files</li>
</ul>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// This processes a 10GB file using ~constant memory
await run("cat", "huge-file.txt")
  .run("grep", "pattern")
  .run("wc", "-l")
  .lines.first;
</code></pre>
<h2 id="debugging-pipelines"><a class="header" href="#debugging-pipelines">Debugging Pipelines</a></h2>
<p>Print intermediate results:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("cat", "file.txt")
  .run("grep", "pattern")
  .lines
  .map(line =&gt; {
    console.log(`Processing: ${line}`);
    return line;
  })
  .forEach(process);
</code></pre>
<p>Or split it up:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const step1 = run("cat", "file.txt");
const step2 = step1.run("grep", "pattern");
const step3 = step2.lines;

// Now you can inspect each step
for await (const line of step3) {
  console.log(line);
}
</code></pre>
<h2 id="common-patterns-2"><a class="header" href="#common-patterns-2">Common Patterns</a></h2>
<h3 id="extract-and-count"><a class="header" href="#extract-and-count">Extract and Count</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const count = await run("cat", "file.txt")
  .run("grep", "-o", "pattern")
  .lines.count();
</code></pre>
<h3 id="filter-and-transform"><a class="header" href="#filter-and-transform">Filter and Transform</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const results = await run("cat", "data.csv")
  .run("grep", "-v", "^#")  // Remove comments
  .run("cut", "-d", ",", "-f", "1,3")  // Extract columns
  .lines
  .map(line =&gt; line.split(","))
  .collect();
</code></pre>
<h3 id="aggregate-data"><a class="header" href="#aggregate-data">Aggregate Data</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const sum = await run("cat", "numbers.txt")
  .lines
  .map(line =&gt; parseInt(line))
  .reduce((acc, n) =&gt; acc + n, 0);
</code></pre>
<h2 id="when-to-use-pipelines"><a class="header" href="#when-to-use-pipelines">When to Use Pipelines</a></h2>
<p><strong>Use pipelines when:</strong></p>
<ul>
<li>You're processing large files</li>
<li>You want to chain Unix tools</li>
<li>You need streaming performance</li>
<li>You're replacing shell scripts</li>
</ul>
<p><strong>Use JavaScript when:</strong></p>
<ul>
<li>You need complex logic</li>
<li>You're working with structured data (JSON, etc.)</li>
<li>You need type safety</li>
<li>The operation is CPU-bound</li>
</ul>
<p><strong>Mix both</strong> for the best of both worlds!</p>
<h2 id="next-steps-4"><a class="header" href="#next-steps-4">Next Steps</a></h2>
<ul>
<li><a href="core/./output.html">Working with Output</a> - Transform and process output</li>
<li><a href="core/../advanced/concurrent.html">Concurrent Processing</a> - Parallel pipelines</li>
<li><a href="core/../advanced/streaming.html">Streaming Large Files</a> - Handle huge files efficiently</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="working-with-output"><a class="header" href="#working-with-output">Working with Output</a></h1>
<p>Capture, transform, and process command output.</p>
<h2 id="choosing-your-approach"><a class="header" href="#choosing-your-approach">Choosing Your Approach</a></h2>
<p><strong>Use <code>.lines.collect()</code></strong> when you need all output as an array (small outputs only):</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lines = await run("ls").lines.collect();  // All lines in memory
</code></pre>
<p><strong>Use <code>.lines</code> with for-await</strong> when processing large outputs line-by-line:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">for await (const line of run("cat", "huge.log").lines) {
  process(line);  // Constant memory usage
}
</code></pre>
<p><strong>Use <code>.toStdout()</code></strong> when you just want to see the output:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("ls", "-la").toStdout();  // Prints directly to console
</code></pre>
<p><strong>Use <code>.first</code> or <code>.last</code></strong> when you only need one line:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const result = await run("git", "rev-parse", "HEAD").lines.first;
</code></pre>
<h2 id="getting-output"><a class="header" href="#getting-output">Getting Output</a></h2>
<h3 id="as-lines"><a class="header" href="#as-lines">As Lines</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const lines = await run("ls", "-la").lines.collect();
// string[]
</code></pre>
<h3 id="as-bytes"><a class="header" href="#as-bytes">As Bytes</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const bytes = await run("cat", "file.bin").collect();
// Uint8Array[]
</code></pre>
<h3 id="first-line"><a class="header" href="#first-line">First Line</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const result = await run("git", "rev-parse", "HEAD").lines.first;
// Single string
</code></pre>
<h3 id="print-to-console"><a class="header" href="#print-to-console">Print to Console</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("ls", "-la").toStdout();
</code></pre>
<h2 id="transforming-output"><a class="header" href="#transforming-output">Transforming Output</a></h2>
<h3 id="map-lines"><a class="header" href="#map-lines">Map Lines</a></h3>
<!-- TESTED: tests/mdbook_examples.test.ts - "output: map lines" -->
<pre><code class="language-typescript">const uppercase = await run("cat", "file.txt")
  .lines
  .map(line =&gt; line.toUpperCase())
  .collect();
</code></pre>
<h3 id="filter-lines"><a class="header" href="#filter-lines">Filter Lines</a></h3>
<!-- TESTED: tests/mdbook_examples.test.ts - "output: filter lines" -->
<pre><code class="language-typescript">const errors = await run("cat", "app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .collect();
</code></pre>
<h3 id="parse-output"><a class="header" href="#parse-output">Parse Output</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const commits = await run("git", "log", "--oneline")
  .lines
  .map(line =&gt; {
    const [hash, ...message] = line.split(" ");
    return { hash, message: message.join(" ") };
  })
  .collect();
</code></pre>
<h2 id="streaming-output"><a class="header" href="#streaming-output">Streaming Output</a></h2>
<p>Process output as it arrives:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">for await (const line of run("tail", "-f", "app.log").lines) {
  if (line.includes("ERROR")) {
    console.error(line);
  }
}
</code></pre>
<h2 id="counting-output"><a class="header" href="#counting-output">Counting Output</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lineCount = await run("ls", "-la").lines.count();
</code></pre>
<h2 id="finding-in-output"><a class="header" href="#finding-in-output">Finding in Output</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const match = await run("ps", "aux")
  .lines
  .find(line =&gt; line.includes("node"));
</code></pre>
<h2 id="real-world-examples"><a class="header" href="#real-world-examples">Real-World Examples</a></h2>
<h3 id="parse-json-output"><a class="header" href="#parse-json-output">Parse JSON Output</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const data = await run("curl", "https://api.example.com/data")
  .lines
  .map(line =&gt; JSON.parse(line))
  .collect();
</code></pre>
<h3 id="extract-fields"><a class="header" href="#extract-fields">Extract Fields</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const pids = await run("ps", "aux")
  .lines
  .drop(1)  // Skip header
  .map(line =&gt; line.split(/\s+/)[1])
  .collect();
</code></pre>
<h3 id="aggregate-data-1"><a class="header" href="#aggregate-data-1">Aggregate Data</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const total = await run("du", "-sh", "*")
  .lines
  .map(line =&gt; {
    const size = line.split("\t")[0];
    return parseInt(size);
  })
  .reduce((sum, size) =&gt; sum + size, 0);
</code></pre>
<h2 id="next-steps-5"><a class="header" href="#next-steps-5">Next Steps</a></h2>
<ul>
<li><a href="core/./pipelines.html">Process Pipelines</a> - Chain commands</li>
<li><a href="core/./running-processes.html">Running Processes</a> - More ways to run</li>
<li><a href="core/../iterables/array-methods.html">Array-Like Methods</a> - Transform output</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="working-with-input"><a class="header" href="#working-with-input">Working with Input</a></h1>
<p>Send data to process stdin.</p>
<h2 id="choosing-your-approach-1"><a class="header" href="#choosing-your-approach-1">Choosing Your Approach</a></h2>
<p><strong>Use <code>.run()</code> for process-to-process pipes</strong> (most common):</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("cat", "file.txt").run("grep", "pattern").toStdout();
</code></pre>
<p><strong>Use <code>enumerate()</code> for in-memory data</strong>:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await enumerate(["line1", "line2"]).run("grep", "1").toStdout();
</code></pre>
<p><strong>Use <code>read()</code> for file input</strong>:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await read("input.txt").run("grep", "pattern").toStdout();
</code></pre>
<p><strong>Use <code>range()</code> for generated sequences</strong>:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await range({ to: 100 }).map(n =&gt; n.toString()).run("shuf").toStdout();
</code></pre>
<h2 id="piping-between-processes"><a class="header" href="#piping-between-processes">Piping Between Processes</a></h2>
<p>The most common way to provide input:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

await run("echo", "hello")
  .run("tr", "a-z", "A-Z")  // Receives "hello" as stdin
  .toStdout();
// HELLO
</code></pre>
<h2 id="from-enumerable"><a class="header" href="#from-enumerable">From Enumerable</a></h2>
<p>Pipe any enumerable to a process:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "input: pipe from enumerable" -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const data = ["line 1", "line 2", "line 3"];

await enumerate(data)
  .run("grep", "2")
  .toStdout();
// line 2
</code></pre>
<h2 id="from-file"><a class="header" href="#from-file">From File</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

await read("input.txt")
  .run("grep", "pattern")
  .toStdout();
</code></pre>
<h2 id="real-world-examples-1"><a class="header" href="#real-world-examples-1">Real-World Examples</a></h2>
<h3 id="filter-data"><a class="header" href="#filter-data">Filter Data</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await read("data.txt")
  .run("grep", "ERROR")
  .run("sort")
  .run("uniq")
  .toStdout();
</code></pre>
<h3 id="transform-and-process"><a class="header" href="#transform-and-process">Transform and Process</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await read("input.txt")
  .lines
  .map(line =&gt; line.toUpperCase())
  .run("sort")
  .toStdout();
</code></pre>
<h3 id="generate-and-process"><a class="header" href="#generate-and-process">Generate and Process</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { range } from "jsr:@j50n/proc@0.23.3";

await range({ to: 100 })
  .map(n =&gt; n.toString())
  .run("shuf")  // Shuffle
  .run("head", "-10")
  .toStdout();
</code></pre>
<h2 id="next-steps-6"><a class="header" href="#next-steps-6">Next Steps</a></h2>
<ul>
<li><a href="core/./pipelines.html">Process Pipelines</a> - Chain commands</li>
<li><a href="core/./output.html">Working with Output</a> - Capture results</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="resource-management-1"><a class="header" href="#resource-management-1">Resource Management</a></h1>
<p>Avoid leaks and manage resources properly.</p>
<h2 id="the-golden-rule"><a class="header" href="#the-golden-rule">The Golden Rule</a></h2>
<p><strong>Always consume process output.</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

// ‚ùå Resource leak
const p = run("ls");
// Output never consumed!

// ‚úÖ Output consumed
await run("ls").lines.collect();
</code></pre>
<h2 id="why-this-matters-1"><a class="header" href="#why-this-matters-1">Why This Matters</a></h2>
<p>Unconsumed output keeps the process handle open, preventing cleanup.</p>
<h2 id="ways-to-consume-output"><a class="header" href="#ways-to-consume-output">Ways to Consume Output</a></h2>
<h3 id="collect"><a class="header" href="#collect">collect()</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lines = await run("ls").lines.collect();
</code></pre>
<h3 id="foreach"><a class="header" href="#foreach">forEach()</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("ls").lines.forEach(line =&gt; {
  console.log(line);
});
</code></pre>
<h3 id="for-await"><a class="header" href="#for-await">for-await</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">for await (const line of run("ls").lines) {
  console.log(line);
}
</code></pre>
<h3 id="tostdout"><a class="header" href="#tostdout">toStdout()</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await run("ls").toStdout();
</code></pre>
<h3 id="aggregations"><a class="header" href="#aggregations">Aggregations</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const count = await run("ls").lines.count();
const first = await run("ls").lines.first;
</code></pre>
<h2 id="checking-status"><a class="header" href="#checking-status">Checking Status</a></h2>
<p>Consume output before checking status:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const p = run("command");
await p.lines.collect();  // Consume first
const status = await p.status;  // Then check
</code></pre>
<h2 id="error-handling-2"><a class="header" href="#error-handling-2">Error Handling</a></h2>
<p>Errors automatically clean up resources:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  await run("false").lines.collect();
} catch (error) {
  // Resources cleaned up automatically
}
</code></pre>
<h2 id="long-running-processes"><a class="header" href="#long-running-processes">Long-Running Processes</a></h2>
<p>For processes that run indefinitely:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// This is fine - consuming output as it arrives
for await (const line of run("tail", "-f", "log").lines) {
  process(line);
}
</code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<ol>
<li><strong>Always consume output</strong> - Use collect(), forEach(), or iterate</li>
<li><strong>Check status after consuming</strong> - Don't check status first</li>
<li><strong>Let errors propagate</strong> - They clean up automatically</li>
<li><strong>Use try-finally for cleanup</strong> - If you need custom cleanup</li>
</ol>
<h2 id="next-steps-7"><a class="header" href="#next-steps-7">Next Steps</a></h2>
<ul>
<li><a href="core/./error-handling.html">Error Handling</a> - Handle failures</li>
<li><a href="core/./running-processes.html">Running Processes</a> - Process basics</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="understanding-enumerable"><a class="header" href="#understanding-enumerable">Understanding Enumerable</a></h1>
<p>Enumerable is the heart of proc's async iterable magic. It wraps any iterable and gives you Array-like superpowers.</p>
<h2 id="what-is-enumerable"><a class="header" href="#what-is-enumerable">What is Enumerable?</a></h2>
<p>Think of Enumerable as an Array, but for async data. It gives you <code>map</code>, <code>filter</code>, <code>reduce</code>, and more‚Äîbut for data that arrives over time.</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

// Wrap any iterable
const nums = enumerate([1, 2, 3, 4, 5]);

// Use Array methods
const doubled = await nums
  .map(n =&gt; n * 2)
  .filter(n =&gt; n &gt; 5)
  .collect();

console.log(doubled); // [6, 8, 10]
</code></pre>
<h2 id="why-enumerable"><a class="header" href="#why-enumerable">Why Enumerable?</a></h2>
<p>JavaScript has Arrays for sync data and Streams for async data. But Streams are awkward:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Streams are verbose
const stream = readableStream
  .pipeThrough(new TransformStream({
    transform(chunk, controller) {
      controller.enqueue(chunk * 2);
    }
  }))
  .pipeThrough(new TransformStream({
    transform(chunk, controller) {
      if (chunk &gt; 5) controller.enqueue(chunk);
    }
  }));
</code></pre>
<p>Enumerable makes it simple:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Enumerable is clean
const result = await enumerate(asyncIterable)
  .map(n =&gt; n * 2)
  .filter(n =&gt; n &gt; 5)
  .collect();
</code></pre>
<h2 id="creating-enumerables"><a class="header" href="#creating-enumerables">Creating Enumerables</a></h2>
<h3 id="from-arrays"><a class="header" href="#from-arrays">From Arrays</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const nums = enumerate([1, 2, 3]);
</code></pre>
<h3 id="from-async-generators"><a class="header" href="#from-async-generators">From Async Generators</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">async function* generate() {
  yield 1;
  yield 2;
  yield 3;
}

const nums = enumerate(generate());
</code></pre>
<h3 id="from-process-output"><a class="header" href="#from-process-output">From Process Output</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const lines = run("ls", "-la").lines;
// lines is already an Enumerable&lt;string&gt;
</code></pre>
<h3 id="from-files"><a class="header" href="#from-files">From Files</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const bytes = read("file.txt");
// bytes is Enumerable&lt;Uint8Array&gt;

const lines = read("file.txt").lines;
// lines is Enumerable&lt;string&gt;
</code></pre>
<h2 id="consuming-enumerables"><a class="header" href="#consuming-enumerables">Consuming Enumerables</a></h2>
<h3 id="collect-to-array"><a class="header" href="#collect-to-array">Collect to Array</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const array = await enumerate([1, 2, 3]).collect();
// [1, 2, 3]
</code></pre>
<h3 id="iterate-with-for-await"><a class="header" href="#iterate-with-for-await">Iterate with for-await</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">for await (const item of enumerate([1, 2, 3])) {
  console.log(item);
}
</code></pre>
<h3 id="process-each-item"><a class="header" href="#process-each-item">Process Each Item</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await enumerate([1, 2, 3]).forEach(item =&gt; {
  console.log(item);
});
</code></pre>
<h3 id="get-first-or-last"><a class="header" href="#get-first-or-last">Get First or Last</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const first = await enumerate([1, 2, 3]).first;
const last = await enumerate([1, 2, 3]).last;
</code></pre>
<h2 id="lazy-evaluation"><a class="header" href="#lazy-evaluation">Lazy Evaluation</a></h2>
<p>Enumerables are <strong>lazy</strong>‚Äînothing happens until you consume them:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// This doesn't run anything yet
const pipeline = enumerate([1, 2, 3])
  .map(n =&gt; {
    console.log(`Processing ${n}`);
    return n * 2;
  });

// Now it runs
const result = await pipeline.collect();
// Logs: Processing 1, Processing 2, Processing 3
</code></pre>
<p>This is powerful for large datasets:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Processes one line at a time, never loads entire file
for await (const line of read("huge-file.txt").lines) {
  process(line);
}
</code></pre>
<h2 id="chaining-operations"><a class="header" href="#chaining-operations">Chaining Operations</a></h2>
<p>Chain as many operations as you want:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const result = await enumerate([1, 2, 3, 4, 5])
  .map(n =&gt; n * 2)        // [2, 4, 6, 8, 10]
  .filter(n =&gt; n &gt; 5)     // [6, 8, 10]
  .map(n =&gt; n.toString()) // ["6", "8", "10"]
  .collect();
</code></pre>
<p>Each operation returns a new Enumerable, so you can keep chaining.</p>
<h2 id="type-safety-1"><a class="header" href="#type-safety-1">Type Safety</a></h2>
<p>Enumerable is fully typed:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const nums: Enumerable&lt;number&gt; = enumerate([1, 2, 3]);

const strings: Enumerable&lt;string&gt; = nums.map(n =&gt; n.toString());
//    ^-- TypeScript knows this is Enumerable&lt;string&gt;

const result: string[] = await strings.collect();
//    ^-- TypeScript knows this is string[]
</code></pre>
<p>Your IDE will guide you with autocomplete and type errors.</p>
<h2 id="common-patterns-3"><a class="header" href="#common-patterns-3">Common Patterns</a></h2>
<h3 id="transform-and-collect"><a class="header" href="#transform-and-collect">Transform and Collect</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const result = await enumerate(data)
  .map(transform)
  .collect();
</code></pre>
<h3 id="filter-and-count"><a class="header" href="#filter-and-count">Filter and Count</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const count = await enumerate(data)
  .filter(predicate)
  .count();
</code></pre>
<h3 id="find-first-match"><a class="header" href="#find-first-match">Find First Match</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const match = await enumerate(data)
  .find(predicate);
</code></pre>
<h3 id="check-if-anyall"><a class="header" href="#check-if-anyall">Check if Any/All</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const hasMatch = await enumerate(data).some(predicate);
const allMatch = await enumerate(data).every(predicate);
</code></pre>
<h2 id="performance"><a class="header" href="#performance">Performance</a></h2>
<p>Enumerable is:</p>
<ul>
<li><strong>Streaming</strong> - Processes one item at a time</li>
<li><strong>Lazy</strong> - Only runs when consumed</li>
<li><strong>Memory efficient</strong> - Doesn't load everything at once</li>
<li><strong>Fast</strong> - Minimal overhead</li>
</ul>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// This processes a 10GB file using constant memory
await read("huge-file.txt")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .forEach(console.log);
</code></pre>
<h2 id="enumerable-vs-array"><a class="header" href="#enumerable-vs-array">Enumerable vs Array</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Array</th><th>Enumerable</th></tr></thead><tbody>
<tr><td>Data</td><td>Sync</td><td>Async</td></tr>
<tr><td>Memory</td><td>All in memory</td><td>Streaming</td></tr>
<tr><td>Size</td><td>Limited by RAM</td><td>Unlimited</td></tr>
<tr><td>Methods</td><td>map, filter, etc.</td><td>map, filter, etc.</td></tr>
<tr><td>Lazy</td><td>No</td><td>Yes</td></tr>
</tbody></table>
</div>
<p>Use Arrays for small, sync data. Use Enumerable for large, async data.</p>
<h2 id="caching-iterables"><a class="header" href="#caching-iterables">Caching Iterables</a></h2>
<p>Sometimes you need to reuse an iterable's results. Use <code>cache()</code> to store results for replay:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { cache, enumerate } from "jsr:@j50n/proc@0.23.3";

const expensive = enumerate(data)
  .map(expensiveOperation);

const cached = cache(expensive);

// First time - runs the operations
const result1 = await cached.collect();

// Second time - uses cached results, doesn't re-run
const result2 = await cached.collect();
</code></pre>
<p><strong>Use cases:</strong></p>
<ul>
<li>Reuse expensive computations</li>
<li>Replay iterables multiple times</li>
<li>Share results across operations</li>
</ul>
<p><strong>Warning:</strong> Caching stores all results in memory. Only cache when:</p>
<ul>
<li>The dataset is small enough to fit in memory</li>
<li>You need to iterate multiple times</li>
<li>The computation is expensive enough to justify memory usage</li>
</ul>
<h2 id="writable-iterables"><a class="header" href="#writable-iterables">Writable Iterables</a></h2>
<p>Create async iterables you can write to programmatically:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { WritableIterable } from "jsr:@j50n/proc@0.23.3";

const writable = new WritableIterable&lt;string&gt;();

// Write to it
await writable.write("item1");
await writable.write("item2");
await writable.write("item3");
await writable.close();

// Read from it
const items = await writable.collect();
// ["item1", "item2", "item3"]
</code></pre>
<p><strong>Use cases:</strong></p>
<ul>
<li>Generate data programmatically</li>
<li>Bridge between push and pull models</li>
<li>Create custom data sources</li>
<li>Implement producer-consumer patterns</li>
</ul>
<p><strong>Example: Event-driven data:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const events = new WritableIterable&lt;Event&gt;();

// Producer: write events as they occur
eventEmitter.on("data", async (event) =&gt; {
  await events.write(event);
});

eventEmitter.on("end", async () =&gt; {
  await events.close();
});

// Consumer: process events as they arrive
for await (const event of events) {
  processEvent(event);
}
</code></pre>
<h2 id="next-steps-8"><a class="header" href="#next-steps-8">Next Steps</a></h2>
<ul>
<li><a href="iterables/./array-methods.html">Array-Like Methods</a> - All the methods available</li>
<li><a href="iterables/./transformations.html">Transformations</a> - map, flatMap, transform</li>
<li><a href="iterables/./aggregations.html">Aggregations</a> - reduce, count, sum</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="array-like-methods"><a class="header" href="#array-like-methods">Array-Like Methods</a></h1>
<p>Enumerable gives you the Array methods you know and love, but for async data.</p>
<h2 id="transformations"><a class="header" href="#transformations">Transformations</a></h2>
<h3 id="map"><a class="header" href="#map">map()</a></h3>
<p>Transform each item:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const doubled = await enumerate([1, 2, 3])
  .map(n =&gt; n * 2)
  .collect();
// [2, 4, 6]
</code></pre>
<p>Works with async functions:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const results = await enumerate(urls)
  .map(async (url) =&gt; {
    const response = await fetch(url);
    return response.json();
  })
  .collect();
</code></pre>
<h3 id="filter"><a class="header" href="#filter">filter()</a></h3>
<p>Keep only items that match:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const evens = await enumerate([1, 2, 3, 4])
  .filter(n =&gt; n % 2 === 0)
  .collect();
// [2, 4]
</code></pre>
<h3 id="flatmap"><a class="header" href="#flatmap">flatMap()</a></h3>
<p>Map and flatten in one step:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "array-methods: flatMap" -->
<pre><code class="language-typescript">const words = await enumerate(["hello world", "foo bar"])
  .flatMap(line =&gt; line.split(" "))
  .collect();
// ["hello", "world", "foo", "bar"]
</code></pre>
<h2 id="aggregations-1"><a class="header" href="#aggregations-1">Aggregations</a></h2>
<h3 id="reduce"><a class="header" href="#reduce">reduce()</a></h3>
<p>Combine items into a single value:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const sum = await enumerate([1, 2, 3, 4])
  .reduce((acc, n) =&gt; acc + n, 0);
// 10
</code></pre>
<p>Build complex objects:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const grouped = await enumerate(items)
  .reduce((acc, item) =&gt; {
    acc[item.category] = acc[item.category] || [];
    acc[item.category].push(item);
    return acc;
  }, {});
</code></pre>
<h3 id="count"><a class="header" href="#count">count()</a></h3>
<p>Count items:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "array-methods: count" -->
<pre><code class="language-typescript">const total = await enumerate([1, 2, 3]).count();
// 3
</code></pre>
<h3 id="some"><a class="header" href="#some">some()</a></h3>
<p>Check if any item matches:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "array-methods: some" -->
<pre><code class="language-typescript">const hasError = await enumerate(lines)
  .some(line =&gt; line.includes("ERROR"));
</code></pre>
<h3 id="every"><a class="header" href="#every">every()</a></h3>
<p>Check if all items match:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "array-methods: every" -->
<pre><code class="language-typescript">const allPositive = await enumerate([1, 2, 3])
  .every(n =&gt; n &gt; 0);
</code></pre>
<h2 id="finding-items"><a class="header" href="#finding-items">Finding Items</a></h2>
<h3 id="find"><a class="header" href="#find">find()</a></h3>
<p>Find first match:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "array-methods: find" -->
<pre><code class="language-typescript">const match = await enumerate([1, 2, 3, 4])
  .find(n =&gt; n &gt; 2);
// 3
</code></pre>
<h3 id="first"><a class="header" href="#first">first</a></h3>
<p>Get first item:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const first = await enumerate([1, 2, 3]).first;
// 1
</code></pre>
<h3 id="last"><a class="header" href="#last">last</a></h3>
<p>Get last item:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const last = await enumerate([1, 2, 3]).last;
// 3
</code></pre>
<h3 id="nth"><a class="header" href="#nth">nth()</a></h3>
<p>Get item at index:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const third = await enumerate([1, 2, 3, 4]).nth(2);
// 3 (zero-indexed)
</code></pre>
<h2 id="slicing"><a class="header" href="#slicing">Slicing</a></h2>
<h3 id="take"><a class="header" href="#take">take()</a></h3>
<p>Take first N items:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const first3 = await enumerate([1, 2, 3, 4, 5])
  .take(3)
  .collect();
// [1, 2, 3]
</code></pre>
<h3 id="drop"><a class="header" href="#drop">drop()</a></h3>
<p>Skip first N items:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const rest = await enumerate([1, 2, 3, 4, 5])
  .drop(2)
  .collect();
// [3, 4, 5]
</code></pre>
<h3 id="slice"><a class="header" href="#slice">slice()</a></h3>
<p>Get a range:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const middle = await enumerate([1, 2, 3, 4, 5])
  .slice(1, 4)
  .collect();
// [2, 3, 4]
</code></pre>
<h2 id="iteration"><a class="header" href="#iteration">Iteration</a></h2>
<h3 id="foreach-1"><a class="header" href="#foreach-1">forEach()</a></h3>
<p>Process each item:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await enumerate([1, 2, 3]).forEach(n =&gt; {
  console.log(n);
});
</code></pre>
<h3 id="for-await-1"><a class="header" href="#for-await-1">for-await</a></h3>
<p>Use standard JavaScript iteration:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">for await (const item of enumerate([1, 2, 3])) {
  console.log(item);
}
</code></pre>
<h2 id="collecting"><a class="header" href="#collecting">Collecting</a></h2>
<h3 id="collect-1"><a class="header" href="#collect-1">collect()</a></h3>
<p>Gather all items into an array:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const array = await enumerate([1, 2, 3]).collect();
// [1, 2, 3]
</code></pre>
<h3 id="toarray"><a class="header" href="#toarray">toArray()</a></h3>
<p>Alias for collect():</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const array = await enumerate([1, 2, 3]).toArray();
</code></pre>
<h2 id="utilities"><a class="header" href="#utilities">Utilities</a></h2>
<h3 id="enum"><a class="header" href="#enum">enum()</a></h3>
<p>Add indices to items:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const indexed = await enumerate(["a", "b", "c"])
  .enum()
  .collect();
// [["a", 0], ["b", 1], ["c", 2]]
</code></pre>
<p>Use with map:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const numbered = await enumerate(["a", "b", "c"])
  .enum()
  .map(([item, i]) =&gt; `${i + 1}. ${item}`)
  .collect();
// ["1. a", "2. b", "3. c"]
</code></pre>
<h3 id="tee"><a class="header" href="#tee">tee()</a></h3>
<p>Split into multiple streams:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const [stream1, stream2] = enumerate([1, 2, 3]).tee();

const [sum, product] = await Promise.all([
  stream1.reduce((a, b) =&gt; a + b, 0),
  stream2.reduce((a, b) =&gt; a * b, 1),
]);
</code></pre>
<h3 id="flatten"><a class="header" href="#flatten">flatten()</a></h3>
<p>Flatten nested iterables:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const flat = await enumerate([[1, 2], [3, 4]])
  .flatten()
  .collect();
// [1, 2, 3, 4]
</code></pre>
<h2 id="concurrent-operations"><a class="header" href="#concurrent-operations">Concurrent Operations</a></h2>
<h3 id="concurrentmap"><a class="header" href="#concurrentmap">concurrentMap()</a></h3>
<p>Map with controlled concurrency:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const results = await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    return await fetch(url);
  }, { concurrency: 5 })
  .collect();
</code></pre>
<p>Results are returned in order.</p>
<h3 id="concurrentunorderedmap"><a class="header" href="#concurrentunorderedmap">concurrentUnorderedMap()</a></h3>
<p>Map with maximum concurrency:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const results = await enumerate(urls)
  .concurrentUnorderedMap(async (url) =&gt; {
    return await fetch(url);
  }, { concurrency: 5 })
  .collect();
</code></pre>
<p>Results are returned as they complete (faster).</p>
<h2 id="chaining-examples"><a class="header" href="#chaining-examples">Chaining Examples</a></h2>
<h3 id="complex-pipeline"><a class="header" href="#complex-pipeline">Complex Pipeline</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const result = await enumerate(data)
  .filter(item =&gt; item.active)
  .map(item =&gt; item.value)
  .filter(value =&gt; value &gt; 0)
  .map(value =&gt; value * 2)
  .take(10)
  .collect();
</code></pre>
<h3 id="real-world-example"><a class="header" href="#real-world-example">Real-World Example</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const topErrors = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .map(line =&gt; {
    const match = line.match(/ERROR: (.+)/);
    return match ? match[1] : line;
  })
  .reduce((acc, error) =&gt; {
    acc[error] = (acc[error] || 0) + 1;
    return acc;
  }, {});
</code></pre>
<h2 id="performance-tips-1"><a class="header" href="#performance-tips-1">Performance Tips</a></h2>
<h3 id="use-streaming"><a class="header" href="#use-streaming">Use Streaming</a></h3>
<p>Don't collect if you don't need to:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Loads everything
const items = await enumerate(huge).collect();
for (const item of items) process(item);

// ‚úÖ Streams
for await (const item of enumerate(huge)) {
  process(item);
}
</code></pre>
<h3 id="use-take-for-limits"><a class="header" href="#use-take-for-limits">Use take() for Limits</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Get first 10 matches
const matches = await enumerate(data)
  .filter(predicate)
  .take(10)
  .collect();
</code></pre>
<h3 id="use-concurrentmap-for-io"><a class="header" href="#use-concurrentmap-for-io">Use concurrentMap() for I/O</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Process 5 URLs at a time
const results = await enumerate(urls)
  .concurrentMap(fetch, { concurrency: 5 })
  .collect();
</code></pre>
<h2 id="next-steps-9"><a class="header" href="#next-steps-9">Next Steps</a></h2>
<ul>
<li><a href="iterables/./transformations.html">Transformations</a> - Deep dive into map, flatMap, transform</li>
<li><a href="iterables/./aggregations.html">Aggregations</a> - Deep dive into reduce, count, sum</li>
<li><a href="iterables/./slicing.html">Slicing and Sampling</a> - Deep dive into take, drop, slice</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="transformations-1"><a class="header" href="#transformations-1">Transformations</a></h1>
<p>Change data as it flows through your pipeline.</p>
<h2 id="map-1"><a class="header" href="#map-1">map()</a></h2>
<p>Transform each item:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const doubled = await enumerate([1, 2, 3])
  .map(n =&gt; n * 2)
  .collect();
// [2, 4, 6]
</code></pre>
<h3 id="with-async-functions"><a class="header" href="#with-async-functions">With Async Functions</a></h3>
<!-- TESTED: tests/mdbook_examples.test.ts - "transformations: map with async" -->
<pre><code class="language-typescript">const results = await enumerate(urls)
  .map(async (url) =&gt; {
    const response = await fetch(url);
    return response.json();
  })
  .collect();
</code></pre>
<h3 id="type-transformations"><a class="header" href="#type-transformations">Type Transformations</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const strings = await enumerate([1, 2, 3])
  .map(n =&gt; n.toString())
  .collect();
// ["1", "2", "3"]
</code></pre>
<h3 id="complex-transformations"><a class="header" href="#complex-transformations">Complex Transformations</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const processed = await enumerate(rawData)
  .map(item =&gt; ({
    id: item.id,
    name: item.name.toUpperCase(),
    value: parseFloat(item.value),
    timestamp: new Date(item.timestamp)
  }))
  .collect();
</code></pre>
<h2 id="flatmap-1"><a class="header" href="#flatmap-1">flatMap()</a></h2>
<p>Map and flatten in one step:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const words = await enumerate(["hello world", "foo bar"])
  .flatMap(line =&gt; line.split(" "))
  .collect();
// ["hello", "world", "foo", "bar"]
</code></pre>
<h3 id="expanding-items"><a class="header" href="#expanding-items">Expanding Items</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const expanded = await enumerate([1, 2, 3])
  .flatMap(n =&gt; [n, n * 10])
  .collect();
// [1, 10, 2, 20, 3, 30]
</code></pre>
<h3 id="filtering-while-mapping"><a class="header" href="#filtering-while-mapping">Filtering While Mapping</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const valid = await enumerate(data)
  .flatMap(item =&gt; {
    if (item.valid) {
      return [item.value];
    }
    return [];  // Skip invalid items
  })
  .collect();
</code></pre>
<h2 id="filter-1"><a class="header" href="#filter-1">filter()</a></h2>
<p>Keep only matching items:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const evens = await enumerate([1, 2, 3, 4, 5])
  .filter(n =&gt; n % 2 === 0)
  .collect();
// [2, 4]
</code></pre>
<h3 id="complex-predicates"><a class="header" href="#complex-predicates">Complex Predicates</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const active = await enumerate(users)
  .filter(user =&gt; 
    user.active &amp;&amp; 
    user.lastLogin &gt; cutoffDate &amp;&amp;
    user.role !== "guest"
  )
  .collect();
</code></pre>
<h3 id="with-type-guards"><a class="header" href="#with-type-guards">With Type Guards</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const numbers = await enumerate(mixed)
  .filter((item): item is number =&gt; typeof item === "number")
  .collect();
</code></pre>
<h2 id="transform"><a class="header" href="#transform">transform()</a></h2>
<p>Apply a TransformStream:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const decompressed = await read("file.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .collect();
</code></pre>
<h3 id="custom-transform"><a class="header" href="#custom-transform">Custom Transform</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const transformed = await enumerate(data)
  .transform(new TransformStream({
    transform(chunk, controller) {
      controller.enqueue(chunk.toUpperCase());
    }
  }))
  .collect();
</code></pre>
<h2 id="chaining-transformations"><a class="header" href="#chaining-transformations">Chaining Transformations</a></h2>
<p>Combine multiple transformations:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const result = await enumerate(data)
  .map(item =&gt; item.trim())
  .filter(item =&gt; item.length &gt; 0)
  .map(item =&gt; item.toUpperCase())
  .filter(item =&gt; item.startsWith("A"))
  .collect();
</code></pre>
<h2 id="real-world-examples-2"><a class="header" href="#real-world-examples-2">Real-World Examples</a></h2>
<h3 id="parse-csv"><a class="header" href="#parse-csv">Parse CSV</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const data = await read("data.csv")
  .lines
  .drop(1)  // Skip header
  .map(line =&gt; line.split(","))
  .map(([name, age, city]) =&gt; ({
    name,
    age: parseInt(age),
    city
  }))
  .filter(row =&gt; row.age &gt;= 18)
  .collect();
</code></pre>
<h3 id="extract-urls"><a class="header" href="#extract-urls">Extract URLs</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const urls = await read("page.html")
  .lines
  .flatMap(line =&gt; {
    const matches = line.match(/https?:\/\/[^\s"']+/g);
    return matches || [];
  })
  .collect();
</code></pre>
<h3 id="clean-data"><a class="header" href="#clean-data">Clean Data</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const cleaned = await enumerate(rawData)
  .map(item =&gt; item.trim())
  .filter(item =&gt; item.length &gt; 0)
  .map(item =&gt; item.toLowerCase())
  .filter(item =&gt; !item.startsWith("#"))
  .collect();
</code></pre>
<h3 id="transform-json-lines"><a class="header" href="#transform-json-lines">Transform JSON Lines</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const objects = await read("data.jsonl")
  .lines
  .map(line =&gt; JSON.parse(line))
  .filter(obj =&gt; obj.status === "active")
  .map(obj =&gt; ({
    id: obj.id,
    name: obj.name,
    value: obj.value * 1.1  // Apply 10% increase
  }))
  .collect();
</code></pre>
<h2 id="performance-tips-2"><a class="header" href="#performance-tips-2">Performance Tips</a></h2>
<h3 id="lazy-evaluation-1"><a class="header" href="#lazy-evaluation-1">Lazy Evaluation</a></h3>
<p>Transformations don't run until you consume:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Nothing happens yet
const pipeline = enumerate(data)
  .map(expensive)
  .filter(predicate);

// Now it runs
const result = await pipeline.collect();
</code></pre>
<h3 id="early-filtering"><a class="header" href="#early-filtering">Early Filtering</a></h3>
<p>Filter before expensive operations:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚úÖ Filter first
const result = await enumerate(data)
  .filter(cheap)      // Fast filter
  .map(expensive)     // Expensive operation
  .collect();

// ‚ùå Map first
const result = await enumerate(data)
  .map(expensive)     // Runs on everything
  .filter(cheap)      // Then filters
  .collect();
</code></pre>
<h3 id="use-take-to-limit"><a class="header" href="#use-take-to-limit">Use take() to Limit</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Stop after 10 matches
const first10 = await enumerate(huge)
  .filter(predicate)
  .take(10)
  .collect();
</code></pre>
<h2 id="common-patterns-4"><a class="header" href="#common-patterns-4">Common Patterns</a></h2>
<h3 id="normalize-data"><a class="header" href="#normalize-data">Normalize Data</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const normalized = await enumerate(data)
  .map(item =&gt; ({
    ...item,
    name: item.name.trim().toLowerCase(),
    email: item.email.toLowerCase(),
    phone: item.phone.replace(/\D/g, "")
  }))
  .collect();
</code></pre>
<h3 id="extract-fields-1"><a class="header" href="#extract-fields-1">Extract Fields</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const names = await enumerate(users)
  .map(user =&gt; user.name)
  .collect();
</code></pre>
<h3 id="conditional-transform"><a class="header" href="#conditional-transform">Conditional Transform</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const processed = await enumerate(items)
  .map(item =&gt; {
    if (item.type === "A") {
      return processTypeA(item);
    } else {
      return processTypeB(item);
    }
  })
  .collect();
</code></pre>
<h3 id="batch-transform"><a class="header" href="#batch-transform">Batch Transform</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const batched = await enumerate(items)
  .map((item, i) =&gt; ({
    ...item,
    batch: Math.floor(i / 100)
  }))
  .collect();
</code></pre>
<h2 id="error-handling-3"><a class="header" href="#error-handling-3">Error Handling</a></h2>
<p>Errors in transformations propagate:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  await enumerate(data)
    .map(item =&gt; {
      if (!item.valid) {
        throw new Error(`Invalid item: ${item.id}`);
      }
      return item.value;
    })
    .collect();
} catch (error) {
  console.error(`Transform failed: ${error.message}`);
}
</code></pre>
<h2 id="next-steps-10"><a class="header" href="#next-steps-10">Next Steps</a></h2>
<ul>
<li><a href="iterables/./aggregations.html">Aggregations</a> - Combine items into single values</li>
<li><a href="iterables/./array-methods.html">Array-Like Methods</a> - All available methods</li>
<li><a href="iterables/../advanced/concurrent.html">Concurrent Processing</a> - Transform in parallel</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="custom-transformations"><a class="header" href="#custom-transformations">Custom Transformations</a></h1>
<p>Build powerful data transformations with async generators‚Äîthe readable, maintainable way.</p>
<h2 id="why-async-generators"><a class="header" href="#why-async-generators">Why Async Generators?</a></h2>
<p>When you need custom transformations beyond <code>map()</code> and <code>filter()</code>, you have two choices: async generators or <code>TransformStream</code>. <strong>Async generators are almost always better.</strong></p>
<p>Compare these approaches for parsing JSON lines:</p>
<p><strong>Async Generator:</strong></p>
<pre><code class="language-typescript">async function* parseJsonLines(lines: AsyncIterable&lt;string&gt;) {
  for await (const line of lines) {
    try {
      const obj = JSON.parse(line.trim());
      if (obj.id &amp;&amp; obj.timestamp) {
        yield obj;
      }
    } catch {
      // Skip invalid JSON
    }
  }
}
</code></pre>
<p><strong>TransformStream:</strong></p>
<pre><code class="language-typescript">const parseJsonLines = new TransformStream({
  transform(chunk, controller) {
    try {
      const obj = JSON.parse(chunk.trim());
      if (obj.id &amp;&amp; obj.timestamp) {
        controller.enqueue(obj);
      }
    } catch {
      // Error handling is more complex
    }
  }
});
</code></pre>
<p>The generator reads like the logic you're implementing. The stream forces you into callbacks.</p>
<h2 id="batching-data"><a class="header" href="#batching-data">Batching Data</a></h2>
<p>Group items into fixed-size chunks:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "custom-transformations: batching" -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc";

async function* batch&lt;T&gt;(items: AsyncIterable&lt;T&gt;, size: number) {
  let batch: T[] = [];
  for await (const item of items) {
    batch.push(item);
    if (batch.length === size) {
      yield batch;
      batch = [];
    }
  }
  if (batch.length &gt; 0) yield batch;
}

const batches = await enumerate([1, 2, 3, 4, 5, 6, 7])
  .transform(items =&gt; batch(items, 3))
  .collect();

console.log(batches); // [[1, 2, 3], [4, 5, 6], [7]]
</code></pre>
<h2 id="stateful-processing"><a class="header" href="#stateful-processing">Stateful Processing</a></h2>
<p>Keep running calculations as data flows:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "custom-transformations: running-average" -->
<pre><code class="language-typescript">async function* runningAverage(numbers: AsyncIterable&lt;number&gt;) {
  let sum = 0;
  let count = 0;
  
  for await (const num of numbers) {
    sum += num;
    count++;
    yield sum / count;
  }
}

const averages = await enumerate([10, 20, 30, 40])
  .transform(runningAverage)
  .collect();

console.log(averages); // [10, 15, 20, 25]
</code></pre>
<p>State variables live naturally in the function scope‚Äîno external state management needed.</p>
<h2 id="parsing-with-error-recovery"><a class="header" href="#parsing-with-error-recovery">Parsing with Error Recovery</a></h2>
<p>Handle complex parsing gracefully:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "custom-transformations: parse-json-lines" -->
<pre><code class="language-typescript">interface LogEntry {
  id: string;
  timestamp: string;
  level: string;
  message: string;
}

async function* parseJsonLines(lines: AsyncIterable&lt;string&gt;) {
  for await (const line of lines) {
    const trimmed = line.trim();
    if (!trimmed) continue;
    
    try {
      const obj = JSON.parse(trimmed);
      if (obj.id &amp;&amp; obj.timestamp &amp;&amp; obj.level &amp;&amp; obj.message) {
        yield obj as LogEntry;
      }
    } catch {
      // Skip invalid JSON, could log errors here
    }
  }
}

const logs = await enumerate([
  '{"id":"1","timestamp":"2024-01-01","level":"info","message":"Started"}',
  'invalid json line',
  '{"id":"2","timestamp":"2024-01-01","level":"error","message":"Failed"}',
  ''
]).transform(parseJsonLines).collect();

console.log(logs.length); // 2 (invalid lines skipped)
</code></pre>
<h2 id="rate-limiting"><a class="header" href="#rate-limiting">Rate Limiting</a></h2>
<p>Control timing between items:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "custom-transformations: throttle" -->
<pre><code class="language-typescript">import { enumerate, sleep } from "jsr:@j50n/proc";

async function* throttle&lt;T&gt;(items: AsyncIterable&lt;T&gt;, delayMs: number) {
  let first = true;
  
  for await (const item of items) {
    if (!first) {
      await sleep(delayMs);
    }
    first = false;
    yield item;
  }
}

// Rate-limit API calls
const results = await enumerate(["url1", "url2", "url3"])
  .transform(urls =&gt; throttle(urls, 1000))
  .map(async (url) =&gt; {
    const response = await fetch(url);
    return response.status;
  })
  .collect();
</code></pre>
<h2 id="multi-stage-processing"><a class="header" href="#multi-stage-processing">Multi-Stage Processing</a></h2>
<p>Combine filtering, enrichment, and transformation:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "custom-transformations: multi-stage" -->
<pre><code class="language-typescript">async function* processLogEntries(lines: AsyncIterable&lt;string&gt;) {
  for await (const line of lines) {
    try {
      const entry = JSON.parse(line);
      
      if (entry.level !== 'error') continue;
      
      const enriched = {
        ...entry,
        processedAt: new Date().toISOString(),
        severity: entry.message.toLowerCase().includes('critical') ? 'high' : 'medium'
      };
      
      yield {
        timestamp: enriched.timestamp,
        severity: enriched.severity,
        summary: enriched.message.substring(0, 100)
      };
      
    } catch {
      // Skip invalid entries
    }
  }
}

const processed = await enumerate([
  '{"level":"info","message":"System started","timestamp":"2024-01-01T10:00:00Z"}',
  '{"level":"error","message":"Critical database failure","timestamp":"2024-01-01T10:01:00Z"}',
  '{"level":"error","message":"Minor timeout","timestamp":"2024-01-01T10:02:00Z"}'
]).transform(processLogEntries).collect();

console.log(processed.length); // 2 (only error entries)
</code></pre>
<h2 id="generator-vs-transformstream"><a class="header" href="#generator-vs-transformstream">Generator vs TransformStream</a></h2>
<p>The same batching logic, both ways:</p>
<p><strong>Generator (8 lines):</strong></p>
<pre><code class="language-typescript">async function* batch&lt;T&gt;(items: AsyncIterable&lt;T&gt;, size: number) {
  let batch: T[] = [];
  for await (const item of items) {
    batch.push(item);
    if (batch.length === size) {
      yield batch;
      batch = [];
    }
  }
  if (batch.length &gt; 0) yield batch;
}
</code></pre>
<p><strong>TransformStream (15+ lines):</strong></p>
<pre><code class="language-typescript">function createBatchTransform&lt;T&gt;(size: number) {
  let batch: T[] = [];
  
  return new TransformStream&lt;T, T[]&gt;({
    transform(chunk, controller) {
      batch.push(chunk);
      if (batch.length === size) {
        controller.enqueue([...batch]);
        batch = [];
      }
    },
    flush(controller) {
      if (batch.length &gt; 0) {
        controller.enqueue(batch);
      }
    }
  });
}
</code></pre>
<p>Generators are shorter, more readable, easier to debug, and handle errors naturally with try-catch.</p>
<h2 id="when-to-use-each"><a class="header" href="#when-to-use-each">When to Use Each</a></h2>
<p><strong>Use Async Generators for:</strong></p>
<ul>
<li>Complex state management (faster + easier)</li>
<li>Error handling and recovery</li>
<li>Multi-stage processing</li>
<li>Readable, maintainable code</li>
<li>Most custom transformations</li>
</ul>
<p><strong>Use TransformStream for:</strong></p>
<ul>
<li>Simple 1:1 transformations (much faster)</li>
<li>Built-in streams (<code>CompressionStream</code>, <code>DecompressionStream</code>)</li>
<li>Interfacing with existing stream APIs</li>
</ul>
<p><strong>In practice:</strong></p>
<pre><code class="language-typescript">// Built-in streams - use directly
.transform(new CompressionStream("gzip"))

// Custom logic - use generators
.transform(items =&gt; batch(items, 100))
.transform(parseJsonLines)
</code></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<!-- TESTED: tests/mdbook_examples.test.ts - "custom-transformations: best-practices" -->
<pre><code class="language-typescript">// Good: Clear, focused, well-typed
async function* parseAndValidateUsers(
  lines: AsyncIterable&lt;string&gt;
): AsyncGenerator&lt;User&gt; {
  for await (const line of lines) {
    try {
      const user = JSON.parse(line) as User;
      if (isValidUser(user)) {
        yield user;
      }
    } catch (error) {
      console.warn(`Skipping invalid user data: ${error.message}`);
    }
  }
}
</code></pre>
<ol>
<li><strong>Keep generators focused</strong> - One responsibility per function</li>
<li><strong>Handle errors gracefully</strong> - Use try-catch for parsing/validation</li>
<li><strong>Yield frequently</strong> - Don't buffer unnecessarily</li>
<li><strong>Use meaningful names</strong> - <code>parseJsonLines</code> not <code>transform1</code></li>
<li><strong>Add type annotations</strong> - Help TypeScript help you</li>
</ol>
<h2 id="performance-1"><a class="header" href="#performance-1">Performance</a></h2>
<p>We ran comprehensive benchmarks comparing async generators vs TransformStream across different scenarios:</p>
<p><strong>TransformStream excels at simple operations:</strong></p>
<ul>
<li>Small datasets: Similar performance</li>
<li>Large datasets: Up to 810x faster for simple transformations</li>
<li>JSON parsing: Up to 150x faster</li>
<li><strong>Best for</strong>: Simple 1:1 transformations, especially with large data</li>
</ul>
<p><strong>Async generators excel at complex operations:</strong></p>
<ul>
<li>Stateful processing: 4-6x faster (batching, running totals)</li>
<li>Error handling: 3-4x faster with try-catch</li>
<li>Multi-stage logic: 4x faster for complex processing</li>
<li><strong>Best for</strong>: State management, error recovery, complex logic</li>
</ul>
<p><strong>Recommendation</strong>:</p>
<ul>
<li>Use <strong>TransformStream</strong> for simple operations on large datasets</li>
<li>Use <strong>async generators</strong> for complex logic, state management, or when readability matters</li>
<li>For most real-world transformations (parsing, validation, multi-step processing), generators are both faster and easier to write</li>
</ul>
<p>Start with these patterns and build more sophisticated processing pipelines as needed.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="aggregations-2"><a class="header" href="#aggregations-2">Aggregations</a></h1>
<p>Combine many items into one result.</p>
<h2 id="reduce-1"><a class="header" href="#reduce-1">reduce()</a></h2>
<p>The Swiss Army knife of aggregations:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "enumerable: reduce" -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const sum = await enumerate([1, 2, 3, 4])
  .reduce((acc, n) =&gt; acc + n, 0);
// 10
</code></pre>
<h3 id="how-it-works-2"><a class="header" href="#how-it-works-2">How It Works</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Start with initial value: 0
// Step 1: 0 + 1 = 1
// Step 2: 1 + 2 = 3
// Step 3: 3 + 3 = 6
// Step 4: 6 + 4 = 10
</code></pre>
<h3 id="building-objects"><a class="header" href="#building-objects">Building Objects</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const grouped = await enumerate(items)
  .reduce((acc, item) =&gt; {
    const key = item.category;
    acc[key] = acc[key] || [];
    acc[key].push(item);
    return acc;
  }, {});
</code></pre>
<h3 id="calculating-statistics"><a class="header" href="#calculating-statistics">Calculating Statistics</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const stats = await enumerate(numbers)
  .reduce((acc, n) =&gt; ({
    sum: acc.sum + n,
    count: acc.count + 1,
    min: Math.min(acc.min, n),
    max: Math.max(acc.max, n)
  }), { sum: 0, count: 0, min: Infinity, max: -Infinity });

const average = stats.sum / stats.count;
</code></pre>
<h2 id="count-1"><a class="header" href="#count-1">count()</a></h2>
<p>Count items:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const total = await enumerate([1, 2, 3, 4, 5]).count();
// 5
</code></pre>
<h3 id="count-matches"><a class="header" href="#count-matches">Count Matches</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const errorCount = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .count();
</code></pre>
<h2 id="some-1"><a class="header" href="#some-1">some()</a></h2>
<p>Check if any item matches:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const hasError = await enumerate(lines)
  .some(line =&gt; line.includes("ERROR"));
// true or false
</code></pre>
<h3 id="early-exit"><a class="header" href="#early-exit">Early Exit</a></h3>
<p>Stops as soon as it finds a match:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Stops reading after first match
const hasLargeFile = await enumerate(files)
  .some(file =&gt; file.size &gt; 1_000_000_000);
</code></pre>
<h2 id="every-1"><a class="header" href="#every-1">every()</a></h2>
<p>Check if all items match:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const allPositive = await enumerate([1, 2, 3, 4])
  .every(n =&gt; n &gt; 0);
// true
</code></pre>
<h3 id="validation"><a class="header" href="#validation">Validation</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const allValid = await enumerate(records)
  .every(record =&gt; 
    record.name &amp;&amp; 
    record.email &amp;&amp; 
    record.age &gt;= 0
  );
</code></pre>
<h2 id="find-1"><a class="header" href="#find-1">find()</a></h2>
<p>Find first matching item:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const firstError = await enumerate(lines)
  .find(line =&gt; line.includes("ERROR"));
// First line with ERROR, or undefined
</code></pre>
<h3 id="with-complex-predicate"><a class="header" href="#with-complex-predicate">With Complex Predicate</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const admin = await enumerate(users)
  .find(user =&gt; 
    user.role === "admin" &amp;&amp; 
    user.active
  );
</code></pre>
<h2 id="real-world-examples-3"><a class="header" href="#real-world-examples-3">Real-World Examples</a></h2>
<h3 id="sum-values"><a class="header" href="#sum-values">Sum Values</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const total = await enumerate(orders)
  .map(order =&gt; order.amount)
  .reduce((sum, amount) =&gt; sum + amount, 0);
</code></pre>
<h3 id="count-by-category"><a class="header" href="#count-by-category">Count by Category</a></h3>
<!-- TESTED: tests/mdbook_examples.test.ts - "aggregations: build object" -->
<pre><code class="language-typescript">const counts = await enumerate(items)
  .reduce((acc, item) =&gt; {
    acc[item.category] = (acc[item.category] || 0) + 1;
    return acc;
  }, {});
</code></pre>
<h3 id="find-maximum"><a class="header" href="#find-maximum">Find Maximum</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const max = await enumerate(numbers)
  .reduce((max, n) =&gt; Math.max(max, n), -Infinity);
</code></pre>
<h3 id="build-index"><a class="header" href="#build-index">Build Index</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const index = await enumerate(items)
  .reduce((acc, item) =&gt; {
    acc[item.id] = item;
    return acc;
  }, {});
</code></pre>
<h3 id="concatenate-strings"><a class="header" href="#concatenate-strings">Concatenate Strings</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const combined = await enumerate(words)
  .reduce((acc, word) =&gt; acc + " " + word, "");
</code></pre>
<h3 id="collect-unique-values"><a class="header" href="#collect-unique-values">Collect Unique Values</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const unique = await enumerate(items)
  .reduce((acc, item) =&gt; {
    acc.add(item);
    return acc;
  }, new Set());
</code></pre>
<h2 id="advanced-patterns"><a class="header" href="#advanced-patterns">Advanced Patterns</a></h2>
<h3 id="running-average"><a class="header" href="#running-average">Running Average</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const runningAvg = await enumerate(numbers)
  .reduce((acc, n) =&gt; {
    acc.sum += n;
    acc.count += 1;
    acc.average = acc.sum / acc.count;
    return acc;
  }, { sum: 0, count: 0, average: 0 });
</code></pre>
<h3 id="nested-grouping"><a class="header" href="#nested-grouping">Nested Grouping</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const grouped = await enumerate(items)
  .reduce((acc, item) =&gt; {
    const cat = item.category;
    const type = item.type;
    
    acc[cat] = acc[cat] || {};
    acc[cat][type] = acc[cat][type] || [];
    acc[cat][type].push(item);
    
    return acc;
  }, {});
</code></pre>
<h3 id="frequency-map"><a class="header" href="#frequency-map">Frequency Map</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const frequency = await enumerate(words)
  .reduce((acc, word) =&gt; {
    acc[word] = (acc[word] || 0) + 1;
    return acc;
  }, {});

// Find most common
const mostCommon = Object.entries(frequency)
  .sort((a, b) =&gt; b[1] - a[1])[0];
</code></pre>
<h3 id="accumulate-with-transform"><a class="header" href="#accumulate-with-transform">Accumulate with Transform</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const processed = await enumerate(data)
  .reduce((acc, item) =&gt; {
    const transformed = transform(item);
    if (transformed.valid) {
      acc.push(transformed);
    }
    return acc;
  }, []);
</code></pre>
<h2 id="performance-tips-3"><a class="header" href="#performance-tips-3">Performance Tips</a></h2>
<h3 id="use-specific-methods"><a class="header" href="#use-specific-methods">Use Specific Methods</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Slower
const count = await enumerate(items)
  .reduce((acc) =&gt; acc + 1, 0);

// ‚úÖ Faster
const count = await enumerate(items).count();
</code></pre>
<h3 id="early-exit-with-someevery"><a class="header" href="#early-exit-with-someevery">Early Exit with some/every</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Stops at first match
const hasMatch = await enumerate(huge)
  .some(predicate);

// Better than
const matches = await enumerate(huge)
  .filter(predicate)
  .count();
</code></pre>
<h3 id="combine-operations"><a class="header" href="#combine-operations">Combine Operations</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚úÖ One pass
const stats = await enumerate(numbers)
  .reduce((acc, n) =&gt; ({
    sum: acc.sum + n,
    count: acc.count + 1
  }), { sum: 0, count: 0 });

// ‚ùå Two passes
const sum = await enumerate(numbers).reduce((a, b) =&gt; a + b, 0);
const count = await enumerate(numbers).count();
</code></pre>
<h2 id="common-mistakes"><a class="header" href="#common-mistakes">Common Mistakes</a></h2>
<h3 id="forgetting-initial-value"><a class="header" href="#forgetting-initial-value">Forgetting Initial Value</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Error with empty array
const sum = await enumerate([]).reduce((a, b) =&gt; a + b);

// ‚úÖ Works with empty array
const sum = await enumerate([]).reduce((a, b) =&gt; a + b, 0);
</code></pre>
<h3 id="not-returning-accumulator"><a class="header" href="#not-returning-accumulator">Not Returning Accumulator</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Returns undefined
const result = await enumerate(items)
  .reduce((acc, item) =&gt; {
    acc.push(item);
    // Missing return!
  }, []);

// ‚úÖ Returns accumulator
const result = await enumerate(items)
  .reduce((acc, item) =&gt; {
    acc.push(item);
    return acc;
  }, []);
</code></pre>
<h2 id="next-steps-11"><a class="header" href="#next-steps-11">Next Steps</a></h2>
<ul>
<li><a href="iterables/./transformations.html">Transformations</a> - Transform items</li>
<li><a href="iterables/./array-methods.html">Array-Like Methods</a> - All available methods</li>
<li><a href="iterables/../advanced/streaming.html">Streaming Large Files</a> - Aggregate huge datasets</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="slicing-and-sampling"><a class="header" href="#slicing-and-sampling">Slicing and Sampling</a></h1>
<p>Take portions of your data stream.</p>
<h2 id="take-1"><a class="header" href="#take-1">take()</a></h2>
<p>Take first N items:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "slicing: take" -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const first3 = await enumerate([1, 2, 3, 4, 5])
  .take(3)
  .collect();
// [1, 2, 3]
</code></pre>
<h3 id="early-exit-1"><a class="header" href="#early-exit-1">Early Exit</a></h3>
<p>Stops reading after N items:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Only reads first 10 lines
const preview = await read("huge-file.txt")
  .lines
  .take(10)
  .collect();
</code></pre>
<h3 id="with-filter"><a class="header" href="#with-filter">With Filter</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// First 5 errors
const errors = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .take(5)
  .collect();
</code></pre>
<h2 id="drop-1"><a class="header" href="#drop-1">drop()</a></h2>
<p>Skip first N items:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "slicing: drop" -->
<pre><code class="language-typescript">const rest = await enumerate([1, 2, 3, 4, 5])
  .drop(2)
  .collect();
// [3, 4, 5]
</code></pre>
<h3 id="skip-header"><a class="header" href="#skip-header">Skip Header</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const data = await read("data.csv")
  .lines
  .drop(1)  // Skip header row
  .collect();
</code></pre>
<h2 id="combining-drop-and-take"><a class="header" href="#combining-drop-and-take">Combining drop() and take()</a></h2>
<p>Get a range of items by combining drop and take:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "slicing: slice with drop and take" -->
<pre><code class="language-typescript">const middle = await enumerate([1, 2, 3, 4, 5])
  .drop(1)
  .take(3)
  .collect();
// [2, 3, 4]
</code></pre>
<h3 id="pagination"><a class="header" href="#pagination">Pagination</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const page = 2;
const pageSize = 10;

const items = await enumerate(allItems)
  .drop(page * pageSize)
  .take(pageSize)
  .collect();
</code></pre>
<h2 id="first-1"><a class="header" href="#first-1">first</a></h2>
<p>Get first item:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const first = await enumerate([1, 2, 3]).first;
// 1
</code></pre>
<h3 id="with-pipeline"><a class="header" href="#with-pipeline">With Pipeline</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const result = await run("ls", "-la")
  .lines
  .first;
</code></pre>
<h2 id="last-1"><a class="header" href="#last-1">last</a></h2>
<p>Get last item:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const last = await enumerate([1, 2, 3]).last;
// 3
</code></pre>
<p><strong>Note:</strong> Reads entire stream to find last item.</p>
<h2 id="nth-1"><a class="header" href="#nth-1">nth()</a></h2>
<p>Get item at index:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const third = await enumerate([1, 2, 3, 4, 5]).nth(2);
// 3 (zero-indexed)
</code></pre>
<h2 id="real-world-examples-4"><a class="header" href="#real-world-examples-4">Real-World Examples</a></h2>
<h3 id="preview-file"><a class="header" href="#preview-file">Preview File</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">console.log("First 10 lines:");
await read("file.txt")
  .lines
  .take(10)
  .forEach(line =&gt; console.log(line));
</code></pre>
<h3 id="skip-and-take"><a class="header" href="#skip-and-take">Skip and Take</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Lines 11-20
const batch = await read("file.txt")
  .lines
  .drop(10)
  .take(10)
  .collect();
</code></pre>
<h3 id="sample-data"><a class="header" href="#sample-data">Sample Data</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Every 10th item
const sample = await enumerate(data)
  .filter((_, i) =&gt; i % 10 === 0)
  .collect();
</code></pre>
<h3 id="find-nth-match"><a class="header" href="#find-nth-match">Find Nth Match</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// 5th error
const fifthError = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .nth(4);  // Zero-indexed
</code></pre>
<h2 id="performance-tips-4"><a class="header" href="#performance-tips-4">Performance Tips</a></h2>
<h3 id="use-take-for-limits-1"><a class="header" href="#use-take-for-limits-1">Use take() for Limits</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚úÖ Stops early
const first100 = await enumerate(huge)
  .take(100)
  .collect();

// ‚ùå Reads everything
const all = await enumerate(huge).collect();
const first100 = all.slice(0, 100);  // Array slice, not Enumerable
</code></pre>
<h3 id="combine-with-filter"><a class="header" href="#combine-with-filter">Combine with Filter</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Efficient: stops after 10 matches
const matches = await enumerate(data)
  .filter(predicate)
  .take(10)
  .collect();
</code></pre>
<h2 id="next-steps-12"><a class="header" href="#next-steps-12">Next Steps</a></h2>
<ul>
<li><a href="iterables/./array-methods.html">Array-Like Methods</a> - All available methods</li>
<li><a href="iterables/./transformations.html">Transformations</a> - Transform items</li>
<li><a href="iterables/../advanced/streaming.html">Streaming Large Files</a> - Work with huge files</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="concurrent-processing"><a class="header" href="#concurrent-processing">Concurrent Processing</a></h1>
<p>Process multiple items in parallel with controlled concurrency. It's easier than you think.</p>
<h2 id="the-problem-1"><a class="header" href="#the-problem-1">The Problem</a></h2>
<p>You have a list of URLs to fetch. Sequential is slow:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Takes 10 seconds for 10 URLs (1 second each)
for (const url of urls) {
  await fetch(url);
}
</code></pre>
<p>Promise.all is fast but dangerous:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Starts 1000 requests at once - might crash
await Promise.all(urls.map(url =&gt; fetch(url)));
</code></pre>
<h2 id="the-solution"><a class="header" href="#the-solution">The Solution</a></h2>
<p>proc gives you controlled concurrency:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

// Defaults to CPU count (usually 4-8)
const results = await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    return await fetch(url);
  })
  .collect();

// Or specify a limit
const results = await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    return await fetch(url);
  }, { concurrency: 5 })
  .collect();
</code></pre>
<p>Fast, but won't overwhelm your system.</p>
<h2 id="understanding-javascript-concurrency"><a class="header" href="#understanding-javascript-concurrency">Understanding JavaScript Concurrency</a></h2>
<p><strong>Important:</strong> JavaScript concurrency is not parallelism. You're running on a single thread.</p>
<h3 id="what-this-means"><a class="header" href="#what-this-means">What This Means</a></h3>
<p>When you use <code>concurrentMap</code> or <code>concurrentUnorderedMap</code>, you're not creating threads or workers. You're managing multiple <strong>async operations</strong> on one thread. The JavaScript event loop switches between them when they're waiting.</p>
<p><strong>This works great for:</strong></p>
<ul>
<li><strong>Network requests</strong> - While waiting for a response, other operations run</li>
<li><strong>File I/O</strong> - While waiting for disk reads/writes, other operations run</li>
<li><strong>Process execution</strong> - While a child process runs, other operations continue</li>
<li><strong>Database queries</strong> - While waiting for results, other operations run</li>
</ul>
<p><strong>This does NOT work for:</strong></p>
<ul>
<li><strong>CPU-intensive calculations</strong> - Pure JavaScript math, parsing, etc. blocks everything</li>
<li><strong>Synchronous operations</strong> - Anything that doesn't <code>await</code> blocks the thread</li>
<li><strong>Heavy computation</strong> - You still only have one CPU core's worth of processing power</li>
</ul>
<h3 id="example-what-works"><a class="header" href="#example-what-works">Example: What Works</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚úÖ Good: I/O-bound operations run concurrently
const results = await enumerate(urls)
  .concurrentUnorderedMap(async (url) =&gt; {
    // While waiting for fetch, other URLs are being fetched
    const response = await fetch(url);
    return response.json();
  })
  .collect();
// This is genuinely faster - 10 URLs in ~1 second instead of ~10 seconds
</code></pre>
<h3 id="example-what-doesnt-work"><a class="header" href="#example-what-doesnt-work">Example: What Doesn't Work</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Bad: CPU-bound operations don't benefit
const results = await enumerate(numbers)
  .concurrentUnorderedMap(async (n) =&gt; {
    // This blocks the thread - no other operations can run
    let result = 0;
    for (let i = 0; i &lt; 1000000; i++) {
      result += Math.sqrt(n * i);
    }
    return result;
  })
  .collect();
// This is NOT faster - still uses one CPU core sequentially
</code></pre>
<h3 id="why-it-still-matters"><a class="header" href="#why-it-still-matters">Why It Still Matters</a></h3>
<p>Even though it's not true parallelism, concurrency is incredibly useful:</p>
<ol>
<li><strong>I/O operations dominate</strong> - Most real-world tasks are waiting for network/disk</li>
<li><strong>Child processes run in parallel</strong> - When you <code>run()</code> a command, it uses a separate process</li>
<li><strong>Better resource utilization</strong> - Keep the CPU busy while waiting for I/O</li>
<li><strong>Simpler than threads</strong> - No race conditions, no locks, no shared memory issues</li>
</ol>
<h3 id="when-you-need-true-parallelism"><a class="header" href="#when-you-need-true-parallelism">When You Need True Parallelism</a></h3>
<p>If you need to parallelize CPU-intensive JavaScript code, use:</p>
<ul>
<li><strong>Web Workers</strong> (in browsers)</li>
<li><strong>Worker Threads</strong> (in Node.js/Deno)</li>
<li><strong>Child processes</strong> with <code>run()</code> - each process gets its own CPU</li>
</ul>
<p>But for most tasks (fetching URLs, processing files, running commands), JavaScript's concurrency model is perfect.</p>
<h2 id="when-to-use-concurrent-processing"><a class="header" href="#when-to-use-concurrent-processing">When to Use Concurrent Processing</a></h2>
<p><strong>Use <code>concurrentUnorderedMap()</code> (recommended default) when:</strong></p>
<ul>
<li>Order doesn't matter - you want maximum speed</li>
<li>Processing independent tasks where results can arrive in any order</li>
<li>You'll sort or aggregate results anyway</li>
<li><strong>This is usually what you want</strong> - it keeps all workers busy and delivers results as they complete</li>
<li>Example: Downloading files, processing logs, fetching data you'll aggregate</li>
</ul>
<p><strong>Use <code>concurrentMap()</code> when:</strong></p>
<ul>
<li>You <strong>must</strong> have results in the same order as input</li>
<li>Be aware: can bottleneck on the slowest item in each batch</li>
<li>If work isn't balanced, faster items wait for slower ones</li>
<li>Example: Fetching user profiles where display order must match input order</li>
</ul>
<p><strong>Use sequential processing when:</strong></p>
<ul>
<li>Tasks depend on each other</li>
<li>You must respect strict rate limits</li>
<li>Order is critical and tasks are fast</li>
<li>Example: Database transactions that must happen in sequence</li>
</ul>
<p><strong>Choose concurrency level based on:</strong></p>
<ul>
<li><strong>I/O-bound tasks</strong> (network, disk): Start with 5-10, increase if you have bandwidth (see "Understanding JavaScript Concurrency" above)</li>
<li><strong>CPU-bound tasks</strong>: Won't benefit from concurrency - use Worker Threads or child processes instead</li>
<li><strong>Rate-limited APIs</strong>: Match the rate limit (e.g., 10 requests/second = concurrency 1 with 100ms delays)</li>
<li><strong>Memory constraints</strong>: Lower concurrency if processing large data per task</li>
</ul>
<h2 id="concurrentunorderedmap---recommended"><a class="header" href="#concurrentunorderedmap---recommended">concurrentUnorderedMap() - Recommended</a></h2>
<p>Process items concurrently, return results as they complete (fastest):</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Defaults to CPU count
const results = await enumerate([1, 2, 3, 4, 5])
  .concurrentUnorderedMap(async (n) =&gt; {
    await sleep(Math.random() * 1000);
    return n * 2;
  })
  .collect();
// [6, 2, 10, 4, 8] - order varies, but all workers stay busy
</code></pre>
<p><strong>Why it's faster:</strong> Results are delivered as soon as they're ready. If item 3 finishes before item 1, you get item 3 immediately. No waiting for slower items.</p>
<p><strong>Use when:</strong> You don't care about order (most cases). Better performance under real-world conditions where work isn't perfectly balanced.</p>
<p><strong>Concurrency:</strong> Defaults to <code>navigator.hardwareConcurrency</code> (CPU count). Override with <code>{ concurrency: n }</code> if needed.</p>
<h2 id="concurrentmap---order-preserved"><a class="header" href="#concurrentmap---order-preserved">concurrentMap() - Order Preserved</a></h2>
<p>Process items concurrently, return results in input order:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "concurrent: concurrentMap" -->
<pre><code class="language-typescript">const results = await enumerate([1, 2, 3, 4, 5])
  .concurrentMap(async (n) =&gt; {
    await sleep(Math.random() * 1000);
    return n * 2;
  }, { concurrency: 3 })
  .collect();
// [2, 4, 6, 8, 10] - always in order
</code></pre>
<p><strong>Performance caveat:</strong> If item 1 takes 5 seconds and item 2 takes 1 second, item 2 waits for item 1 before being returned. This can create bottlenecks where fast items wait for slow ones.</p>
<p><strong>Use when:</strong> You specifically need results in the same order as input. Only use if order truly matters for your use case.</p>
<p><strong>Concurrency:</strong> Defaults to CPU count. Override with <code>{ concurrency: n }</code> if needed.</p>
<h2 id="real-world-examples-5"><a class="header" href="#real-world-examples-5">Real-World Examples</a></h2>
<h3 id="fetch-multiple-urls"><a class="header" href="#fetch-multiple-urls">Fetch Multiple URLs</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const urls = [
  "https://api.example.com/1",
  "https://api.example.com/2",
  "https://api.example.com/3",
  // ... 100 more
];

// Uses CPU count by default
const data = await enumerate(urls)
  .concurrentUnorderedMap(async (url) =&gt; {
    const response = await fetch(url);
    return response.json();
  })
  .collect();

// Or limit for rate-limited APIs
const data = await enumerate(urls)
  .concurrentUnorderedMap(async (url) =&gt; {
    const response = await fetch(url);
    return response.json();
  }, { concurrency: 10 })
  .collect();
</code></pre>
<h3 id="process-files-in-parallel"><a class="header" href="#process-files-in-parallel">Process Files in Parallel</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const files = ["log1.txt", "log2.txt", "log3.txt"];

const results = await enumerate(files)
  .concurrentMap(async (file) =&gt; {
    const errors = await read(file)
      .lines
      .filter(line =&gt; line.includes("ERROR"))
      .count();
    return { file, errors };
  })
  .collect();
</code></pre>
<h3 id="download-and-process"><a class="header" href="#download-and-process">Download and Process</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const downloads = await enumerate(imageUrls)
  .concurrentUnorderedMap(async (url) =&gt; {
    const response = await fetch(url);
    const blob = await response.blob();
    return processImage(blob);
  })
  .collect();
</code></pre>
<h2 id="choosing-concurrency"><a class="header" href="#choosing-concurrency">Choosing Concurrency</a></h2>
<p><strong>Default behavior:</strong> Both methods default to <code>navigator.hardwareConcurrency</code> (CPU count, typically 4-8). This is usually a good starting point.</p>
<p><strong>When to override:</strong></p>
<p><strong>For I/O-bound tasks</strong> (network, disk):</p>
<ul>
<li>Default is often fine</li>
<li>Increase to 10-20 if you have bandwidth and no rate limits</li>
<li>Decrease to 1-5 for rate-limited APIs</li>
</ul>
<p><strong>For CPU-bound tasks</strong>:</p>
<ul>
<li>Default (CPU count) is optimal</li>
<li>Don't increase - you'll just add overhead</li>
</ul>
<p><strong>For rate-limited APIs</strong>:</p>
<ul>
<li>Set to match the rate limit</li>
<li>Add delays if needed</li>
</ul>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Respect rate limits with low concurrency
const results = await enumerate(apiCalls)
  .concurrentUnorderedMap(async (call) =&gt; {
    const result = await makeApiCall(call);
    await sleep(100); // 10 requests per second
    return result;
  }, { concurrency: 1 })
  .collect();
</code></pre>
<h2 id="error-handling-4"><a class="header" href="#error-handling-4">Error Handling</a></h2>
<p>Errors propagate naturally:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  const results = await enumerate(urls)
    .concurrentMap(async (url) =&gt; {
      const response = await fetch(url);
      if (!response.ok) {
        throw new Error(`Failed: ${url}`);
      }
      return response.json();
    }, { concurrency: 5 })
    .collect();
} catch (error) {
  // First error stops everything
  console.error(`Failed: ${error.message}`);
}
</code></pre>
<h2 id="progress-tracking"><a class="header" href="#progress-tracking">Progress Tracking</a></h2>
<p>Track progress as items complete:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">let completed = 0;
const total = urls.length;

const results = await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    const result = await fetch(url);
    completed++;
    console.log(`Progress: ${completed}/${total}`);
    return result;
  }, { concurrency: 5 })
  .collect();
</code></pre>
<h2 id="combining-with-other-operations"><a class="header" href="#combining-with-other-operations">Combining with Other Operations</a></h2>
<p>Chain concurrent operations with other methods:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const results = await enumerate(urls)
  .concurrentMap(fetch, { concurrency: 5 })
  .filter(response =&gt; response.ok)
  .concurrentMap(response =&gt; response.json(), { concurrency: 5 })
  .filter(data =&gt; data.active)
  .collect();
</code></pre>
<h2 id="performance-comparison"><a class="header" href="#performance-comparison">Performance Comparison</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Sequential: 10 seconds (one at a time)
for (const url of urls) {
  await fetch(url);
}

// concurrentMap (5): 2-4 seconds
// Can bottleneck if one item is slow - others wait
await enumerate(urls)
  .concurrentMap(fetch, { concurrency: 5 })
  .collect();

// concurrentUnorderedMap (5): 2 seconds
// Faster - no waiting, results delivered as ready
await enumerate(urls)
  .concurrentUnorderedMap(fetch, { concurrency: 5 })
  .collect();
</code></pre>
<p><strong>Why unordered is faster:</strong> Imagine 5 tasks with times [1s, 1s, 1s, 1s, 5s]. With <code>concurrentMap</code>, the 5-second task blocks its batch. With <code>concurrentUnorderedMap</code>, the four 1-second tasks complete and return immediately while the 5-second task finishes in the background.</p>
<h2 id="advanced-patterns-1"><a class="header" href="#advanced-patterns-1">Advanced Patterns</a></h2>
<h3 id="batch-processing"><a class="header" href="#batch-processing">Batch Processing</a></h3>
<p>Process in batches:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const batchSize = 10;
for (let i = 0; i &lt; items.length; i += batchSize) {
  const batch = items.slice(i, i + batchSize);
  const results = await enumerate(batch)
    .concurrentMap(process, { concurrency: 5 })
    .collect();
  await saveBatch(results);
}
</code></pre>
<h3 id="retry-failed-items"><a class="header" href="#retry-failed-items">Retry Failed Items</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const results = await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    let attempts = 0;
    while (attempts &lt; 3) {
      try {
        return await fetch(url);
      } catch (error) {
        attempts++;
        if (attempts === 3) throw error;
        await sleep(1000 * attempts);
      }
    }
  }, { concurrency: 5 })
  .collect();
</code></pre>
<h3 id="dynamic-concurrency"><a class="header" href="#dynamic-concurrency">Dynamic Concurrency</a></h3>
<p>Adjust concurrency based on results:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">let concurrency = 5;

for (const batch of batches) {
  const start = Date.now();
  
  const results = await enumerate(batch)
    .concurrentMap(process, { concurrency })
    .collect();
  
  const duration = Date.now() - start;
  
  // Adjust based on performance
  if (duration &lt; 1000) concurrency = Math.min(concurrency + 1, 20);
  if (duration &gt; 5000) concurrency = Math.max(concurrency - 1, 1);
}
</code></pre>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<ol>
<li><strong>Prefer unordered</strong> - Use <code>concurrentUnorderedMap</code> unless you specifically need order</li>
<li><strong>Start conservative</strong> - Begin with low concurrency, increase if needed</li>
<li><strong>Monitor resources</strong> - Watch memory and network usage</li>
<li><strong>Respect rate limits</strong> - Don't overwhelm external services</li>
<li><strong>Handle errors</strong> - One error stops everything, handle gracefully</li>
<li><strong>Understand the bottleneck</strong> - <code>concurrentMap</code> can wait on slow items; unordered doesn't</li>
</ol>
<h2 id="common-mistakes-1"><a class="header" href="#common-mistakes-1">Common Mistakes</a></h2>
<h3 id="too-much-concurrency"><a class="header" href="#too-much-concurrency">Too Much Concurrency</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Might crash with 10,000 concurrent requests
await enumerate(hugeList)
  .concurrentMap(fetch, { concurrency: 10000 })
  .collect();

// ‚úÖ Reasonable concurrency
await enumerate(hugeList)
  .concurrentMap(fetch, { concurrency: 10 })
  .collect();
</code></pre>
<h3 id="forgetting-to-await"><a class="header" href="#forgetting-to-await">Forgetting to Await</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Returns promises, not results
const promises = enumerate(urls)
  .concurrentMap(fetch, { concurrency: 5 });

// ‚úÖ Await the results
const results = await enumerate(urls)
  .concurrentMap(fetch, { concurrency: 5 })
  .collect();
</code></pre>
<h2 id="next-steps-13"><a class="header" href="#next-steps-13">Next Steps</a></h2>
<ul>
<li><a href="advanced/./streaming.html">Streaming Large Files</a> - Handle huge files efficiently</li>
<li><a href="advanced/./performance.html">Performance Optimization</a> - Make it faster</li>
<li><a href="advanced/../recipes/parallel-downloads.html">Parallel Downloads</a> - Real-world example</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="streaming-large-files"><a class="header" href="#streaming-large-files">Streaming Large Files</a></h1>
<p>Process files bigger than your RAM. It's easier than you think.</p>
<h2 id="when-to-stream-vs-collect"><a class="header" href="#when-to-stream-vs-collect">When to Stream vs Collect</a></h2>
<p><strong>Always stream when:</strong></p>
<ul>
<li>File is larger than available RAM (or even close to it)</li>
<li>You don't need all data at once</li>
<li>Processing can be done incrementally (line-by-line, record-by-record)</li>
<li>You want to start processing immediately without waiting for full download/read</li>
<li>Memory efficiency is important</li>
</ul>
<p><strong>Consider collecting when:</strong></p>
<ul>
<li>File is small (&lt; 100MB) and fits comfortably in memory</li>
<li>You need random access to data</li>
<li>You need to process data multiple times</li>
<li>You need to sort or aggregate all data before processing</li>
<li>Memory is not a concern</li>
</ul>
<p><strong>Memory/Speed Tradeoffs:</strong></p>
<ul>
<li><strong>Streaming</strong>: Constant memory (~64KB buffer), processes as data arrives, can't random access</li>
<li><strong>Collecting</strong>: Memory = file size, all data available immediately, can random access, must wait for full load</li>
</ul>
<p><strong>Example decision:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// 10GB log file - MUST stream
for await (const line of read("huge.log").lines) {
  if (line.includes("ERROR")) console.log(line);
}

// 1MB config file - can collect
const config = await read("config.json").lines.collect();
const parsed = JSON.parse(config.join("\n"));

// 500MB data file - stream if processing once
const sum = await read("numbers.txt")
  .lines
  .map(line =&gt; parseFloat(line))
  .reduce((a, b) =&gt; a + b, 0);
</code></pre>
<h2 id="the-problem-2"><a class="header" href="#the-problem-2">The Problem</a></h2>
<p>You have a 10GB log file. Loading it into memory crashes your program:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Crashes with large files
const content = await Deno.readTextFile("huge.log");
const lines = content.split("\n");
</code></pre>
<h2 id="the-solution-1"><a class="header" href="#the-solution-1">The Solution</a></h2>
<p>Stream it, one line at a time:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

// ‚úÖ Constant memory, any file size
for await (const line of read("huge.log").lines) {
  if (line.includes("ERROR")) {
    console.log(line);
  }
}
</code></pre>
<h2 id="how-streaming-works"><a class="header" href="#how-streaming-works">How Streaming Works</a></h2>
<p>Instead of loading everything:</p>
<ol>
<li>Read a chunk (buffer)</li>
<li>Process it</li>
<li>Discard it</li>
<li>Repeat</li>
</ol>
<p>Memory usage stays constant, no matter how big the file.</p>
<h2 id="real-examples-1"><a class="header" href="#real-examples-1">Real Examples</a></h2>
<h3 id="count-lines-in-huge-file"><a class="header" href="#count-lines-in-huge-file">Count Lines in Huge File</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const count = await read("10gb-file.txt").lines.count();
console.log(`${count} lines`);
</code></pre>
<p>Uses ~constant memory, even for 10GB.</p>
<h3 id="find-pattern-in-large-file"><a class="header" href="#find-pattern-in-large-file">Find Pattern in Large File</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const matches = await read("huge.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .take(10)  // Stop after 10 matches
  .collect();
</code></pre>
<p>Stops reading once it finds 10 matches. Efficient!</p>
<h3 id="process-csv-file"><a class="header" href="#process-csv-file">Process CSV File</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const data = await read("huge-data.csv")
  .lines
  .drop(1)  // Skip header
  .map(line =&gt; {
    const [id, name, value] = line.split(",");
    return { id, name, value: parseFloat(value) };
  })
  .filter(row =&gt; row.value &gt; 100)
  .collect();
</code></pre>
<h3 id="aggregate-large-dataset"><a class="header" href="#aggregate-large-dataset">Aggregate Large Dataset</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const sum = await read("numbers.txt")
  .lines
  .map(line =&gt; parseFloat(line))
  .reduce((acc, n) =&gt; acc + n, 0);
</code></pre>
<h2 id="compressed-files"><a class="header" href="#compressed-files">Compressed Files</a></h2>
<p>Stream compressed files without extracting:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lineCount = await read("huge.log.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .count();
</code></pre>
<p>Decompresses on-the-fly, never stores uncompressed data.</p>
<h2 id="multiple-files"><a class="header" href="#multiple-files">Multiple Files</a></h2>
<p>Process multiple large files:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const files = ["log1.txt", "log2.txt", "log3.txt"];

for (const file of files) {
  const errors = await read(file)
    .lines
    .filter(line =&gt; line.includes("ERROR"))
    .count();
  console.log(`${file}: ${errors} errors`);
}
</code></pre>
<h2 id="streaming-transformations"><a class="header" href="#streaming-transformations">Streaming Transformations</a></h2>
<p>Chain transformations, all streaming:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const result = await read("data.txt")
  .lines
  .map(line =&gt; line.trim())
  .filter(line =&gt; line.length &gt; 0)
  .map(line =&gt; line.toUpperCase())
  .filter(line =&gt; line.startsWith("ERROR"))
  .collect();
</code></pre>
<p>Each line flows through all transformations before the next line is read.</p>
<h2 id="writing-large-files"><a class="header" href="#writing-large-files">Writing Large Files</a></h2>
<p>Stream output to a file:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { concat } from "jsr:@j50n/proc@0.23.3";

const processed = await read("input.txt")
  .lines
  .map(line =&gt; line.toUpperCase())
  .map(line =&gt; new TextEncoder().encode(line + "\n"))
  .collect();

await Deno.writeFile("output.txt", concat(processed));
</code></pre>
<h2 id="performance-tips-5"><a class="header" href="#performance-tips-5">Performance Tips</a></h2>
<h3 id="use-take-for-early-exit"><a class="header" href="#use-take-for-early-exit">Use take() for Early Exit</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Stops reading after 100 matches
const first100 = await read("huge.txt")
  .lines
  .filter(predicate)
  .take(100)
  .collect();
</code></pre>
<h3 id="dont-collect-unless-needed"><a class="header" href="#dont-collect-unless-needed">Don't Collect Unless Needed</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Loads everything into memory
const lines = await read("huge.txt").lines.collect();
for (const line of lines) process(line);

// ‚úÖ Streams
for await (const line of read("huge.txt").lines) {
  process(line);
}
</code></pre>
<h3 id="use-concurrent-processing"><a class="header" href="#use-concurrent-processing">Use Concurrent Processing</a></h3>
<p>Process multiple files in parallel:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const results = await enumerate(files)
  .concurrentMap(async (file) =&gt; {
    return await read(file).lines.count();
  }, { concurrency: 3 })
  .collect();
</code></pre>
<h2 id="memory-usage"><a class="header" href="#memory-usage">Memory Usage</a></h2>
<p>Streaming uses constant memory:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// File size: 10GB
// Memory used: ~64KB (buffer size)
await read("10gb-file.txt")
  .lines
  .forEach(line =&gt; process(line));
</code></pre>
<h2 id="real-world-example-1"><a class="header" href="#real-world-example-1">Real-World Example</a></h2>
<p>Analyze a year of logs:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const errorsByDay = await read("year-of-logs.txt")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .map(line =&gt; {
    const date = line.match(/\d{4}-\d{2}-\d{2}/)?.[0];
    return date;
  })
  .filter(date =&gt; date !== null)
  .reduce((acc, date) =&gt; {
    acc[date] = (acc[date] || 0) + 1;
    return acc;
  }, {});

// Show top 10 error days
Object.entries(errorsByDay)
  .sort((a, b) =&gt; b[1] - a[1])
  .slice(0, 10)
  .forEach(([date, count]) =&gt; {
    console.log(`${date}: ${count} errors`);
  });
</code></pre>
<p>Processes gigabytes of logs with minimal memory.</p>
<h2 id="when-to-stream"><a class="header" href="#when-to-stream">When to Stream</a></h2>
<p><strong>Always stream when:</strong></p>
<ul>
<li>File is larger than available RAM</li>
<li>You don't need all data at once</li>
<li>Processing can be done incrementally</li>
<li>You want to start processing immediately</li>
</ul>
<p><strong>Consider collecting when:</strong></p>
<ul>
<li>File is small (&lt; 100MB)</li>
<li>You need random access</li>
<li>You need to process data multiple times</li>
<li>Memory is not a concern</li>
</ul>
<h2 id="common-patterns-5"><a class="header" href="#common-patterns-5">Common Patterns</a></h2>
<h3 id="filter-and-count-1"><a class="header" href="#filter-and-count-1">Filter and Count</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const count = await read("file.txt")
  .lines
  .filter(predicate)
  .count();
</code></pre>
<h3 id="transform-and-save"><a class="header" href="#transform-and-save">Transform and Save</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const output = await read("input.txt")
  .lines
  .map(transform)
  .map(line =&gt; new TextEncoder().encode(line + "\n"))
  .collect();

await Deno.writeFile("output.txt", concat(output));
</code></pre>
<h3 id="aggregate-data-2"><a class="header" href="#aggregate-data-2">Aggregate Data</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const stats = await read("data.txt")
  .lines
  .reduce((acc, line) =&gt; {
    // Update statistics
    return acc;
  }, initialStats);
</code></pre>
<h2 id="next-steps-14"><a class="header" href="#next-steps-14">Next Steps</a></h2>
<ul>
<li><a href="advanced/./concurrent.html">Concurrent Processing</a> - Process multiple files in parallel</li>
<li><a href="advanced/./performance.html">Performance Optimization</a> - Make it faster</li>
<li><a href="advanced/../recipes/decompression.html">Decompressing Files</a> - Work with compressed files</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="performance-characteristics-1"><a class="header" href="#performance-characteristics-1">Performance Characteristics</a></h1>
<p>Understanding async iteration performance and how proc optimizes for real-world usage.</p>
<h2 id="the-async-iteration-overhead"><a class="header" href="#the-async-iteration-overhead">The Async Iteration Overhead</a></h2>
<p>Async generators create promises per iteration, which adds overhead for simple operations. <strong>This is built into the JavaScript language and V8 engine</strong>, not a limitation of this library:</p>
<pre><code class="language-typescript">// Benchmark: 10,000 items
async function* double(items: AsyncIterable&lt;number&gt;) {
  for await (const item of items) {
    yield item * 2;
  }
}

// Results:
// Async generator: 2.7ms
// TransformStream: 40¬µs (67x faster)
// Raw array iteration: 39¬µs
</code></pre>
<p>The overhead grows with data size - at 100,000 items, the gap becomes 810x. <strong>This is fundamental to how <code>for await</code> loops work in JavaScript</strong>, not an implementation issue.</p>
<blockquote>
<p><strong>Note</strong>: JavaScript engines continue to optimize async iteration. These performance characteristics may improve in future V8 versions.</p>
</blockquote>
<h2 id="the-v8-optimization-cliff"><a class="header" href="#the-v8-optimization-cliff">The V8 Optimization Cliff</a></h2>
<p><strong>TransformStream performance has a dramatic cliff</strong> - it looks extremely fast in microbenchmarks but can become orders of magnitude slower with minimal added complexity.</p>
<p><strong>Simple operations get heavily optimized:</strong></p>
<pre><code class="language-typescript">// V8 can inline this entire pipeline
const doubleStream = new TransformStream({
  transform(chunk, controller) {
    controller.enqueue(chunk * 2); // Becomes nearly native code
  }
});
// Result: 750x faster than generators
</code></pre>
<p><strong>Adding any complexity breaks optimization:</strong></p>
<pre><code class="language-typescript">// Closure state prevents V8 inlining
function createRunningTotalStream() {
  let total = 0; // This breaks optimization
  return new TransformStream({
    transform(chunk, controller) {
      total += chunk;              // Closure access overhead
      controller.enqueue(total);   // Can't optimize with state
    }
  });
}
// Result: 6x slower than generators
</code></pre>
<p><strong>Why this happens:</strong></p>
<ul>
<li>V8 aggressively optimizes trivial TransformStream operations into native code paths</li>
<li>Any closure variables, state dependencies, or complex logic breaks these optimizations</li>
<li>Once optimization fails, the callback overhead makes TransformStream much slower</li>
<li>Generators have consistent overhead regardless of complexity</li>
</ul>
<p><strong>Practical implication:</strong> TransformStream microbenchmarks are misleading - they show best-case performance that disappears in real-world usage.</p>
<p><strong>The bottom line:</strong> JavaScript performance is notoriously difficult to predict. V8's aggressive optimizations can make simple code incredibly fast, but these optimizations are fragile and break easily. If performance truly matters for your use case, profile your actual workload rather than relying on synthetic benchmarks.</p>
<h2 id="the-chunking-solution"><a class="header" href="#the-chunking-solution">The Chunking Solution</a></h2>
<p>proc uses <strong>chunking</strong> to amortize async iteration costs by processing multiple items per iteration:</p>
<pre><code class="language-typescript">// Instead of: 1 promise per line (expensive)
async function* inefficientLines(bytes: AsyncIterable&lt;Uint8Array&gt;) {
  for await (const chunk of bytes) {
    for (const line of decode(chunk).split('\n')) {
      yield line; // 1000 lines = 1000 promises
    }
  }
}

// proc does: 1 promise per chunk of lines (efficient)
export async function* toChunkedLines(bytes: AsyncIterable&lt;Uint8Array&gt;) {
  for await (const chunk of bytes) {
    const lines = decode(chunk).split('\n');
    if (lines.length &gt; 0) {
      yield lines; // 1000 lines in 10 chunks = 10 promises
    }
  }
}

// Then flatten efficiently
async function* toLines(bytes: AsyncIterable&lt;Uint8Array&gt;) {
  for await (const lines of toChunkedLines(bytes)) {
    yield* lines; // Sync iteration within async iteration
  }
}
</code></pre>
<p><strong>Result</strong>: 10x performance improvement for line processing.</p>
<h2 id="when-complexity-flips-performance"><a class="header" href="#when-complexity-flips-performance">When Complexity Flips Performance</a></h2>
<p>For complex operations, async generators become faster because TransformStream's callback model creates overhead:</p>
<pre><code class="language-typescript">// Complex stateful processing
async function* processLogs(lines: AsyncIterable&lt;string&gt;) {
  let errorCount = 0;
  
  for await (const line of lines) {
    try {
      const entry = JSON.parse(line);
      if (entry.level === 'error') {
        errorCount++;
        yield {
          ...entry,
          errorNumber: errorCount,
          severity: entry.message.includes('critical') ? 'high' : 'medium'
        };
      }
    } catch {
      errorCount++;
    }
  }
}

// Benchmark results (10k items):
// Async generator: 3.1ms
// TransformStream: 13.8ms (4x slower)
</code></pre>
<h2 id="practical-implications"><a class="header" href="#practical-implications">Practical Implications</a></h2>
<p><strong>Async generators win for real-world use cases:</strong></p>
<ul>
<li>Parsing and validation (where most errors occur)</li>
<li>Multi-step transformations</li>
<li>State management across items</li>
<li>Error handling and recovery</li>
</ul>
<p><strong>The chunking strategy makes overhead negligible</strong> for typical data processing workloads.</p>
<p><strong>TransformStream is available</strong> for the rare cases where simple, high-volume transformations need maximum performance, but the complexity trade-off usually isn't worth it.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="file-io"><a class="header" href="#file-io">File I/O</a></h1>
<p>Read and write files with streaming efficiency.</p>
<h2 id="reading-files"><a class="header" href="#reading-files">Reading Files</a></h2>
<h3 id="read-as-bytes"><a class="header" href="#read-as-bytes">Read as Bytes</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const bytes = await read("file.bin").collect();
// Uint8Array[]
</code></pre>
<h3 id="read-as-lines"><a class="header" href="#read-as-lines">Read as Lines</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lines = await read("file.txt").lines.collect();
// string[]
</code></pre>
<h3 id="stream-large-files"><a class="header" href="#stream-large-files">Stream Large Files</a></h3>
<p>Process files larger than memory:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">for await (const line of read("huge-file.txt").lines) {
  process(line);  // One line at a time
}
</code></pre>
<h2 id="file-paths"><a class="header" href="#file-paths">File Paths</a></h2>
<h3 id="relative-paths"><a class="header" href="#relative-paths">Relative Paths</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">read("data.txt")  // Relative to current directory
</code></pre>
<h3 id="absolute-paths"><a class="header" href="#absolute-paths">Absolute Paths</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">read("/var/log/app.log")
</code></pre>
<h3 id="urls"><a class="header" href="#urls">URLs</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const path = new URL("./data.txt", import.meta.url);
read(path)
</code></pre>
<h2 id="common-patterns-6"><a class="header" href="#common-patterns-6">Common Patterns</a></h2>
<h3 id="count-lines-1"><a class="header" href="#count-lines-1">Count Lines</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lineCount = await read("file.txt").lines.count();
</code></pre>
<h3 id="find-pattern"><a class="header" href="#find-pattern">Find Pattern</a></h3>
<!-- TESTED: tests/mdbook_examples.test.ts - "file-io: read and filter" -->
<pre><code class="language-typescript">const matches = await read("file.txt")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .collect();
</code></pre>
<h3 id="transform-lines"><a class="header" href="#transform-lines">Transform Lines</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const processed = await read("input.txt")
  .lines
  .map(line =&gt; line.toUpperCase())
  .collect();
</code></pre>
<h3 id="parse-csv-1"><a class="header" href="#parse-csv-1">Parse CSV</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const data = await read("data.csv")
  .lines
  .drop(1)  // Skip header
  .map(line =&gt; {
    const [name, age, city] = line.split(",");
    return { name, age: parseInt(age), city };
  })
  .collect();
</code></pre>
<h2 id="writing-files"><a class="header" href="#writing-files">Writing Files</a></h2>
<h3 id="write-array-to-file"><a class="header" href="#write-array-to-file">Write Array to File</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lines = ["line 1", "line 2", "line 3"];
const content = lines.join("\n");
await Deno.writeTextFile("output.txt", content);
</code></pre>
<h3 id="stream-to-file"><a class="header" href="#stream-to-file">Stream to File</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { concat } from "jsr:@j50n/proc@0.23.3";

const bytes = await read("input.txt")
  .lines
  .map(line =&gt; new TextEncoder().encode(line + "\n"))
  .collect();

await Deno.writeFile("output.txt", concat(bytes));
</code></pre>
<h2 id="working-with-binary-files"><a class="header" href="#working-with-binary-files">Working with Binary Files</a></h2>
<h3 id="read-binary"><a class="header" href="#read-binary">Read Binary</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const bytes = await read("image.png").collect();
const data = concat(bytes);
</code></pre>
<h3 id="process-binary"><a class="header" href="#process-binary">Process Binary</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const processed = await read("data.bin")
  .map(chunk =&gt; {
    // Process each chunk
    return transform(chunk);
  })
  .collect();
</code></pre>
<h2 id="compressed-files-1"><a class="header" href="#compressed-files-1">Compressed Files</a></h2>
<h3 id="read-compressed"><a class="header" href="#read-compressed">Read Compressed</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lines = await read("file.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .collect();
</code></pre>
<p>See <a href="utilities/../recipes/decompression.html">Decompressing Files</a> for more.</p>
<h2 id="multiple-files-1"><a class="header" href="#multiple-files-1">Multiple Files</a></h2>
<h3 id="process-multiple-files"><a class="header" href="#process-multiple-files">Process Multiple Files</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const files = ["log1.txt", "log2.txt", "log3.txt"];

for (const file of files) {
  const errors = await read(file)
    .lines
    .filter(line =&gt; line.includes("ERROR"))
    .count();
  console.log(`${file}: ${errors} errors`);
}
</code></pre>
<h3 id="concurrent-processing-1"><a class="header" href="#concurrent-processing-1">Concurrent Processing</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const results = await enumerate(files)
  .concurrentMap(async (file) =&gt; {
    const lines = await read(file).lines.count();
    return { file, lines };
  }, { concurrency: 3 })
  .collect();
</code></pre>
<h2 id="error-handling-5"><a class="header" href="#error-handling-5">Error Handling</a></h2>
<h3 id="file-not-found"><a class="header" href="#file-not-found">File Not Found</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  const lines = await read("missing.txt").lines.collect();
} catch (error) {
  console.error(`Failed to read file: ${error.message}`);
}
</code></pre>
<h3 id="permission-denied"><a class="header" href="#permission-denied">Permission Denied</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">try {
  const lines = await read("/root/secret.txt").lines.collect();
} catch (error) {
  if (error instanceof Deno.errors.PermissionDenied) {
    console.error("Permission denied");
  }
}
</code></pre>
<h2 id="performance-tips-6"><a class="header" href="#performance-tips-6">Performance Tips</a></h2>
<h3 id="stream-dont-collect"><a class="header" href="#stream-dont-collect">Stream Don't Collect</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Loads entire file into memory
const lines = await read("huge.txt").lines.collect();

// ‚úÖ Processes one line at a time
for await (const line of read("huge.txt").lines) {
  process(line);
}
</code></pre>
<h3 id="use-chunked-lines-for-performance"><a class="header" href="#use-chunked-lines-for-performance">Use Chunked Lines for Performance</a></h3>
<p>For files with many small lines:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const chunks = await read("file.txt").chunkedLines.collect();
// Array of string arrays
</code></pre>
<h2 id="real-world-examples-6"><a class="header" href="#real-world-examples-6">Real-World Examples</a></h2>
<h3 id="log-analysis"><a class="header" href="#log-analysis">Log Analysis</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const errorsByType = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .reduce((acc, line) =&gt; {
    const type = line.match(/ERROR: (\w+)/)?.[1] || "unknown";
    acc[type] = (acc[type] || 0) + 1;
    return acc;
  }, {});
</code></pre>
<h3 id="data-extraction"><a class="header" href="#data-extraction">Data Extraction</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const emails = await read("contacts.txt")
  .lines
  .map(line =&gt; line.match(/[\w.-]+@[\w.-]+\.\w+/))
  .filter(match =&gt; match !== null)
  .map(match =&gt; match[0])
  .collect();
</code></pre>
<h3 id="file-conversion"><a class="header" href="#file-conversion">File Conversion</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const jsonLines = await read("data.csv")
  .lines
  .drop(1)  // Skip header
  .map(line =&gt; {
    const [name, age] = line.split(",");
    return JSON.stringify({ name, age: parseInt(age) });
  })
  .collect();

await Deno.writeTextFile("data.jsonl", jsonLines.join("\n"));
</code></pre>
<h2 id="next-steps-15"><a class="header" href="#next-steps-15">Next Steps</a></h2>
<ul>
<li><a href="utilities/../recipes/decompression.html">Decompressing Files</a> - Work with compressed files</li>
<li><a href="utilities/../advanced/streaming.html">Streaming Large Files</a> - Handle huge files</li>
<li><a href="utilities/../recipes/log-processing.html">Log Processing</a> - Analyze logs</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="range-and-iteration"><a class="header" href="#range-and-iteration">Range and Iteration</a></h1>
<p>Generate sequences of numbers lazily.</p>
<h2 id="basic-range"><a class="header" href="#basic-range">Basic Range</a></h2>
<!-- TESTED: tests/mdbook_examples.test.ts - "range: basic range" -->
<pre><code class="language-typescript">import { range } from "jsr:@j50n/proc@0.23.3";

const numbers = await range({ to: 5 }).collect();
// [0, 1, 2, 3, 4]
</code></pre>
<h2 id="exclusive-vs-inclusive"><a class="header" href="#exclusive-vs-inclusive">Exclusive vs Inclusive</a></h2>
<h3 id="to-exclusive"><a class="header" href="#to-exclusive">to (exclusive)</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const nums = await range({ to: 3 }).collect();
// [0, 1, 2]
</code></pre>
<h3 id="until-inclusive"><a class="header" href="#until-inclusive">until (inclusive)</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const nums = await range({ until: 3 }).collect();
// [0, 1, 2, 3]
</code></pre>
<h2 id="custom-start"><a class="header" href="#custom-start">Custom Start</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const nums = await range({ from: 5, to: 10 }).collect();
// [5, 6, 7, 8, 9]
</code></pre>
<h2 id="custom-step"><a class="header" href="#custom-step">Custom Step</a></h2>
<!-- TESTED: tests/mdbook_examples.test.ts - "range: with step" -->
<pre><code class="language-typescript">const evens = await range({ from: 0, to: 10, step: 2 }).collect();
// [0, 2, 4, 6, 8]
</code></pre>
<h2 id="counting-down"><a class="header" href="#counting-down">Counting Down</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const countdown = await range({ from: 5, to: 0, step: -1 }).collect();
// [5, 4, 3, 2, 1]
</code></pre>
<h2 id="real-world-examples-7"><a class="header" href="#real-world-examples-7">Real-World Examples</a></h2>
<h3 id="repeat-n-times"><a class="header" href="#repeat-n-times">Repeat N Times</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">await range({ to: 10 }).forEach(i =&gt; {
  console.log(`Iteration ${i}`);
});
</code></pre>
<h3 id="generate-test-data"><a class="header" href="#generate-test-data">Generate Test Data</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const users = await range({ to: 100 })
  .map(i =&gt; ({
    id: i,
    name: `User ${i}`,
    email: `user${i}@example.com`
  }))
  .collect();
</code></pre>
<h3 id="batch-processing-1"><a class="header" href="#batch-processing-1">Batch Processing</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const batchSize = 10;
const total = 100;

for await (const batch of range({ from: 0, to: total, step: batchSize })) {
  const items = data.slice(batch, batch + batchSize);
  await processBatch(items);
}
</code></pre>
<h3 id="pagination-1"><a class="header" href="#pagination-1">Pagination</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const pages = Math.ceil(total / pageSize);

for await (const page of range({ to: pages })) {
  const items = await fetchPage(page);
  await processItems(items);
}
</code></pre>
<h3 id="retry-logic"><a class="header" href="#retry-logic">Retry Logic</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">for await (const attempt of range({ to: 3 })) {
  try {
    await operation();
    break;
  } catch (error) {
    if (attempt === 2) throw error;
    await sleep(1000 * (attempt + 1));
  }
}
</code></pre>
<h2 id="infinite-ranges"><a class="header" href="#infinite-ranges">Infinite Ranges</a></h2>
<p><strong>Warning:</strong> Don't collect infinite ranges!</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Never completes
const infinite = await range({ from: 0, to: Infinity }).collect();

// ‚úÖ Use with take()
const first100 = await range({ from: 0, to: Infinity })
  .take(100)
  .collect();
</code></pre>
<h2 id="performance-2"><a class="header" href="#performance-2">Performance</a></h2>
<p>Ranges are lazy‚Äînumbers generated on demand:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Doesn't generate all numbers upfront
const huge = range({ to: 1_000_000_000 });

// Only generates what you use
const first10 = await huge.take(10).collect();
</code></pre>
<h2 id="next-steps-16"><a class="header" href="#next-steps-16">Next Steps</a></h2>
<ul>
<li><a href="utilities/./zip-enumerate.html">Zip and Enumerate</a> - Combine iterables</li>
<li><a href="utilities/../iterables/array-methods.html">Array-Like Methods</a> - Transform ranges</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="zip-and-enumerate"><a class="header" href="#zip-and-enumerate">Zip and Enumerate</a></h1>
<p>Combine and index iterables.</p>
<h2 id="enumerate"><a class="header" href="#enumerate">enumerate()</a></h2>
<p>Wrap any iterable for Array-like methods:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const result = await enumerate([1, 2, 3])
  .map(n =&gt; n * 2)
  .collect();
// [2, 4, 6]
</code></pre>
<h2 id="enum-1"><a class="header" href="#enum-1">.enum()</a></h2>
<p>Add indices to items:</p>
<!-- TESTED: tests/mdbook_examples.test.ts - "zip-enumerate: enum" -->
<pre><code class="language-typescript">const indexed = await enumerate(["a", "b", "c"])
  .enum()
  .collect();
// [["a", 0], ["b", 1], ["c", 2]]
</code></pre>
<h3 id="format-with-indices"><a class="header" href="#format-with-indices">Format with Indices</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const numbered = await enumerate(["apple", "banana", "cherry"])
  .enum()
  .map(([fruit, i]) =&gt; `${i + 1}. ${fruit}`)
  .collect();
// ["1. apple", "2. banana", "3. cherry"]
</code></pre>
<h2 id="zip"><a class="header" href="#zip">zip()</a></h2>
<p>Combine two iterables:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { zip } from "jsr:@j50n/proc@0.23.3";

const names = ["Alice", "Bob", "Charlie"];
const ages = [25, 30, 35];

const people = await zip(names, ages)
  .map(([name, age]) =&gt; ({ name, age }))
  .collect();
// [{ name: "Alice", age: 25 }, ...]
</code></pre>
<h3 id="multiple-iterables"><a class="header" href="#multiple-iterables">Multiple Iterables</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const combined = await zip(iter1, iter2)
  .map(([a, b]) =&gt; a + b)
  .collect();
</code></pre>
<h2 id="real-world-examples-8"><a class="header" href="#real-world-examples-8">Real-World Examples</a></h2>
<h3 id="number-lines"><a class="header" href="#number-lines">Number Lines</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const numbered = await read("file.txt")
  .lines
  .enum()
  .map(([line, i]) =&gt; `${i + 1}: ${line}`)
  .forEach(console.log);
</code></pre>
<h3 id="combine-data-sources"><a class="header" href="#combine-data-sources">Combine Data Sources</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const merged = await zip(
  read("names.txt").lines,
  read("emails.txt").lines
)
  .map(([name, email]) =&gt; ({ name, email }))
  .collect();
</code></pre>
<h3 id="track-progress"><a class="header" href="#track-progress">Track Progress</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const items = [...]; // Large array

await enumerate(items)
  .enum()
  .forEach(([item, i]) =&gt; {
    console.log(`Processing ${i + 1}/${items.length}`);
    process(item);
  });
</code></pre>
<h2 id="next-steps-17"><a class="header" href="#next-steps-17">Next Steps</a></h2>
<ul>
<li><a href="utilities/./range.html">Range and Iteration</a> - Generate sequences</li>
<li><a href="utilities/../iterables/array-methods.html">Array-Like Methods</a> - Transform data</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="writableiterable"><a class="header" href="#writableiterable">WritableIterable</a></h1>
<p><code>WritableIterable</code> is a fascinating utility that inverts the normal data flow: instead of pulling data from an iterable, you push data into it. It bridges the gap between push-based (callbacks, events) and pull-based (async iteration) programming models.</p>
<h2 id="the-problem-it-solves"><a class="header" href="#the-problem-it-solves">The Problem It Solves</a></h2>
<p>Imagine you have a callback-based API (like event emitters, WebSocket messages, or sensor data) and you want to process it with proc's pipeline operations. You can't easily convert callbacks to an AsyncIterable... until now.</p>
<h2 id="how-it-works-3"><a class="header" href="#how-it-works-3">How It Works</a></h2>
<p><code>WritableIterable</code> is both:</p>
<ul>
<li><strong>Writable</strong>: You can <code>.write()</code> items to it</li>
<li><strong>AsyncIterable</strong>: You can iterate over it with <code>for await</code></li>
</ul>
<p>It uses an internal queue to buffer items between the writer and reader, allowing them to operate at different speeds.</p>
<h2 id="basic-usage-1"><a class="header" href="#basic-usage-1">Basic Usage</a></h2>
<!-- TESTED: tests/docs/writable-iterable.test.ts - "WritableIterable - basic write and read" -->
<pre><code class="language-typescript">import { WritableIterable, sleep } from "jsr:@j50n/proc@0.23.3";

const writable = new WritableIterable&lt;number&gt;();

// Write in background (simulating slow producer)
(async () =&gt; {
  await writable.write(1);
  await sleep(100);
  await writable.write(2);
  await sleep(100);
  await writable.write(3);
  await writable.close();
})();

// Read (items arrive as they're written)
const results: number[] = [];
for await (const item of writable) {
  console.log("Received:", item);
  results.push(item);
}

console.log(results); // [1, 2, 3]
</code></pre>
<p>This demonstrates the streaming nature: the reader receives items as they're written, not all at once.</p>
<blockquote>
<p><strong>‚ö†Ô∏è Important</strong>: You MUST call <code>.close()</code> when done writing, or iteration will hang forever waiting for more data.</p>
</blockquote>
<h2 id="key-concepts-1"><a class="header" href="#key-concepts-1">Key Concepts</a></h2>
<h3 id="push-vs-pull"><a class="header" href="#push-vs-pull">Push vs Pull</a></h3>
<p><strong>Traditional AsyncIterable (pull-based)</strong>:</p>
<pre><code class="language-typescript">// Consumer pulls data
for await (const item of iterable) {
  // Process item
}
</code></pre>
<p><strong>WritableIterable (push-based)</strong>:</p>
<pre><code class="language-typescript">// Producer pushes data
await writable.write(item);
</code></pre>
<h3 id="backpressure"><a class="header" href="#backpressure">Backpressure</a></h3>
<p><code>WritableIterable</code> implements automatic backpressure. If the writer is faster than the reader, <code>.write()</code> will pause until the reader catches up. This prevents unbounded memory growth.</p>
<h2 id="real-world-examples-9"><a class="header" href="#real-world-examples-9">Real-World Examples</a></h2>
<h3 id="example-1-event-stream-to-pipeline"><a class="header" href="#example-1-event-stream-to-pipeline">Example 1: Event Stream to Pipeline</a></h3>
<p>Convert DOM events into a processable stream:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { WritableIterable, enumerate } from "jsr:@j50n/proc@0.23.3";

const clicks = new WritableIterable&lt;MouseEvent&gt;();

// Producer: capture clicks
document.addEventListener("click", async (event) =&gt; {
  await clicks.write(event);
});

// Consumer: process clicks
enumerate(clicks)
  .map(event =&gt; ({ x: event.clientX, y: event.clientY }))
  .filter(pos =&gt; pos.x &gt; 100)
  .forEach(pos =&gt; console.log("Click at:", pos));

// Close when done (e.g., on page unload)
window.addEventListener("unload", () =&gt; clicks.close());
</code></pre>
<h3 id="example-2-websocket-to-process"><a class="header" href="#example-2-websocket-to-process">Example 2: WebSocket to Process</a></h3>
<p>Feed WebSocket messages to a process:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { WritableIterable } from "jsr:@j50n/proc@0.23.3";

const messages = new WritableIterable&lt;string&gt;();

// Producer: WebSocket messages
const ws = new WebSocket("wss://example.com");
ws.onmessage = async (event) =&gt; {
  await messages.write(event.data);
};
ws.onclose = () =&gt; messages.close();

// Consumer: pipe to process
await enumerate(messages)
  .run("jq", ".")  // Pretty-print JSON
  .toStdout();
</code></pre>
<h3 id="example-3-sensor-data-stream"><a class="header" href="#example-3-sensor-data-stream">Example 3: Sensor Data Stream</a></h3>
<p>Process sensor readings as they arrive:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { WritableIterable, enumerate } from "jsr:@j50n/proc@0.23.3";

interface SensorReading {
  temperature: number;
  timestamp: number;
}

const readings = new WritableIterable&lt;SensorReading&gt;();

// Producer: sensor callback
sensor.onReading(async (reading) =&gt; {
  await readings.write(reading);
});

// Consumer: calculate moving average
const averages = await enumerate(readings)
  .map(r =&gt; r.temperature)
  .take(100)  // First 100 readings
  .reduce((acc, temp) =&gt; acc + temp, 0)
  .then(sum =&gt; sum / 100);

console.log(`Average: ${averages}¬∞C`);
await readings.close();
</code></pre>
<h3 id="example-4-manual-process-stdin"><a class="header" href="#example-4-manual-process-stdin">Example 4: Manual Process stdin</a></h3>
<p>Feed data to a process programmatically:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { WritableIterable, enumerate } from "jsr:@j50n/proc@0.23.3";

const input = new WritableIterable&lt;string&gt;();

// Producer: generate data
(async () =&gt; {
  for (let i = 0; i &lt; 10; i++) {
    await input.write(`line ${i}`);
  }
  await input.close();
})();

// Consumer: pipe to process
await enumerate(input)
  .run("grep", "5")
  .toStdout();
// Output: line 5
</code></pre>
<h2 id="error-handling-6"><a class="header" href="#error-handling-6">Error Handling</a></h2>
<p>Errors propagate through the iteration:</p>
<!-- TESTED: tests/docs/writable-iterable.test.ts - "WritableIterable - error propagation" -->
<pre><code class="language-typescript">import { WritableIterable } from "jsr:@j50n/proc@0.23.3";

const writable = new WritableIterable&lt;number&gt;();

// Write and close with error
(async () =&gt; {
  await writable.write(1);
  await writable.write(2);
  await writable.close(new Error("something failed"));
})();

try {
  for await (const item of writable) {
    console.log(item);
  }
} catch (error) {
  console.error("Error:", error.message);
}
// Output:
// 1
// 2
// Error: something failed
</code></pre>
<h2 id="cleanup-with-onclose"><a class="header" href="#cleanup-with-onclose">Cleanup with onclose</a></h2>
<p>You can provide a cleanup callback:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { WritableIterable } from "jsr:@j50n/proc@0.23.3";

const writable = new WritableIterable&lt;string&gt;({
  onclose: async () =&gt; {
    console.log("Cleaning up resources...");
    // Close connections, files, etc.
  }
});

await writable.write("data");
await writable.close();
// Output: Cleaning up resources...
</code></pre>
<h2 id="api-reference"><a class="header" href="#api-reference">API Reference</a></h2>
<h3 id="constructor"><a class="header" href="#constructor">Constructor</a></h3>
<pre><code class="language-typescript">new WritableIterable&lt;T&gt;(options?: { onclose?: () =&gt; void | Promise&lt;void&gt; })
</code></pre>
<ul>
<li><code>options.onclose</code>: Optional callback invoked when <code>.close()</code> is called</li>
</ul>
<h3 id="methods"><a class="header" href="#methods">Methods</a></h3>
<p><strong><code>.write(item: T): Promise&lt;void&gt;</code></strong></p>
<ul>
<li>Write an item to the stream</li>
<li>Throws if already closed</li>
<li>Implements backpressure (pauses if reader is slow)</li>
</ul>
<p><strong><code>.close(error?: Error): Promise&lt;void&gt;</code></strong></p>
<ul>
<li>Close the stream</li>
<li>Must be called to end iteration</li>
<li>Safe to call multiple times</li>
<li>Optional error propagates to reader</li>
</ul>
<h3 id="properties"><a class="header" href="#properties">Properties</a></h3>
<p><strong><code>.isClosed: boolean</code></strong></p>
<ul>
<li>Returns <code>true</code> if <code>.close()</code> has been called</li>
</ul>
<h2 id="common-patterns-7"><a class="header" href="#common-patterns-7">Common Patterns</a></h2>
<h3 id="pattern-timed-data-generation"><a class="header" href="#pattern-timed-data-generation">Pattern: Timed Data Generation</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const timed = new WritableIterable&lt;number&gt;();

(async () =&gt; {
  for (let i = 0; i &lt; 5; i++) {
    await timed.write(i);
    await new Promise(resolve =&gt; setTimeout(resolve, 1000));
  }
  await timed.close();
})();

for await (const item of timed) {
  console.log(item); // Prints 0, 1, 2, 3, 4 (one per second)
}
</code></pre>
<h3 id="pattern-conditional-close"><a class="header" href="#pattern-conditional-close">Pattern: Conditional Close</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const conditional = new WritableIterable&lt;number&gt;();

(async () =&gt; {
  for (let i = 0; i &lt; 100; i++) {
    await conditional.write(i);
    if (i === 10) {
      await conditional.close(); // Stop early
      break;
    }
  }
})();

const items = await enumerate(conditional).collect();
console.log(items.length); // 11 (0 through 10)
</code></pre>
<h2 id="when-to-use-writableiterable"><a class="header" href="#when-to-use-writableiterable">When to Use WritableIterable</a></h2>
<p><strong>Use it when:</strong></p>
<ul>
<li>Converting callback-based APIs to AsyncIterable</li>
<li>Feeding data to process stdin programmatically</li>
<li>Bridging event-driven and stream-based code</li>
<li>You need backpressure between producer and consumer</li>
</ul>
<p><strong>Don't use it when:</strong></p>
<ul>
<li>You already have an AsyncIterable (use <code>enumerate()</code> instead)</li>
<li>You're working with synchronous data (use arrays)</li>
<li>You need multi-consumer support (WritableIterable is single-consumer)</li>
</ul>
<h2 id="performance-notes"><a class="header" href="#performance-notes">Performance Notes</a></h2>
<ul>
<li>Internal queue grows if writer is faster than reader</li>
<li>Backpressure prevents unbounded growth</li>
<li>Each <code>.write()</code> creates a Promise (small overhead)</li>
<li>Best for moderate data rates (not millions of items/second)</li>
</ul>
<h2 id="comparison-with-other-approaches"><a class="header" href="#comparison-with-other-approaches">Comparison with Other Approaches</a></h2>
<h3 id="vs-array"><a class="header" href="#vs-array">vs. Array</a></h3>
<pre><code class="language-typescript">// Array: all data in memory
const data = [1, 2, 3];
for (const item of data) { }

// WritableIterable: streaming, backpressure
const writable = new WritableIterable&lt;number&gt;();
for await (const item of writable) { }
</code></pre>
<h3 id="vs-transformstream"><a class="header" href="#vs-transformstream">vs. TransformStream</a></h3>
<pre><code class="language-typescript">// TransformStream: byte-oriented, Web Streams API
const { readable, writable } = new TransformStream();

// WritableIterable: value-oriented, AsyncIterable
const writable = new WritableIterable&lt;T&gt;();
</code></pre>
<h3 id="vs-channel-from-other-languages"><a class="header" href="#vs-channel-from-other-languages">vs. Channel (from other languages)</a></h3>
<p>If you're familiar with Go channels or Rust channels, <code>WritableIterable</code> is similar but:</p>
<ul>
<li>Single-consumer (not multi-consumer)</li>
<li>Unbuffered by default (backpressure on every write)</li>
<li>Integrates with AsyncIterable ecosystem</li>
</ul>
<h2 id="the-interesting-little-beast"><a class="header" href="#the-interesting-little-beast">The "Interesting Little Beast"</a></h2>
<p>What makes <code>WritableIterable</code> interesting:</p>
<ol>
<li><strong>Inverted Control</strong>: Most iterables pull data; this one receives pushes</li>
<li><strong>Backpressure</strong>: Automatically slows down fast producers</li>
<li><strong>Bridge Pattern</strong>: Connects imperative (callbacks) to declarative (iteration)</li>
<li><strong>Error Propagation</strong>: Errors flow naturally through the iteration</li>
<li><strong>Simple API</strong>: Just <code>.write()</code>, <code>.close()</code>, and iterate</li>
</ol>
<p>It's a small utility that solves a specific problem elegantly: turning push-based data sources into pull-based async iterables that work seamlessly with proc's pipeline operations.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sleep"><a class="header" href="#sleep">Sleep</a></h1>
<p>The <code>sleep</code> function pauses execution for a specified duration. While it might seem like an outlier in a process management library, it's surprisingly useful when working with async pipelines, rate limiting, and testing.</p>
<h2 id="basic-usage-2"><a class="header" href="#basic-usage-2">Basic Usage</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { sleep } from "jsr:@j50n/proc@0.23.3";

console.log("Starting...");
await sleep(2000);  // Pause for 2 seconds
console.log("Done!");
</code></pre>
<h2 id="why-its-included"><a class="header" href="#why-its-included">Why It's Included</a></h2>
<p>When working with processes and async iterables, you often need to:</p>
<ul>
<li>Rate limit operations</li>
<li>Add delays between retries</li>
<li>Simulate slow data sources for testing</li>
<li>Throttle concurrent operations</li>
<li>Add breathing room for external services</li>
</ul>
<p>Having <code>sleep</code> built-in means you don't need to import it from another library or write the <code>setTimeout</code> wrapper yourself.</p>
<h2 id="common-use-cases"><a class="header" href="#common-use-cases">Common Use Cases</a></h2>
<h3 id="rate-limiting-api-calls"><a class="header" href="#rate-limiting-api-calls">Rate Limiting API Calls</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate, sleep } from "jsr:@j50n/proc@0.23.3";

const urls = ["url1", "url2", "url3"];

await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    const response = await fetch(url);
    await sleep(1000);  // Wait 1 second between requests
    return response.json();
  }, { concurrency: 1 })
  .forEach(data =&gt; console.log(data));
</code></pre>
<h3 id="retry-with-backoff"><a class="header" href="#retry-with-backoff">Retry with Backoff</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run, sleep } from "jsr:@j50n/proc@0.23.3";

async function runWithRetry(maxRetries = 3) {
  for (let i = 0; i &lt; maxRetries; i++) {
    try {
      return await run("flaky-command").lines.collect();
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      
      const delay = Math.pow(2, i) * 1000;  // Exponential backoff
      console.log(`Retry ${i + 1} after ${delay}ms...`);
      await sleep(delay);
    }
  }
}
</code></pre>
<h3 id="simulating-slow-data-sources"><a class="header" href="#simulating-slow-data-sources">Simulating Slow Data Sources</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { WritableIterable, sleep } from "jsr:@j50n/proc@0.23.3";

const slowData = new WritableIterable&lt;number&gt;();

// Simulate data arriving slowly
(async () =&gt; {
  for (let i = 0; i &lt; 10; i++) {
    await slowData.write(i);
    await sleep(500);  // 500ms between items
  }
  await slowData.close();
})();

for await (const item of slowData) {
  console.log("Received:", item);
}
</code></pre>
<h3 id="throttling-process-output"><a class="header" href="#throttling-process-output">Throttling Process Output</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run, sleep } from "jsr:@j50n/proc@0.23.3";

// Process lines slowly to avoid overwhelming downstream
await run("cat", "large-file.txt")
  .lines
  .map(async (line) =&gt; {
    await sleep(10);  // 10ms delay per line
    return line;
  })
  .toStdout();
</code></pre>
<h3 id="testing-concurrent-operations"><a class="header" href="#testing-concurrent-operations">Testing Concurrent Operations</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate, sleep } from "jsr:@j50n/proc@0.23.3";

// Verify concurrency limit works correctly
const startTimes: number[] = [];

await enumerate([1, 2, 3, 4, 5])
  .concurrentMap(async (n) =&gt; {
    startTimes.push(Date.now());
    await sleep(100);  // Simulate work
    return n;
  }, { concurrency: 2 })
  .collect();

// Analyze timing to verify only 2 ran concurrently
</code></pre>
<h2 id="time-constants"><a class="header" href="#time-constants">Time Constants</a></h2>
<p>The library also provides time constants for readability:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { sleep, SECONDS, MINUTES } from "jsr:@j50n/proc@0.23.3";

await sleep(5 * SECONDS);   // 5 seconds
await sleep(2 * MINUTES);   // 2 minutes
</code></pre>
<p>Available constants:</p>
<ul>
<li><code>SECONDS</code> = 1000 milliseconds</li>
<li><code>MINUTES</code> = 60 seconds</li>
<li><code>HOURS</code> = 60 minutes</li>
<li><code>DAYS</code> = 24 hours</li>
<li><code>WEEKS</code> = 7 days</li>
</ul>
<h2 id="api"><a class="header" href="#api">API</a></h2>
<pre><code class="language-typescript">function sleep(delayms: number): Promise&lt;void&gt;
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>delayms</code>: Delay in milliseconds</li>
</ul>
<p><strong>Returns:</strong></p>
<ul>
<li>Promise that resolves after the specified delay</li>
</ul>
<h2 id="notes"><a class="header" href="#notes">Notes</a></h2>
<ul>
<li>Uses <code>setTimeout</code> internally</li>
<li>Non-blocking (other async operations can run)</li>
<li>Minimum delay depends on JavaScript runtime (typically ~4ms)</li>
<li>For precise timing, consider using <code>performance.now()</code> to measure actual elapsed time</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="counting-words"><a class="header" href="#counting-words">Counting Words</a></h1>
<p>A classic example that shows the power of process pipelines.</p>
<h2 id="simple-word-count"><a class="header" href="#simple-word-count">Simple Word Count</a></h2>
<p>Count total words in a file:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";

const wordCount = await run("wc", "-w", "book.txt").lines.first;
console.log(`Total words: ${wordCount}`);
</code></pre>
<h2 id="unique-words"><a class="header" href="#unique-words">Unique Words</a></h2>
<p>Count unique words:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const uniqueWords = await run("cat", "book.txt")
  .run("tr", "-cs", "A-Za-z", "\n")  // Extract words
  .run("tr", "A-Z", "a-z")            // Lowercase
  .run("sort")                         // Sort
  .run("uniq")                         // Unique
  .lines
  .count();

console.log(`Unique words: ${uniqueWords}`);
</code></pre>
<h2 id="word-frequency"><a class="header" href="#word-frequency">Word Frequency</a></h2>
<p>Find most common words:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const topWords = await run("cat", "book.txt")
  .run("tr", "-cs", "A-Za-z", "\n")
  .run("tr", "A-Z", "a-z")
  .run("sort")
  .run("uniq", "-c")
  .run("sort", "-rn")
  .run("head", "-10")
  .lines
  .collect();

console.log("Top 10 words:");
topWords.forEach(line =&gt; console.log(line));
</code></pre>
<h2 id="pure-javascript-version"><a class="header" href="#pure-javascript-version">Pure JavaScript Version</a></h2>
<p>Do it all in JavaScript:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const wordCounts = await read("book.txt")
  .lines
  .flatMap(line =&gt; line.toLowerCase().match(/\w+/g) || [])
  .reduce((acc, word) =&gt; {
    acc[word] = (acc[word] || 0) + 1;
    return acc;
  }, {});

const topWords = Object.entries(wordCounts)
  .sort((a, b) =&gt; b[1] - a[1])
  .slice(0, 10);

console.log("Top 10 words:");
topWords.forEach(([word, count]) =&gt; {
  console.log(`${count} ${word}`);
});
</code></pre>
<h2 id="compressed-files-2"><a class="header" href="#compressed-files-2">Compressed Files</a></h2>
<p>Count words in a compressed file:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const wordCount = await read("book.txt.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .flatMap(line =&gt; line.match(/\w+/g) || [])
  .count();

console.log(`Total words: ${wordCount}`);
</code></pre>
<h2 id="multiple-files-2"><a class="header" href="#multiple-files-2">Multiple Files</a></h2>
<p>Count words across multiple files:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const files = ["book1.txt", "book2.txt", "book3.txt"];

const results = await enumerate(files)
  .concurrentMap(async (file) =&gt; {
    const words = await read(file)
      .lines
      .flatMap(line =&gt; line.match(/\w+/g) || [])
      .count();
    return { file, words };
  }, { concurrency: 3 })
  .collect();

results.forEach(({ file, words }) =&gt; {
  console.log(`${file}: ${words} words`);
});
</code></pre>
<h2 id="filter-stop-words"><a class="header" href="#filter-stop-words">Filter Stop Words</a></h2>
<p>Exclude common words:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const stopWords = new Set([
  "the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for"
]);

const meaningfulWords = await read("book.txt")
  .lines
  .flatMap(line =&gt; line.toLowerCase().match(/\w+/g) || [])
  .filter(word =&gt; !stopWords.has(word))
  .reduce((acc, word) =&gt; {
    acc[word] = (acc[word] || 0) + 1;
    return acc;
  }, {});
</code></pre>
<h2 id="word-length-distribution"><a class="header" href="#word-length-distribution">Word Length Distribution</a></h2>
<p>Analyze word lengths:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const lengthDist = await read("book.txt")
  .lines
  .flatMap(line =&gt; line.match(/\w+/g) || [])
  .reduce((acc, word) =&gt; {
    const len = word.length;
    acc[len] = (acc[len] || 0) + 1;
    return acc;
  }, {});

console.log("Word length distribution:");
Object.entries(lengthDist)
  .sort((a, b) =&gt; parseInt(a[0]) - parseInt(b[0]))
  .forEach(([len, count]) =&gt; {
    console.log(`${len} letters: ${count} words`);
  });
</code></pre>
<h2 id="real-world-example-war-and-peace"><a class="header" href="#real-world-example-war-and-peace">Real-World Example: War and Peace</a></h2>
<p>Analyze Tolstoy's War and Peace:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const [totalWords, uniqueWords] = await Promise.all([
  // Total words
  read("warandpeace.txt.gz")
    .transform(new DecompressionStream("gzip"))
    .lines
    .flatMap(line =&gt; line.match(/\w+/g) || [])
    .count(),
  
  // Unique words
  read("warandpeace.txt.gz")
    .transform(new DecompressionStream("gzip"))
    .lines
    .flatMap(line =&gt; line.toLowerCase().match(/\w+/g) || [])
    .reduce((acc, word) =&gt; {
      acc.add(word);
      return acc;
    }, new Set())
    .then(set =&gt; set.size)
]);

console.log(`Total words: ${totalWords.toLocaleString()}`);
console.log(`Unique words: ${uniqueWords.toLocaleString()}`);
console.log(`Vocabulary richness: ${(uniqueWords / totalWords * 100).toFixed(1)}%`);
</code></pre>
<h2 id="performance-comparison-1"><a class="header" href="#performance-comparison-1">Performance Comparison</a></h2>
<h3 id="shell-pipeline-fast"><a class="header" href="#shell-pipeline-fast">Shell Pipeline (fast)</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Uses native Unix tools
const count = await run("cat", "book.txt")
  .run("wc", "-w")
  .lines.first;
</code></pre>
<h3 id="javascript-flexible"><a class="header" href="#javascript-flexible">JavaScript (flexible)</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// More control, type-safe
const count = await read("book.txt")
  .lines
  .flatMap(line =&gt; line.match(/\w+/g) || [])
  .count();
</code></pre>
<h3 id="hybrid-best-of-both"><a class="header" href="#hybrid-best-of-both">Hybrid (best of both)</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Use Unix tools for heavy lifting, JavaScript for logic
const words = await run("cat", "book.txt")
  .run("tr", "-cs", "A-Za-z", "\n")
  .lines
  .filter(word =&gt; word.length &gt; 5)  // JavaScript filter
  .count();
</code></pre>
<h2 id="next-steps-18"><a class="header" href="#next-steps-18">Next Steps</a></h2>
<ul>
<li><a href="recipes/../core/pipelines.html">Process Pipelines</a> - Chain commands together</li>
<li><a href="recipes/../advanced/concurrent.html">Concurrent Processing</a> - Process multiple files</li>
<li><a href="recipes/../advanced/streaming.html">Streaming Large Files</a> - Handle huge files</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="processing-log-files"><a class="header" href="#processing-log-files">Processing Log Files</a></h1>
<p>Analyze logs efficiently, even huge ones.</p>
<h2 id="count-errors"><a class="header" href="#count-errors">Count Errors</a></h2>
<!-- TESTED: tests/mdbook_examples.test.ts - "log-processing: count errors" -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const errorCount = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .count();

console.log(`${errorCount} errors found`);
</code></pre>
<h2 id="group-by-error-type"><a class="header" href="#group-by-error-type">Group by Error Type</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const errorTypes = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .reduce((acc, line) =&gt; {
    const match = line.match(/ERROR: (\w+)/);
    const type = match ? match[1] : "unknown";
    acc[type] = (acc[type] || 0) + 1;
    return acc;
  }, {});

console.log("Errors by type:");
Object.entries(errorTypes)
  .sort((a, b) =&gt; b[1] - a[1])
  .forEach(([type, count]) =&gt; {
    console.log(`  ${type}: ${count}`);
  });
</code></pre>
<h2 id="extract-timestamps"><a class="header" href="#extract-timestamps">Extract Timestamps</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const errors = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .map(line =&gt; {
    const timestamp = line.match(/\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}/)?.[0];
    const message = line.split("ERROR:")[1]?.trim();
    return { timestamp, message };
  })
  .collect();
</code></pre>
<h2 id="find-patterns"><a class="header" href="#find-patterns">Find Patterns</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const suspiciousIPs = await read("access.log")
  .lines
  .map(line =&gt; {
    const ip = line.match(/\d+\.\d+\.\d+\.\d+/)?.[0];
    const status = line.match(/HTTP\/\d\.\d" (\d+)/)?.[1];
    return { ip, status };
  })
  .filter(entry =&gt; entry.status === "404")
  .reduce((acc, entry) =&gt; {
    if (entry.ip) {
      acc[entry.ip] = (acc[entry.ip] || 0) + 1;
    }
    return acc;
  }, {});

// Show IPs with &gt; 100 404s
Object.entries(suspiciousIPs)
  .filter(([_, count]) =&gt; count &gt; 100)
  .forEach(([ip, count]) =&gt; {
    console.log(`${ip}: ${count} 404s`);
  });
</code></pre>
<h2 id="time-based-analysis"><a class="header" href="#time-based-analysis">Time-Based Analysis</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const errorsByHour = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .reduce((acc, line) =&gt; {
    const hour = line.match(/T(\d{2}):/)?.[1];
    if (hour) {
      acc[hour] = (acc[hour] || 0) + 1;
    }
    return acc;
  }, {});

console.log("Errors by hour:");
Object.entries(errorsByHour)
  .sort((a, b) =&gt; a[0].localeCompare(b[0]))
  .forEach(([hour, count]) =&gt; {
    console.log(`${hour}:00 - ${count} errors`);
  });
</code></pre>
<h2 id="multiple-log-files"><a class="header" href="#multiple-log-files">Multiple Log Files</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const files = ["app1.log", "app2.log", "app3.log"];

const results = await enumerate(files)
  .concurrentMap(async (file) =&gt; {
    const errors = await read(file)
      .lines
      .filter(line =&gt; line.includes("ERROR"))
      .count();
    return { file, errors };
  }, { concurrency: 3 })
  .collect();

results.forEach(({ file, errors }) =&gt; {
  console.log(`${file}: ${errors} errors`);
});
</code></pre>
<h2 id="compressed-logs"><a class="header" href="#compressed-logs">Compressed Logs</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">const errors = await read("app.log.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .take(10)
  .collect();
</code></pre>
<h2 id="real-time-monitoring"><a class="header" href="#real-time-monitoring">Real-Time Monitoring</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Process log as it grows
for await (const line of read("app.log").lines) {
  if (line.includes("ERROR")) {
    console.error(`üî¥ ${line}`);
  } else if (line.includes("WARN")) {
    console.warn(`‚ö†Ô∏è  ${line}`);
  }
}
</code></pre>
<h2 id="next-steps-19"><a class="header" href="#next-steps-19">Next Steps</a></h2>
<ul>
<li><a href="recipes/../advanced/streaming.html">Streaming Large Files</a> - Handle huge logs</li>
<li><a href="recipes/../advanced/concurrent.html">Concurrent Processing</a> - Process multiple files</li>
<li><a href="recipes/./decompression.html">Decompressing Files</a> - Work with compressed logs</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="decompressing-files"><a class="header" href="#decompressing-files">Decompressing Files</a></h1>
<p>Process compressed files without creating temporary files. Stream everything.</p>
<h2 id="decompress-and-count-lines"><a class="header" href="#decompress-and-count-lines">Decompress and Count Lines</a></h2>
<!-- TESTED: tests/mdbook_examples.test.ts - "decompression: decompress and count" -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const lineCount = await read("war-and-peace.txt.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .count();

console.log(`${lineCount} lines`);
</code></pre>
<p><strong>What's happening:</strong></p>
<ul>
<li><code>read()</code> opens the file as a stream of bytes</li>
<li><code>.transform()</code> pipes through the decompression stream</li>
<li><code>.lines</code> converts bytes to text lines</li>
<li><code>.count()</code> counts them</li>
</ul>
<p>All streaming. No temp files. Constant memory usage.</p>
<h2 id="search-in-compressed-file"><a class="header" href="#search-in-compressed-file">Search in Compressed File</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const matches = await read("logs.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .collect();

console.log(`Found ${matches.length} errors`);
</code></pre>
<h2 id="process-multiple-compressed-files"><a class="header" href="#process-multiple-compressed-files">Process Multiple Compressed Files</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read, enumerate } from "jsr:@j50n/proc@0.23.3";

const files = ["log1.gz", "log2.gz", "log3.gz"];

for (const file of files) {
  const errors = await read(file)
    .transform(new DecompressionStream("gzip"))
    .lines
    .filter(line =&gt; line.includes("ERROR"))
    .count();
  
  console.log(`${file}: ${errors} errors`);
}
</code></pre>
<h2 id="decompress-and-transform"><a class="header" href="#decompress-and-transform">Decompress and Transform</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const data = await read("data.json.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .map(line =&gt; JSON.parse(line))
  .filter(obj =&gt; obj.status === "active")
  .collect();
</code></pre>
<h2 id="supported-formats"><a class="header" href="#supported-formats">Supported Formats</a></h2>
<p>The Web Streams API supports:</p>
<ul>
<li><strong>gzip</strong> - <code>.gz</code> files</li>
<li><strong>deflate</strong> - <code>.zip</code> files (deflate compression)</li>
<li><strong>deflate-raw</strong> - Raw deflate</li>
</ul>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// Gzip
.transform(new DecompressionStream("gzip"))

// Deflate
.transform(new DecompressionStream("deflate"))

// Deflate-raw
.transform(new DecompressionStream("deflate-raw"))
</code></pre>
<h2 id="compress-output"><a class="header" href="#compress-output">Compress Output</a></h2>
<p>You can also compress:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

const compressed = await read("large-file.txt")
  .transform(new CompressionStream("gzip"))
  .collect();

await Deno.writeFile("large-file.txt.gz", concat(compressed));
</code></pre>
<h2 id="real-world-example-log-analysis"><a class="header" href="#real-world-example-log-analysis">Real-World Example: Log Analysis</a></h2>
<p>Analyze compressed logs without extracting them:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { read } from "jsr:@j50n/proc@0.23.3";

interface LogEntry {
  timestamp: string;
  level: string;
  message: string;
}

const errors = await read("app.log.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .map(line =&gt; {
    const [timestamp, level, ...message] = line.split(" ");
    return { timestamp, level, message: message.join(" ") };
  })
  .filter(entry =&gt; entry.level === "ERROR")
  .collect();

console.log(`Found ${errors.length} errors`);
errors.slice(0, 10).forEach(e =&gt; {
  console.log(`${e.timestamp}: ${e.message}`);
});
</code></pre>
<h2 id="performance-tips-7"><a class="header" href="#performance-tips-7">Performance Tips</a></h2>
<h3 id="stream-dont-collect-1"><a class="header" href="#stream-dont-collect-1">Stream, Don't Collect</a></h3>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// ‚ùå Loads entire file into memory
const lines = await read("huge.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .collect();

// ‚úÖ Processes one line at a time
for await (const line of read("huge.gz")
  .transform(new DecompressionStream("gzip"))
  .lines) {
  process(line);
}
</code></pre>
<h3 id="use-concurrent-processing-1"><a class="header" href="#use-concurrent-processing-1">Use Concurrent Processing</a></h3>
<p>Process multiple files in parallel:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const files = ["log1.gz", "log2.gz", "log3.gz"];

const results = await enumerate(files)
  .concurrentMap(async (file) =&gt; {
    const errors = await read(file)
      .transform(new DecompressionStream("gzip"))
      .lines
      .filter(line =&gt; line.includes("ERROR"))
      .count();
    return { file, errors };
  }, { concurrency: 3 })
  .collect();
</code></pre>
<h2 id="why-this-is-better"><a class="header" href="#why-this-is-better">Why This Is Better</a></h2>
<p><strong>Traditional approach:</strong></p>
<pre><code class="language-bash"># Extract first
gunzip file.gz
# Then process
grep ERROR file
# Clean up
rm file
</code></pre>
<p><strong>proc approach:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">// One step, no temp files
await read("file.gz")
  .transform(new DecompressionStream("gzip"))
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .forEach(console.log);
</code></pre>
<p>Faster, cleaner, more memory-efficient.</p>
<h2 id="next-steps-20"><a class="header" href="#next-steps-20">Next Steps</a></h2>
<ul>
<li><a href="recipes/../advanced/streaming.html">Streaming Large Files</a> - Handle huge files</li>
<li><a href="recipes/../advanced/concurrent.html">Concurrent Processing</a> - Process multiple files in parallel</li>
<li><a href="recipes/../utilities/file-io.html">File I/O</a> - More file operations</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="parallel-downloads"><a class="header" href="#parallel-downloads">Parallel Downloads</a></h1>
<p>Download multiple files concurrently with controlled concurrency.</p>
<h2 id="basic-example"><a class="header" href="#basic-example">Basic Example</a></h2>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const urls = [
  "https://example.com/file1.json",
  "https://example.com/file2.json",
  "https://example.com/file3.json",
  // ... more URLs
];

const results = await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    const response = await fetch(url);
    if (!response.ok) {
      throw new Error(`Failed to fetch ${url}: ${response.status}`);
    }
    return {
      url,
      data: await response.json(),
      size: response.headers.get("content-length")
    };
  }, { concurrency: 5 })
  .collect();

console.log(`Downloaded ${results.length} files`);
</code></pre>
<h2 id="download-and-save-files"><a class="header" href="#download-and-save-files">Download and Save Files</a></h2>
<p>Download files and save them to disk:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const downloads = [
  { url: "https://example.com/image1.jpg", path: "./downloads/image1.jpg" },
  { url: "https://example.com/image2.jpg", path: "./downloads/image2.jpg" },
  { url: "https://example.com/image3.jpg", path: "./downloads/image3.jpg" },
];

await enumerate(downloads)
  .concurrentMap(async ({ url, path }) =&gt; {
    const response = await fetch(url);
    const blob = await response.blob();
    const buffer = await blob.arrayBuffer();
    await Deno.writeFile(path, new Uint8Array(buffer));
    console.log(`Downloaded: ${path}`);
    return path;
  }, { concurrency: 3 })
  .collect();

console.log("All downloads complete");
</code></pre>
<h2 id="with-progress-tracking"><a class="header" href="#with-progress-tracking">With Progress Tracking</a></h2>
<p>Track download progress:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

let completed = 0;
const total = urls.length;

const results = await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    const response = await fetch(url);
    const data = await response.json();
    
    completed++;
    console.log(`Progress: ${completed}/${total} (${Math.round(completed/total*100)}%)`);
    
    return { url, data };
  }, { concurrency: 5 })
  .collect();
</code></pre>
<h2 id="with-retry-logic"><a class="header" href="#with-retry-logic">With Retry Logic</a></h2>
<p>Retry failed downloads:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

async function fetchWithRetry(url: string, maxRetries = 3): Promise&lt;Response&gt; {
  for (let attempt = 1; attempt &lt;= maxRetries; attempt++) {
    try {
      const response = await fetch(url);
      if (response.ok) return response;
      
      if (attempt === maxRetries) {
        throw new Error(`Failed after ${maxRetries} attempts: ${response.status}`);
      }
    } catch (error) {
      if (attempt === maxRetries) throw error;
      
      // Exponential backoff
      const delay = Math.min(1000 * Math.pow(2, attempt - 1), 10000);
      console.log(`Retry ${attempt}/${maxRetries} for ${url} after ${delay}ms`);
      await new Promise(resolve =&gt; setTimeout(resolve, delay));
    }
  }
  throw new Error("Unreachable");
}

const results = await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    const response = await fetchWithRetry(url);
    return await response.json();
  }, { concurrency: 5 })
  .collect();
</code></pre>
<h2 id="download-large-files"><a class="header" href="#download-large-files">Download Large Files</a></h2>
<p>Stream large files to disk without loading into memory:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const largeFiles = [
  { url: "https://example.com/large1.zip", path: "./large1.zip" },
  { url: "https://example.com/large2.zip", path: "./large2.zip" },
];

await enumerate(largeFiles)
  .concurrentMap(async ({ url, path }) =&gt; {
    const response = await fetch(url);
    if (!response.body) throw new Error("No response body");
    
    const file = await Deno.open(path, { write: true, create: true });
    await response.body.pipeTo(file.writable);
    
    console.log(`Downloaded: ${path}`);
    return path;
  }, { concurrency: 2 })
  .collect();
</code></pre>
<h2 id="api-rate-limiting"><a class="header" href="#api-rate-limiting">API Rate Limiting</a></h2>
<p>Respect API rate limits:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const apiEndpoints = [
  "/api/users/1",
  "/api/users/2",
  // ... 100 more
];

// Add delay between requests
await enumerate(apiEndpoints)
  .concurrentMap(async (endpoint) =&gt; {
    const response = await fetch(`https://api.example.com${endpoint}`);
    const data = await response.json();
    
    // Wait 100ms between requests (10 requests/second)
    await new Promise(resolve =&gt; setTimeout(resolve, 100));
    
    return data;
  }, { concurrency: 1 })  // Sequential to respect rate limit
  .collect();
</code></pre>
<h2 id="filter-failed-downloads"><a class="header" href="#filter-failed-downloads">Filter Failed Downloads</a></h2>
<p>Continue even if some downloads fail:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">import { enumerate } from "jsr:@j50n/proc@0.23.3";

const results = await enumerate(urls)
  .concurrentMap(async (url) =&gt; {
    try {
      const response = await fetch(url);
      if (!response.ok) return null;
      return { url, data: await response.json() };
    } catch (error) {
      console.error(`Failed to download ${url}:`, error.message);
      return null;
    }
  }, { concurrency: 5 })
  .filter(result =&gt; result !== null)
  .collect();

console.log(`Successfully downloaded ${results.length}/${urls.length} files`);
</code></pre>
<h2 id="when-to-use"><a class="header" href="#when-to-use">When to Use</a></h2>
<p><strong>Use parallel downloads when:</strong></p>
<ul>
<li>You have multiple independent files to fetch</li>
<li>Network latency is the bottleneck</li>
<li>The server can handle concurrent requests</li>
<li>You want to minimize total download time</li>
</ul>
<p><strong>Choose concurrency based on:</strong></p>
<ul>
<li>Server rate limits (respect them!)</li>
<li>Your network bandwidth</li>
<li>Server capacity</li>
<li>Start with 3-5, adjust based on results</li>
</ul>
<h2 id="next-steps-21"><a class="header" href="#next-steps-21">Next Steps</a></h2>
<ul>
<li><a href="recipes/../advanced/concurrent.html">Concurrent Processing</a> - Deep dive into concurrency</li>
<li><a href="recipes/../core/error-handling.html">Error Handling</a> - Handle download failures</li>
<li><a href="recipes/../advanced/streaming.html">Streaming Large Files</a> - Work with large downloads</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="shell-script-replacement"><a class="header" href="#shell-script-replacement">Shell Script Replacement</a></h1>
<p>Replace Bash scripts with type-safe Deno.</p>
<h2 id="why-replace-shell-scripts"><a class="header" href="#why-replace-shell-scripts">Why Replace Shell Scripts?</a></h2>
<p><strong>Shell scripts are:</strong></p>
<ul>
<li>Hard to debug</li>
<li>No type safety</li>
<li>Limited error handling</li>
<li>Platform-specific</li>
</ul>
<p><strong>proc gives you:</strong></p>
<ul>
<li>Full TypeScript</li>
<li>IDE support</li>
<li>Proper error handling</li>
<li>Cross-platform</li>
</ul>
<h2 id="common-patterns-8"><a class="header" href="#common-patterns-8">Common Patterns</a></h2>
<h3 id="file-operations"><a class="header" href="#file-operations">File Operations</a></h3>
<p><strong>Bash:</strong></p>
<pre><code class="language-bash">#!/bin/bash
for file in *.txt; do
  wc -l "$file"
done
</code></pre>
<p><strong>proc:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">#!/usr/bin/env -S deno run --allow-read --allow-run
import { run } from "jsr:@j50n/proc@0.23.3";

for await (const entry of Deno.readDir(".")) {
  if (entry.name.endsWith(".txt")) {
    const count = await run("wc", "-l", entry.name).lines.first;
    console.log(count);
  }
}
</code></pre>
<h3 id="process-logs"><a class="header" href="#process-logs">Process Logs</a></h3>
<p><strong>Bash:</strong></p>
<pre><code class="language-bash">#!/bin/bash
grep ERROR app.log | wc -l
</code></pre>
<p><strong>proc:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">#!/usr/bin/env -S deno run --allow-read --allow-run
import { read } from "jsr:@j50n/proc@0.23.3";

const errors = await read("app.log")
  .lines
  .filter(line =&gt; line.includes("ERROR"))
  .count();

console.log(`${errors} errors`);
</code></pre>
<h3 id="backup-script"><a class="header" href="#backup-script">Backup Script</a></h3>
<p><strong>Bash:</strong></p>
<pre><code class="language-bash">#!/bin/bash
tar -czf backup-$(date +%Y%m%d).tar.gz /data
</code></pre>
<p><strong>proc:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">#!/usr/bin/env -S deno run --allow-read --allow-run
import { run } from "jsr:@j50n/proc@0.23.3";

const date = new Date().toISOString().split("T")[0].replace(/-/g, "");
await run("tar", "-czf", `backup-${date}.tar.gz`, "/data").toStdout();
</code></pre>
<h3 id="system-monitoring"><a class="header" href="#system-monitoring">System Monitoring</a></h3>
<p><strong>Bash:</strong></p>
<pre><code class="language-bash">#!/bin/bash
while true; do
  df -h | grep /dev/sda1
  sleep 60
done
</code></pre>
<p><strong>proc:</strong></p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">#!/usr/bin/env -S deno run --allow-run
import { run, sleep } from "jsr:@j50n/proc@0.23.3";

while (true) {
  const usage = await run("df", "-h")
    .lines
    .find(line =&gt; line.includes("/dev/sda1"));
  
  console.log(usage);
  await sleep(60000);  // sleep() is exported from proc
}
</code></pre>
<h2 id="real-script-example"><a class="header" href="#real-script-example">Real Script Example</a></h2>
<p>Complete deployment script:</p>
<!-- NOT TESTED: Illustrative example -->
<pre><code class="language-typescript">#!/usr/bin/env -S deno run --allow-all
import { run } from "jsr:@j50n/proc@0.23.3";

console.log("üöÄ Deploying application...");

try {
  // Pull latest code
  console.log("üì• Pulling latest code...");
  await run("git", "pull").toStdout();
  
  // Install dependencies
  console.log("üì¶ Installing dependencies...");
  await run("npm", "install").toStdout();
  
  // Run tests
  console.log("üß™ Running tests...");
  await run("npm", "test").toStdout();
  
  // Build
  console.log("üî® Building...");
  await run("npm", "run", "build").toStdout();
  
  // Restart service
  console.log("üîÑ Restarting service...");
  await run("systemctl", "restart", "myapp").toStdout();
  
  console.log("‚úÖ Deployment complete!");
} catch (error) {
  console.error("‚ùå Deployment failed:", error.message);
  Deno.exit(1);
}
</code></pre>
<h2 id="benefits"><a class="header" href="#benefits">Benefits</a></h2>
<ol>
<li><strong>Type Safety</strong> - Catch errors before running</li>
<li><strong>IDE Support</strong> - Autocomplete and refactoring</li>
<li><strong>Error Handling</strong> - Proper try-catch</li>
<li><strong>Debugging</strong> - Use debugger, breakpoints</li>
<li><strong>Testing</strong> - Write unit tests</li>
<li><strong>Portability</strong> - Works on any platform with Deno</li>
</ol>
<h2 id="making-scripts-executable"><a class="header" href="#making-scripts-executable">Making Scripts Executable</a></h2>
<pre><code class="language-bash">chmod +x script.ts
./script.ts
</code></pre>
<h2 id="next-steps-22"><a class="header" href="#next-steps-22">Next Steps</a></h2>
<ul>
<li><a href="recipes/../core/running-processes.html">Running Processes</a> - Process basics</li>
<li><a href="recipes/../core/error-handling.html">Error Handling</a> - Handle failures</li>
<li><a href="recipes/../core/pipelines.html">Process Pipelines</a> - Chain commands</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-reference-1"><a class="header" href="#api-reference-1">API Reference</a></h1>
<p>Complete API documentation is auto-generated from the source code using Deno's
documentation tool.</p>
<h2 :target="&quot;_blank&quot;"><a href="./api-docs/index.html">üìö View Full API Documentation</a></h2>
<p>The API documentation includes:</p>
<ul>
<li><strong>All exported functions</strong> - Complete signatures and descriptions</li>
<li><strong>All classes and interfaces</strong> - Full type information</li>
<li><strong>All methods and properties</strong> - Detailed documentation</li>
<li><strong>Type definitions</strong> - Complete TypeScript types</li>
<li><strong>Examples</strong> - Code examples from JSDoc</li>
</ul>
<h2 id="quick-links"><a class="header" href="#quick-links">Quick Links</a></h2>
<h3 id="core-functions"><a class="header" href="#core-functions">Core Functions</a></h3>
<ul>
<li><strong><a href="./api-docs/~/run.html">run()</a>{:target="_blank"}</strong> - Run a child process</li>
<li><strong><a href="./api-docs/~/enumerate.html">enumerate()</a>{:target="_blank"}</strong> - Wrap an
iterable</li>
<li><strong><a href="./api-docs/~/read.html">read()</a>{:target="_blank"}</strong> - Read a file</li>
</ul>
<h3 id="classes"><a class="header" href="#classes">Classes</a></h3>
<ul>
<li><strong><a href="./api-docs/~/Enumerable.html">Enumerable</a>{:target="_blank"}</strong> - Array-like
methods for async iterables</li>
<li><strong><a href="./api-docs/~/ProcessEnumerable.html">ProcessEnumerable</a>{:target="_blank"}</strong> -
Process-specific enumerable</li>
<li><strong><a href="./api-docs/~/Process.html">Process</a>{:target="_blank"}</strong> - Process
management</li>
</ul>
<h3 id="error-types-1"><a class="header" href="#error-types-1">Error Types</a></h3>
<ul>
<li><strong><a href="./api-docs/~/ExitCodeError.html">ExitCodeError</a>{:target="_blank"}</strong> -
Non-zero exit code</li>
<li><strong><a href="./api-docs/~/SignalError.html">SignalError</a>{:target="_blank"}</strong> - Process
killed by signal</li>
<li><strong><a href="./api-docs/~/UpstreamError.html">UpstreamError</a>{:target="_blank"}</strong> - Error
from upstream process</li>
</ul>
<h3 id="utilities-1"><a class="header" href="#utilities-1">Utilities</a></h3>
<ul>
<li><strong><a href="./api-docs/~/range.html">range()</a>{:target="_blank"}</strong> - Generate number
ranges</li>
<li><strong><a href="./api-docs/~/zip.html">zip()</a>{:target="_blank"}</strong> - Combine iterables</li>
<li><strong><a href="./api-docs/~/concat.html">concat()</a>{:target="_blank"}</strong> - Concatenate byte
arrays</li>
<li><strong><a href="./api-docs/~/cache.html">cache()</a>{:target="_blank"}</strong> - Cache iterable
results</li>
</ul>
<h2 id="using-the-api-docs"><a class="header" href="#using-the-api-docs">Using the API Docs</a></h2>
<p>The generated documentation includes:</p>
<h3 id="search"><a class="header" href="#search">Search</a></h3>
<p>Use the search box to find any function, class, or type.</p>
<h3 id="type-information"><a class="header" href="#type-information">Type Information</a></h3>
<p>Click on any type to see its definition and usage.</p>
<h3 id="examples"><a class="header" href="#examples">Examples</a></h3>
<p>Most functions include working code examples.</p>
<h3 id="source-links"><a class="header" href="#source-links">Source Links</a></h3>
<p>Click "Source" to view the implementation.</p>
<h2 id="integration-with-this-guide"><a class="header" href="#integration-with-this-guide">Integration with This Guide</a></h2>
<p>This user guide provides:</p>
<ul>
<li><strong>Conceptual explanations</strong> - Why and when to use features</li>
<li><strong>Tutorials</strong> - Step-by-step learning</li>
<li><strong>Recipes</strong> - Real-world solutions</li>
<li><strong>Best practices</strong> - How to use effectively</li>
</ul>
<p>The API reference provides:</p>
<ul>
<li><strong>Complete signatures</strong> - Exact function parameters</li>
<li><strong>Type definitions</strong> - TypeScript types</li>
<li><strong>Technical details</strong> - Implementation specifics</li>
<li><strong>All exports</strong> - Everything available</li>
</ul>
<p>Use both together for complete understanding!</p>
<h2 id="keeping-docs-updated"><a class="header" href="#keeping-docs-updated">Keeping Docs Updated</a></h2>
<p>The API documentation is regenerated every time the site is built, so it's
always in sync with the code.</p>
<p>To regenerate manually:</p>
<pre><code class="language-bash">deno doc --html --name="proc" --output=./site/src/api-docs ./mod.ts
</code></pre>
<h2 id="next-steps-23"><a class="header" href="#next-steps-23">Next Steps</a></h2>
<ul>
<li><a href="./api-docs/index.html">Browse the full API documentation</a>{:target="_blank"}</li>
<li><a href="./getting-started/installation.html">Getting Started</a> - If you're new</li>
<li><a href="./core/error-handling.html">Core Features</a> - Learn the essentials</li>
<li><a href="./recipes/counting-words.html">Recipes</a> - See real examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="migration-guide"><a class="header" href="#migration-guide">Migration Guide</a></h1>
<p>Migrating from other tools to proc.</p>
<h2 id="from-denocommand"><a class="header" href="#from-denocommand">From Deno.Command</a></h2>
<p><strong>Before:</strong></p>
<pre><code class="language-typescript">const command = new Deno.Command("ls", { args: ["-la"] });
const output = await command.output();
const text = new TextDecoder().decode(output.stdout);
</code></pre>
<p><strong>After:</strong></p>
<pre><code class="language-typescript">import { run } from "jsr:@j50n/proc@0.23.3";
const lines = await run("ls", "-la").lines.collect();
</code></pre>
<h2 id="from-shell-scripts"><a class="header" href="#from-shell-scripts">From Shell Scripts</a></h2>
<p>See <a href="./recipes/shell-replacement.html">Shell Script Replacement</a> for detailed
examples.</p>
<h2 id="key-differences"><a class="header" href="#key-differences">Key Differences</a></h2>
<ul>
<li>Properties vs methods: <code>.lines</code> not <code>.lines()</code></li>
<li>Always consume output to avoid leaks</li>
<li>Errors propagate through pipelines</li>
<li>Use <code>enumerate()</code> then <code>.enum()</code> for indices</li>
</ul>
<h2 id="see-also"><a class="header" href="#see-also">See Also</a></h2>
<ul>
<li><a href="./getting-started/installation.html">Getting Started</a> - Installation</li>
<li><a href="./getting-started/key-concepts.html">Key Concepts</a> - Important concepts</li>
<li><a href="./faq.html">FAQ</a> - Common questions</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="frequently-asked-questions"><a class="header" href="#frequently-asked-questions">Frequently Asked Questions</a></h1>
<h2 id="general"><a class="header" href="#general">General</a></h2>
<h3 id="what-is-proc-1"><a class="header" href="#what-is-proc-1">What is proc?</a></h3>
<p>proc is a Deno library for running child processes and working with async
iterables. It gives you Array-like methods (map, filter, reduce) for streaming
data, with error handling that actually makes sense.</p>
<h3 id="why-should-i-use-proc-instead-of-denocommand"><a class="header" href="#why-should-i-use-proc-instead-of-denocommand">Why should I use proc instead of Deno.Command?</a></h3>
<p>Deno.Command is low-level and requires manual stream handling. proc gives you:</p>
<ul>
<li>Automatic resource management</li>
<li>Natural error propagation</li>
<li>Array-like methods for data processing</li>
<li>Process pipelines that feel like shell pipes</li>
<li>Streaming by default</li>
</ul>
<h3 id="is-proc-production-ready"><a class="header" href="#is-proc-production-ready">Is proc production-ready?</a></h3>
<p>Yes! proc is stable, actively maintained, and used in production. The API is
mature and unlikely to have breaking changes.</p>
<h3 id="does-proc-work-with-nodejs"><a class="header" href="#does-proc-work-with-nodejs">Does proc work with Node.js?</a></h3>
<p>No, proc is Deno-only. It uses Deno-specific APIs like <code>Deno.Command</code> and
requires Deno's permission system.</p>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<h3 id="why-do-i-get-resource-leak-errors"><a class="header" href="#why-do-i-get-resource-leak-errors">Why do I get "resource leak" errors?</a></h3>
<p>You must consume process output. Unconsumed output keeps the process handle
open:</p>
<pre><code class="language-typescript">// ‚ùå Resource leak
const p = run("ls");

// ‚úÖ Consume output
await run("ls").lines.collect();
</code></pre>
<h3 id="is-lines-a-method-or-property"><a class="header" href="#is-lines-a-method-or-property">Is <code>.lines</code> a method or property?</a></h3>
<p><strong>Property.</strong> Use <code>.lines</code> not <code>.lines()</code>:</p>
<pre><code class="language-typescript">// ‚úÖ Correct
run("ls").lines;

// ‚ùå Wrong
run("ls").lines();
</code></pre>
<p>Same for <code>.status</code>, <code>.first</code>, <code>.last</code>.</p>
<h3 id="how-do-i-check-exit-code-without-throwing"><a class="header" href="#how-do-i-check-exit-code-without-throwing">How do I check exit code without throwing?</a></h3>
<p>Consume output first, then check <code>.status</code>:</p>
<pre><code class="language-typescript">const p = run("command");
await p.lines.collect(); // Consume first
const status = await p.status; // Then check

if (status.code !== 0) {
  console.error("Failed");
}
</code></pre>
<h3 id="why-doesnt-enumerate-add-indices"><a class="header" href="#why-doesnt-enumerate-add-indices">Why doesn't <code>enumerate()</code> add indices?</a></h3>
<p><code>enumerate()</code> wraps an iterable. Use <code>.enum()</code> to add indices:</p>
<pre><code class="language-typescript">const result = await enumerate(["a", "b", "c"])
  .enum() // This adds indices
  .map(([item, i]) =&gt; `${i}: ${item}`)
  .collect();
</code></pre>
<h3 id="how-do-i-pipe-processes-together"><a class="header" href="#how-do-i-pipe-processes-together">How do I pipe processes together?</a></h3>
<p>Use <code>.run()</code> method:</p>
<pre><code class="language-typescript">await run("cat", "file.txt")
  .run("grep", "pattern")
  .run("wc", "-l")
  .lines.first;
</code></pre>
<h3 id="can-i-use-shell-syntax-like-ls--la"><a class="header" href="#can-i-use-shell-syntax-like-ls--la">Can I use shell syntax like <code>ls -la</code>?</a></h3>
<p>No, arguments must be separate:</p>
<pre><code class="language-typescript">// ‚úÖ Correct
run("ls", "-la");

// ‚ùå Wrong
run("ls -la");
</code></pre>
<h2 id="error-handling-7"><a class="header" href="#error-handling-7">Error Handling</a></h2>
<h3 id="do-i-need-try-catch-at-every-step"><a class="header" href="#do-i-need-try-catch-at-every-step">Do I need try-catch at every step?</a></h3>
<p>No! That's the whole point. Errors propagate through the pipeline:</p>
<pre><code class="language-typescript">try {
  await run("cmd1")
    .run("cmd2")
    .run("cmd3")
    .lines.forEach(process);
} catch (error) {
  // All errors caught here
}
</code></pre>
<h3 id="what-happens-when-a-process-fails"><a class="header" href="#what-happens-when-a-process-fails">What happens when a process fails?</a></h3>
<p>By default, non-zero exit codes throw <code>ExitCodeError</code>. You can catch it:</p>
<pre><code class="language-typescript">try {
  await run("false").lines.collect();
} catch (error) {
  if (error instanceof ExitCodeError) {
    console.error(`Exit code: ${error.code}`);
  }
}
</code></pre>
<h3 id="can-i-customize-error-handling"><a class="header" href="#can-i-customize-error-handling">Can I customize error handling?</a></h3>
<p>Yes, use <code>fnError</code> option. See
<a href="./advanced/custom-errors.html">Custom Error Handling</a>.</p>
<h2 id="performance-3"><a class="header" href="#performance-3">Performance</a></h2>
<h3 id="is-proc-fast"><a class="header" href="#is-proc-fast">Is proc fast?</a></h3>
<p>Yes! proc is streaming by default, which means:</p>
<ul>
<li>Constant memory usage, even for huge files</li>
<li>Concurrent process execution</li>
<li>Lazy evaluation (only runs when consumed)</li>
</ul>
<h3 id="how-do-i-process-large-files"><a class="header" href="#how-do-i-process-large-files">How do I process large files?</a></h3>
<p>Stream them:</p>
<pre><code class="language-typescript">// Processes 10GB file with constant memory
for await (const line of read("huge.txt").lines) {
  process(line);
}
</code></pre>
<h3 id="can-i-process-files-in-parallel"><a class="header" href="#can-i-process-files-in-parallel">Can I process files in parallel?</a></h3>
<p>Yes, use <code>concurrentMap</code>:</p>
<pre><code class="language-typescript">await enumerate(files)
  .concurrentMap(async (file) =&gt; {
    return await processFile(file);
  }, { concurrency: 5 })
  .collect();
</code></pre>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="my-process-hangs"><a class="header" href="#my-process-hangs">My process hangs</a></h3>
<p>You probably didn't consume the output:</p>
<pre><code class="language-typescript">// ‚ùå Hangs
const p = run("command");
await p.status; // Waiting for output to be consumed

// ‚úÖ Works
const p = run("command");
await p.lines.collect(); // Consume first
await p.status;
</code></pre>
<h3 id="i-get-type-errors"><a class="header" href="#i-get-type-errors">I get type errors</a></h3>
<p>Check if you're using properties as methods:</p>
<pre><code class="language-typescript">// ‚ùå Type error
run("ls").lines();

// ‚úÖ Correct
run("ls").lines;
</code></pre>
<h3 id="decompressionstream-type-error"><a class="header" href="#decompressionstream-type-error">DecompressionStream type error</a></h3>
<p>Add a type cast:</p>
<pre><code class="language-typescript">.transform(new DecompressionStream("gzip") as TransformStream&lt;Uint8Array, Uint8Array&gt;)
</code></pre>
<p>Or use <code>--no-check</code> flag.</p>
<h3 id="permission-denied-errors"><a class="header" href="#permission-denied-errors">Permission denied errors</a></h3>
<p>Grant the necessary permissions:</p>
<pre><code class="language-bash">deno run --allow-run --allow-read your-script.ts
</code></pre>
<h2 id="comparison"><a class="header" href="#comparison">Comparison</a></h2>
<h3 id="proc-vs-denocommand"><a class="header" href="#proc-vs-denocommand">proc vs Deno.Command</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Deno.Command</th><th>proc</th></tr></thead><tbody>
<tr><td>Boilerplate</td><td>High</td><td>Low</td></tr>
<tr><td>Error handling</td><td>Manual</td><td>Automatic</td></tr>
<tr><td>Streaming</td><td>Manual</td><td>Built-in</td></tr>
<tr><td>Pipelines</td><td>Manual</td><td><code>.run()</code></td></tr>
<tr><td>Array methods</td><td>No</td><td>Yes</td></tr>
</tbody></table>
</div>
<h3 id="proc-vs-shell-scripts"><a class="header" href="#proc-vs-shell-scripts">proc vs shell scripts</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Shell</th><th>proc</th></tr></thead><tbody>
<tr><td>Type safety</td><td>No</td><td>Yes</td></tr>
<tr><td>Error handling</td><td>Manual</td><td>Automatic</td></tr>
<tr><td>IDE support</td><td>Limited</td><td>Full</td></tr>
<tr><td>Debugging</td><td>Hard</td><td>Easy</td></tr>
<tr><td>Portability</td><td>Limited</td><td>Cross-platform</td></tr>
</tbody></table>
</div>
<h2 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h2>
<h3 id="where-can-i-find-examples"><a class="header" href="#where-can-i-find-examples">Where can I find examples?</a></h3>
<ul>
<li><a href="./getting-started/quick-start.html">Quick Start</a></li>
<li><a href="./recipes/counting-words.html">Recipes</a></li>
<li><a href="./api/run.html">API Reference</a></li>
</ul>
<h3 id="how-do-i-report-bugs"><a class="header" href="#how-do-i-report-bugs">How do I report bugs?</a></h3>
<p><a href="https://github.com/j50n/deno-proc/issues">File an issue</a> on GitHub.</p>
<h3 id="is-there-a-discordslack"><a class="header" href="#is-there-a-discordslack">Is there a Discord/Slack?</a></h3>
<p>Not currently. Use GitHub issues for questions and discussions.</p>
<h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<h3 id="can-i-contribute"><a class="header" href="#can-i-contribute">Can I contribute?</a></h3>
<p>Yes! Contributions are welcome. See the repository for guidelines.</p>
<h3 id="how-can-i-help"><a class="header" href="#how-can-i-help">How can I help?</a></h3>
<ul>
<li>Report bugs</li>
<li>Improve documentation</li>
<li>Add examples</li>
<li>Fix issues</li>
</ul>
<h2 id="miscellaneous"><a class="header" href="#miscellaneous">Miscellaneous</a></h2>
<h3 id="why-proc-1"><a class="header" href="#why-proc-1">Why "proc"?</a></h3>
<p>Short for "process". Easy to type, easy to remember.</p>
<h3 id="who-maintains-proc"><a class="header" href="#who-maintains-proc">Who maintains proc?</a></h3>
<p>proc is maintained by <a href="https://github.com/j50n">@j50n</a> and contributors.</p>
<h3 id="whats-the-license"><a class="header" href="#whats-the-license">What's the license?</a></h3>
<p>MIT License. Use it freely.</p>
<h3 id="can-i-use-proc-in-commercial-projects"><a class="header" href="#can-i-use-proc-in-commercial-projects">Can I use proc in commercial projects?</a></h3>
<p>Yes! MIT license allows commercial use.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="theme/custom.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
